[
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "Background\nMy name is Raquel (Rack-el) and I come from the bustling metropolis of Miami Florida, however I prefer the quiet of the mountains to the coast. By trade I am a veterinarian and while I enjoy clinical medicine, I am most passionate about wildlife disease research. Specifically zoonosis and reverse zoonosis.\n\n\n\nPast Research\nSome of my past research topics include: SARS-CoV-2 in North American Wildlife, the Burden and Diversity of Antimicrobial Resistance Genes in White Stork, and most recently the epidemiology of Sarcoptic mange in American black bears.\n\n\n\nCourse Goals\nI consider myself passable at best in regard to coding and statistical analysis. I hope to use this course as a tool to better understand, visualize, and interpret my often “messy” wildlife field data.\n\n\nFun Fact\nMy spouse and I own 9 chickens. All are hens, all have names, and all come running when you call out “Ladies!”.\n\n\n\nWeird Fact\nRecently it was discovered that California Condors can undergo pathenogenesis, where in a female can create a fertile egg without a male. This was discovered due to continuous genetic analysis of captive-bred condor chicks. While both chicks survived infancy, neither survived to sexual maturity. Bringing into questions, what is the evolutionary advantage of this process IF males are present.\nFacultative Parthenogenesis in California Condors"
  },
  {
    "objectID": "AMRproject/AMRsummary.html",
    "href": "AMRproject/AMRsummary.html",
    "title": "A Match Made in Landfills?",
    "section": "",
    "text": "Warning: package 'here' was built under R version 4.2.2\n\n\nWarning: package 'knitr' was built under R version 4.2.2"
  },
  {
    "objectID": "AMRproject/AMRsummary.html#questionshypotheses-to-be-addressed",
    "href": "AMRproject/AMRsummary.html#questionshypotheses-to-be-addressed",
    "title": "A Match Made in Landfills?",
    "section": "Questions/Hypotheses to be addressed",
    "text": "Questions/Hypotheses to be addressed\nDoes landfill use by storks increase the likelihood of carrying Antimicrobial resistance (AMR) genes and resistance gene burden?.\nStork that visit the landfill more often will have a higher likelihood of carrying AMR genes and have a higher burden of AMR genes.\nIs nest success related to AMR gene burden and multi-drug resistance (i.e., resistance to 3 or more drug classes)?\nStork with more AMR gene burdens and multi-drug resistance will have lower nest success.\n\nDescription of data and data source\nWe have 126 observations taken over a period of 2 years. We are evaluating for the presence and burden of antimicrobial resistance genes in white stork feces."
  },
  {
    "objectID": "AMRproject/AMRsummary.html#data-aquisition",
    "href": "AMRproject/AMRsummary.html#data-aquisition",
    "title": "A Match Made in Landfills?",
    "section": "Data aquisition",
    "text": "Data aquisition\n\nExperimental Design\nStudy Area — This study took place in Prado Herrero, a private cattle ranch located northwest of metropolitan Madrid and is surrounded by agriculture (e.g. beef cattle, cereal grains, legumes, and forage plants (“Renta Agraria,” 2019)). Prado Herrero is located within a nationally protected area (Cuenca Alta del Manzanares Regional Park) and is just north of Santillana Reservoir. This reservoir that was declared an Important Bird Area by Regional Catalogue of Reservoirs and Wetlands of the Community of Madrid due to the numerous resident and migratory species that utilize this water source . This cattle ranch has supported a productive white stork rookery where storks have been banded and monitored by biologists at UCM for over 20 years <CITE: Aguirre and Atienza>.\nDuring the 2020 to 2021 breeding season, between the months of March to June, stork nests were identified, marked, and monitored for productivity. Of marked nests between the 2020 and 2021 breeding seasons, 31 with banded adults were used both years to lay eggs successfully. All 31 nests were located in ash trees (Fraxinus angustifolius ) found within the cattle pasture. Storks that breed within the Prado Herrero rookery are known to utilize Colmenar Viejo Landfill which is located approximately 12km southeast. Colmenar Viejo is an open-air landfill and it is second largest of it’s kind in the Madrid region <CITE: Alejandro 2022>.\nSample Collection — Between March to May 2020 and 2021, we collected feces from marked nests with banded adults in known breeding pairs at 3 points of the breeding season:\n\nAdult sample during incubation\nAn early juvenile sample during the first two weeks of the chicks life when adults are believed to forage on natural sources <CITE: >.\n\n\n\nWhite stork chick growth from 1 to ~10 days of age\n\n\nA late juvenile sample after chicks were past two weeks of age when adults forage on anthropogenic resources.\n\n\n\nWhite stork chick from 21 to ~33 days of age.\n\n\n\nNests were visited in the late mornings and approximately one gram of fresh feces was collected from the perimeter of the nest structure into a sterile Eppendorf tube (). Samples were maintained cold in a portable cooler with frozen gel packs and frozen in a −20°C freezer within 4 hours of collection and processed at a later date.\nEthics statement: All animal handling was authorized by Cumunidad de Madrid: Consejeria de Medio Ambiente, Administracion Local y Ordenacion de Territorio. The permit number is D.N.I. nº 07.239.972-D."
  },
  {
    "objectID": "AMRproject/AMRsummary.html#molecular-analysis-of-args",
    "href": "AMRproject/AMRsummary.html#molecular-analysis-of-args",
    "title": "A Match Made in Landfills?",
    "section": "Molecular analysis of ARGs",
    "text": "Molecular analysis of ARGs\nWe performed total DNA extraction directly from fecal samples, by using a pressure filtration technique (QuickGene DNA Tissue Kit S, Fujifilm, Japan) following the manufacturer’s instructions. The 16S rRNA gene was amplified in each DNA sample by real time PCR (rtPCR) in 10-fold dilutions of extracted samples, according to Jiang et al. (2013). A DNA sample was considered validated when a ten-fold dilution showed a cycle threshold (Ct) less than 25 (Esperón et al., 2018).\nOnce validated, we analyzed DNA samples by with a panel of 21 different ARGs encoding resistance to eight different antimicrobial classes: tetracyclines (tet(A), tet(B), tet(Y), tet(K), tet(M), tet(Q), tet(S), and tet(W)), sulfonamides (sulI and sulII), aminoglycosides (str and aadA), phenicols (catI and catII), macrolides (ermB and ermF), quinolones (qnrS and qnrB), betalactams (blaTEM and mecA), and polymyxins (mcr-1). All rtPCR reactions utilized premade gelled format 96-well plates (Biotools, B &M Labs, S.A., Madrid, Spain), with the exception of blaTEM and mecA genes which used the Sybr GreenTM and TaqManTM probe, respectively. Our thermal cycle was the same for all the rtPCR reactions [6′ 95 °C, 40× (10″ 95 °C, 30″ 60 °C)], with alignment and extension in the same step, at constant temperature of 60 °C. A melting curve step was performed at the end of the qPCR reaction to validate the authenticity of the positive (Nieto-Claudin et al., 2019).\nWe quantified the relative burden of each gene for each sample via the cycle threshold (Ct) for the 16S rRNA and the Ct value of the individual ARG using a previously published formula (Esperón et al., 2020)."
  },
  {
    "objectID": "AMRproject/AMRsummary.html#statistical-analysis",
    "href": "AMRproject/AMRsummary.html#statistical-analysis",
    "title": "A Match Made in Landfills?",
    "section": "Statistical analysis",
    "text": "Statistical analysis\nPresence absence ARG results obtained from the fecal samples between 2020 to 2021 were used for simple summary statistics. Samples were classified as “multiresistant” if they were resistant to three or more of the 8 antibiotic classes that we evaluated for in this study (Blanco-Peña et al., 2017). In addition, we applied the following formula to estimate the percentage of bacteria harboring ARGs: x = 10[2+0.33(ct16S-ctARG)], where x individual percent gene burden in the sample (i.e., the estimated number of copies of the gene present per reaction). Results were expressed in log10, ranging from −8 ( zero to a negligible amount of the bacteria in the sample carried an ARG) to 2 (all or 100% of the bacteria in the sample carried an ARG). The inverse Log10 was then applied to results so they could be totalled and used to evalute total gene burdens accross sampling periods.\nSeveral linear mixed models (LMM) were constructed to evaluate multi-resistance and ARG burden as response variables with nest as a random factor. Covariates considered with each response variable included adult age, adult mean land fill use index (LUI), sample period (as described above), and nest success. Landfill use was quantified by physically observing a banded stork at Colmenar Viejo during weekly visits from March to June in 2021. The LUI was calculated as the number of observations of one particular bird within the total number of visits to landfill per year <CITE Alejandro 2022>. If a banded adult was not seen at the landfill during the breeding season, they were assigned a LUI of 0, suggestive of no resource provisioning at the landfill. All covariates were evaluated for correlation, no covariates were correlated with all the Spearman’s correlation coefficients (rho) < 0.5 and the p > 0.05. All continuous variables (LUI, age, and nest success) were then standardized prior to analysis.\nAll models were constructed with only 2021 data, as the COVID-19 pandemic prohibited the collection of LUI data in 2020. Models were built and fitted to data using the statistical package tidymodels in Program R (R version 4.2.1, www.r-project.org)."
  },
  {
    "objectID": "AMRproject/AMRsummary.html#summary-and-interpretation",
    "href": "AMRproject/AMRsummary.html#summary-and-interpretation",
    "title": "A Match Made in Landfills?",
    "section": "Summary and Interpretation",
    "text": "Summary and Interpretation\n\nAs multi-drug resistance and class diversity increase (similar things I know) throughout the breeding season (compounding effect likely), mean LUI decreases and nest success decreases (makes sense because in your prior papers you have found increase nest success with increased LUI).\nResistance gene burden appears to increase as mean LUI use and age increase. o Most of the burden is due to blaTEM, a common resistance gene associated with anthropogenic impact. Sampling period does not appear to explain burden, but the top blaTEM model did show a trend in burden increasing from the 2nd sampling period to the 3rd sampling period and age."
  },
  {
    "objectID": "AMRproject/AMRsummary.html#conclusions",
    "href": "AMRproject/AMRsummary.html#conclusions",
    "title": "A Match Made in Landfills?",
    "section": "Conclusions",
    "text": "Conclusions\nLUI appears to be correlated with higher levels of AMR gene burden in storks. As LUI increases thorough the breeding season (Bialas et al 2021) resistance gene burden also increases with beta lactam resistance contributing to the majority of the burden. However, multidrug resistance appears to decrease as LUI increases, thus it is likely that storks are being exposed to antimicrobial resistance genes at other foraging areas (urban centers, agricultural pastures, etc.).\nOur results suggest that landfills may not be contributing significantly to the emergence and maintenance of AMR in this system. Little literature exists on the relationship between stork habitat selection and health outside of landfill use in Spain. Future efforts in stork AMR research should focus on exploring the relationship between agricultural land use and health."
  },
  {
    "objectID": "AMRproject/AMRsummary.html#follow-this-link",
    "href": "AMRproject/AMRsummary.html#follow-this-link",
    "title": "A Match Made in Landfills?",
    "section": "Follow this link:",
    "text": "Follow this link:\n\nProject Repository"
  },
  {
    "objectID": "coding_exercise.html",
    "href": "coding_exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Import data and begin to clean data using Tidyverse\n\n#If needed install package that has our data (dslabs) abd the package that will help us clean the data (tidyverse)\n#install.packages(dslabs)\n#install.packages(tidyverse)\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.2.2\n\n#look at help file for gapminder data\n#?gapminder\n#get an overview of data structure\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n#get a summary of data\nsummary(gapminder)\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\n#determine the type of object gapminder is\nclass(gapminder)\n\n[1] \"data.frame\"\n\n#make a tibble data frame\nData <- gapminder  \nas.tibble(Data)\n\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n\n\n# A tibble: 10,545 × 9\n   country          year infan…¹ life_…² ferti…³ popul…⁴      gdp conti…⁵ region\n   <fct>           <int>   <dbl>   <dbl>   <dbl>   <dbl>    <dbl> <fct>   <fct> \n 1 Albania          1960   115.     62.9    6.19  1.64e6 NA       Europe  South…\n 2 Algeria          1960   148.     47.5    7.65  1.11e7  1.38e10 Africa  North…\n 3 Angola           1960   208      36.0    7.32  5.27e6 NA       Africa  Middl…\n 4 Antigua and Ba…  1960    NA      63.0    4.43  5.47e4 NA       Americ… Carib…\n 5 Argentina        1960    59.9    65.4    3.11  2.06e7  1.08e11 Americ… South…\n 6 Armenia          1960    NA      66.9    4.55  1.87e6 NA       Asia    Weste…\n 7 Aruba            1960    NA      65.7    4.82  5.42e4 NA       Americ… Carib…\n 8 Australia        1960    20.3    70.9    3.45  1.03e7  9.67e10 Oceania Austr…\n 9 Austria          1960    37.3    68.8    2.7   7.07e6  5.24e10 Europe  Weste…\n10 Azerbaijan       1960    NA      61.3    5.57  3.90e6 NA       Asia    Weste…\n# … with 10,535 more rows, and abbreviated variable names ¹​infant_mortality,\n#   ²​life_expectancy, ³​fertility, ⁴​population, ⁵​continent\n\n\nFilter all BUT Africa data\n\nafricadata <- Data %>%\nfilter(continent == \"Africa\")\n\nSubset and review new data\n\ndeadbabies <- africadata %>%\nselect(infant_mortality, life_expectancy)\n\nstr(deadbabies)\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\nsummary(deadbabies)\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226                     \n\npopafrica <- africadata %>%\nselect(population, life_expectancy)\n\nstr(popafrica)\n\n'data.frame':   2907 obs. of  2 variables:\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\nsummary(popafrica)\n\n   population        life_expectancy\n Min.   :    41538   Min.   :13.20  \n 1st Qu.:  1605232   1st Qu.:48.23  \n Median :  5570982   Median :53.98  \n Mean   : 12235961   Mean   :54.38  \n 3rd Qu.: 13888152   3rd Qu.:60.10  \n Max.   :182201962   Max.   :77.60  \n NA's   :51                         \n\n\nPlot Data Population Vs Life Exp\n\n#Pop on x-axis\nplot1c <- ggplot(data = africadata) + \n  geom_point(mapping = aes(x = population, y =     life_expectancy, color=country)) +\nscale_x_continuous(trans = 'log10') \n\nplot1y <- ggplot(data = africadata) + \n  geom_point(mapping = aes(x = population, y =     life_expectancy, color=year)) +\nscale_x_continuous(trans = 'log10') \n\nplot1c\n\nWarning: Removed 51 rows containing missing values (`geom_point()`).\n\n\n\n\nplot1y\n\nWarning: Removed 51 rows containing missing values (`geom_point()`).\n\n\n\n\n\nInf Mortality Vs Life Exp\n\nplot2y <- ggplot(data = africadata) + \n  geom_point(mapping = aes(x = life_expectancy, y =  infant_mortality, color=year)) +\nscale_x_continuous(trans = 'log10') \n\nplot2c <- ggplot(data = africadata) + \n  geom_point(mapping = aes(x = life_expectancy, y =  infant_mortality, color=country)) +\nscale_x_continuous(trans = 'log10') \n\nplot2c\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\nplot2y\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFinding all the NAs (ie the missing data)\n\nafricadata %>%\n  summarise(count = sum(is.na(infant_mortality)))\n\n  count\n1   226\n\nafricadata %>%\n  summarise(count = sum(is.na(life_expectancy))) \n\n  count\n1     0\n\nafricadata %>%\n  summarise(count = sum(is.na(population))) \n\n  count\n1    51\n\n\nNow Filter 2000 data from africadata\n\nafrica2000data <- africadata %>%\n  filter(year == '2000')\n\nPlot 2000 data 2000: Population Vs Life Exp\n\nplot3c <- ggplot(data = africa2000data) + \n  geom_point(mapping = aes(x = population, y = life_expectancy, color=country)) +\nscale_x_continuous(trans = 'log10') \n\nplot3c\n\n\n\n\n2000: Inf Mort Vs Life Exp\n\nplot4c <- ggplot(data = africa2000data) + \n  geom_point(mapping = aes(x = life_expectancy, y = infant_mortality, color=country))\n\nplot4c\n\n\n\n\nSimple Stats to Evaluate Data\n\nfit1 <- lm(infant_mortality ~ life_expectancy, africa2000data)\nfit2 <- lm(population ~ life_expectancy, africa2000data)\n\nsummary(fit1)\n\n\nCall:\nlm(formula = infant_mortality ~ life_expectancy, data = africa2000data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-67.262  -9.806  -1.891  12.460  52.285 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     219.0135    21.4781  10.197 1.05e-13 ***\nlife_expectancy  -2.4854     0.3769  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.55 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\nsummary(fit2)\n\n\nCall:\nlm(formula = population ~ life_expectancy, data = africa2000data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-18308728 -12957963  -6425955   2079794 107435285 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)\n(Intercept)      5074933   21193712   0.239    0.812\nlife_expectancy   187799     371938   0.505    0.616\n\nResidual standard error: 22250000 on 49 degrees of freedom\nMultiple R-squared:  0.005176,  Adjusted R-squared:  -0.01513 \nF-statistic: 0.2549 on 1 and 49 DF,  p-value: 0.6159\n\n\nVisualizing Stats 2000: Population Vs Life Exp\n\nggplot(africa2000data, aes(x = life_expectancy, y = infant_mortality)) + geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n2000: Inf Mort Vs Life Exp\n\nggplot(africa2000data, aes(x = life_expectancy, y = population)) + geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "dataanalysis_exercise.html",
    "href": "dataanalysis_exercise.html",
    "title": "Model4_DataWrangling",
    "section": "",
    "text": "Data originally acquired at:\nDHDS - Prevalence of Disability Status and Types by Demographic Groups, 2020 | Data | Centers for Disease Control and Prevention (cdc.gov)\nBrief Description:\nDisability and Health Data System (DHDS) is an online source of state-level data on adults with disabilities. Users can access information on six functional disability types: cognitive (serious difficulty concentrating, remembering or making decisions), hearing (serious difficulty hearing or deaf), mobility (serious difficulty walking or climbing stairs), vision (serious difficulty seeing), self-care (difficulty dressing or bathing) and independent living (difficulty doing errands alone).\n\n\n\nUpload raw data to R and install/load packages required to clean data.\n\n#always open it has a project!\n\n#install.packages(dslabs)\n#install.packages(tidyverse)\n#install.packages(here)\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.2.2\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\n##here command to construct a path the that file. Never make a hard path to the C drive, only relative paths.\n\n#import file\nraw <- read_csv(here('dataanalysis_exercise/data/rawDHDSdata.csv'))\n\nRows: 7168 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (19): LocationAbbr, LocationDesc, DataSource, Category, Indicator, Respo...\ndbl  (7): Year, Data_Value, Data_Value_Alt, Low_Confidence_Limit, High_Confi...\nlgl  (4): StratificationCategory2, Stratification2, StratificationCategoryID...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLook at what we have and make a tibble data frame.\n\nstr(raw)\n\nspc_tbl_ [7,168 × 30] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Year                      : num [1:7168] 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 ...\n $ LocationAbbr              : chr [1:7168] \"HI\" \"OH\" \"WV\" \"ME\" ...\n $ LocationDesc              : chr [1:7168] \"Hawaii\" \"Ohio\" \"West Virginia\" \"Maine\" ...\n $ DataSource                : chr [1:7168] \"BRFSS\" \"BRFSS\" \"BRFSS\" \"BRFSS\" ...\n $ Category                  : chr [1:7168] \"Disability Estimates\" \"Disability Estimates\" \"Disability Estimates\" \"Disability Estimates\" ...\n $ Indicator                 : chr [1:7168] \"Disability status and types among adults 18 years of age or older by veteran status\" \"Disability status and types among adults 18 years of age or older by veteran status\" \"Disability status and types among adults 18 years of age or older by veteran status\" \"Disability status and types among adults 18 years of age or older by veteran status\" ...\n $ Response                  : chr [1:7168] \"Veteran\" \"Veteran\" \"Veteran\" \"Non-Veteran\" ...\n $ Data_Value_Unit           : chr [1:7168] \"%\" \"%\" \"%\" \"%\" ...\n $ Data_Value_Type           : chr [1:7168] \"Age-adjusted Prevalence\" \"Age-adjusted Prevalence\" \"Age-adjusted Prevalence\" \"Age-adjusted Prevalence\" ...\n $ Data_Value                : num [1:7168] 8.9 11.9 33.4 4.2 3.4 12.3 74.9 NA 64.9 6.5 ...\n $ Data_Value_Alt            : num [1:7168] 8.9 11.9 33.4 4.2 3.4 12.3 74.9 NA 64.9 6.5 ...\n $ Data_Value_Footnote_Symbol: chr [1:7168] NA NA NA NA ...\n $ Data_Value_Footnote       : chr [1:7168] NA NA NA NA ...\n $ Low_Confidence_Limit      : num [1:7168] 6.9 9.9 28.1 3.6 2.9 9.4 73.1 NA 57.6 4.1 ...\n $ High_Confidence_Limit     : num [1:7168] 11.3 14.2 39.1 5 4.1 16.1 76.6 NA 71.5 10.2 ...\n $ Number                    : num [1:7168] 158 365 348 483 242 ...\n $ WeightedNumber            : num [1:7168] 20925 158777 73287 42424 259481 ...\n $ StratificationCategory1   : chr [1:7168] \"Disability Type\" \"Disability Type\" \"Disability Status\" \"Disability Type\" ...\n $ Stratification1           : chr [1:7168] \"Hearing Disability\" \"Mobility Disability\" \"Any Disability\" \"Vision Disability\" ...\n $ StratificationCategory2   : logi [1:7168] NA NA NA NA NA NA ...\n $ Stratification2           : logi [1:7168] NA NA NA NA NA NA ...\n $ CategoryID                : chr [1:7168] \"DISEST\" \"DISEST\" \"DISEST\" \"DISEST\" ...\n $ IndicatorID               : chr [1:7168] \"VETIND\" \"VETIND\" \"VETIND\" \"VETIND\" ...\n $ LocationID                : chr [1:7168] \"15\" \"39\" \"54\" \"23\" ...\n $ ResponseID                : chr [1:7168] \"VET1\" \"VET1\" \"VET1\" \"VET2\" ...\n $ DataValueTypeID           : chr [1:7168] \"AGEADJPREV\" \"AGEADJPREV\" \"AGEADJPREV\" \"AGEADJPREV\" ...\n $ StratificationCategoryID1 : chr [1:7168] \"DISTYPE\" \"DISTYPE\" \"DISSTAT\" \"DISTYPE\" ...\n $ StratificationID1         : chr [1:7168] \"HEARDIS\" \"MOBDIS\" \"DISABL\" \"VISDIS\" ...\n $ StratificationCategoryID2 : logi [1:7168] NA NA NA NA NA NA ...\n $ StratificationID2         : logi [1:7168] NA NA NA NA NA NA ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Year = col_double(),\n  ..   LocationAbbr = col_character(),\n  ..   LocationDesc = col_character(),\n  ..   DataSource = col_character(),\n  ..   Category = col_character(),\n  ..   Indicator = col_character(),\n  ..   Response = col_character(),\n  ..   Data_Value_Unit = col_character(),\n  ..   Data_Value_Type = col_character(),\n  ..   Data_Value = col_double(),\n  ..   Data_Value_Alt = col_double(),\n  ..   Data_Value_Footnote_Symbol = col_character(),\n  ..   Data_Value_Footnote = col_character(),\n  ..   Low_Confidence_Limit = col_double(),\n  ..   High_Confidence_Limit = col_double(),\n  ..   Number = col_double(),\n  ..   WeightedNumber = col_double(),\n  ..   StratificationCategory1 = col_character(),\n  ..   Stratification1 = col_character(),\n  ..   StratificationCategory2 = col_logical(),\n  ..   Stratification2 = col_logical(),\n  ..   CategoryID = col_character(),\n  ..   IndicatorID = col_character(),\n  ..   LocationID = col_character(),\n  ..   ResponseID = col_character(),\n  ..   DataValueTypeID = col_character(),\n  ..   StratificationCategoryID1 = col_character(),\n  ..   StratificationID1 = col_character(),\n  ..   StratificationCategoryID2 = col_logical(),\n  ..   StratificationID2 = col_logical()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\nsummary(raw)\n\n      Year      LocationAbbr       LocationDesc        DataSource       \n Min.   :2020   Length:7168        Length:7168        Length:7168       \n 1st Qu.:2020   Class :character   Class :character   Class :character  \n Median :2020   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2020                                                           \n 3rd Qu.:2020                                                           \n Max.   :2020                                                           \n                                                                        \n   Category          Indicator           Response         Data_Value_Unit   \n Length:7168        Length:7168        Length:7168        Length:7168       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n Data_Value_Type      Data_Value    Data_Value_Alt  Data_Value_Footnote_Symbol\n Length:7168        Min.   : 0.70   Min.   : 0.70   Length:7168               \n Class :character   1st Qu.: 5.40   1st Qu.: 5.40   Class :character          \n Mode  :character   Median :10.30   Median :10.30   Mode  :character          \n                    Mean   :20.38   Mean   :20.38                             \n                    3rd Qu.:23.70   3rd Qu.:23.70                             \n                    Max.   :94.80   Max.   :94.80                             \n                    NA's   :1695    NA's   :1695                              \n Data_Value_Footnote Low_Confidence_Limit High_Confidence_Limit\n Length:7168         Min.   : 0.40        Min.   : 1.20        \n Class :character    1st Qu.: 4.30        1st Qu.: 6.90        \n Mode  :character    Median : 8.20        Median :12.70        \n                     Mean   :17.96        Mean   :23.16        \n                     3rd Qu.:20.40        3rd Qu.:27.30        \n                     Max.   :89.80        Max.   :97.80        \n                     NA's   :1695         NA's   :1695         \n     Number       WeightedNumber      StratificationCategory1\n Min.   :     7   Min.   :      471   Length:7168            \n 1st Qu.:    93   1st Qu.:    33767   Class :character       \n Median :   257   Median :   120801   Mode  :character       \n Mean   :  1244   Mean   :   775135                          \n 3rd Qu.:   762   3rd Qu.:   418722                          \n Max.   :243399   Max.   :164671302                          \n NA's   :1695     NA's   :1695                               \n Stratification1    StratificationCategory2 Stratification2  CategoryID       \n Length:7168        Mode:logical            Mode:logical    Length:7168       \n Class :character   NA's:7168               NA's:7168       Class :character  \n Mode  :character                                           Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n IndicatorID         LocationID         ResponseID        DataValueTypeID   \n Length:7168        Length:7168        Length:7168        Length:7168       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n StratificationCategoryID1 StratificationID1  StratificationCategoryID2\n Length:7168               Length:7168        Mode:logical             \n Class :character          Class :character   NA's:7168                \n Mode  :character          Mode  :character                            \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n StratificationID2\n Mode:logical     \n NA's:7168        \n                  \n                  \n                  \n                  \n                  \n\nas.tibble(raw)\n\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n\n\n# A tibble: 7,168 × 30\n    Year Locat…¹ Locat…² DataS…³ Categ…⁴ Indic…⁵ Respo…⁶ Data_…⁷ Data_…⁸ Data_…⁹\n   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>     <dbl>\n 1  2020 HI      Hawaii  BRFSS   Disabi… Disabi… Veteran %       Age-ad…     8.9\n 2  2020 OH      Ohio    BRFSS   Disabi… Disabi… Veteran %       Age-ad…    11.9\n 3  2020 WV      West V… BRFSS   Disabi… Disabi… Veteran %       Age-ad…    33.4\n 4  2020 ME      Maine   BRFSS   Disabi… Disabi… Non-Ve… %       Age-ad…     4.2\n 5  2020 MI      Michig… BRFSS   Disabi… Disabi… Non-Ve… %       Age-ad…     3.4\n 6  2020 OH      Ohio    BRFSS   Disabi… Disabi… Veteran %       Age-ad…    12.3\n 7  2020 TX      Texas   BRFSS   Disabi… Disabi… Non-Ve… %       Age-ad…    74.9\n 8  2020 NH      New Ha… BRFSS   Disabi… Disabi… Veteran %       Age-ad…    NA  \n 9  2020 LA      Louisi… BRFSS   Disabi… Disabi… Veteran %       Age-ad…    64.9\n10  2020 AL      Alabama BRFSS   Disabi… Disabi… Veteran %       Age-ad…     6.5\n# … with 7,158 more rows, 20 more variables: Data_Value_Alt <dbl>,\n#   Data_Value_Footnote_Symbol <chr>, Data_Value_Footnote <chr>,\n#   Low_Confidence_Limit <dbl>, High_Confidence_Limit <dbl>, Number <dbl>,\n#   WeightedNumber <dbl>, StratificationCategory1 <chr>, Stratification1 <chr>,\n#   StratificationCategory2 <lgl>, Stratification2 <lgl>, CategoryID <chr>,\n#   IndicatorID <chr>, LocationID <chr>, ResponseID <chr>,\n#   DataValueTypeID <chr>, StratificationCategoryID1 <chr>, …\n\n\nWrangler data of interest. Goal is to have ~5 variables. Most interesting in this case would be: LocationDesc, Response (Age/Ethnicity/Veteran Status; will have to be split), WeightedNumber (An adjusted version of the crude number of respondents that reflects the number of persons with the attribute in the population.), Stratification 1 (which type of disability)\nNow we’ll put this data out:\n\ndisdata <- raw %>%\nselect(LocationAbbr, Response, WeightedNumber, Stratification1)\n\nstr(disdata)\n\ntibble [7,168 × 4] (S3: tbl_df/tbl/data.frame)\n $ LocationAbbr   : chr [1:7168] \"HI\" \"OH\" \"WV\" \"ME\" ...\n $ Response       : chr [1:7168] \"Veteran\" \"Veteran\" \"Veteran\" \"Non-Veteran\" ...\n $ WeightedNumber : num [1:7168] 20925 158777 73287 42424 259481 ...\n $ Stratification1: chr [1:7168] \"Hearing Disability\" \"Mobility Disability\" \"Any Disability\" \"Vision Disability\" ...\n\nas.tibble(disdata)\n\n# A tibble: 7,168 × 4\n   LocationAbbr Response    WeightedNumber Stratification1     \n   <chr>        <chr>                <dbl> <chr>               \n 1 HI           Veteran              20925 Hearing Disability  \n 2 OH           Veteran             158777 Mobility Disability \n 3 WV           Veteran              73287 Any Disability      \n 4 ME           Non-Veteran          42424 Vision Disability   \n 5 MI           Non-Veteran         259481 Vision Disability   \n 6 OH           Veteran              89980 Cognitive Disability\n 7 TX           Non-Veteran       13660252 No Disability       \n 8 NH           Veteran                 NA Self-care Disability\n 9 LA           Veteran             203697 No Disability       \n10 AL           Veteran              31424 Self-care Disability\n# … with 7,158 more rows\n\n\nLets now look at veterans vs non-veterans. We’ll pull out veterans then remove the “regions” from the data so there are only easily identifiable state abbreviations.\n\nvetdata <- disdata %>%\n  filter(Response == 'Veteran' | Response == 'Non-Veteran') %>%\n  filter(Stratification1 != 'No Disability') %>%\n  filter(LocationAbbr != 'HHS1') %>%\n   filter(LocationAbbr != 'HHS2') %>%\n   filter(LocationAbbr != 'HHS3') %>%\n   filter(LocationAbbr != 'HHS4') %>%\n   filter(LocationAbbr != 'HHS5') %>%\n   filter(LocationAbbr != 'HHS6') %>%\n   filter(LocationAbbr != 'HHS7') %>%\n   filter(LocationAbbr != 'HHS8') %>%\n   filter(LocationAbbr != 'HHS9') %>%\n   filter(LocationAbbr != 'HHS10')\n\ntibble(vetdata)\n\n# A tibble: 756 × 4\n   LocationAbbr Response    WeightedNumber Stratification1     \n   <chr>        <chr>                <dbl> <chr>               \n 1 HI           Veteran              20925 Hearing Disability  \n 2 OH           Veteran             158777 Mobility Disability \n 3 WV           Veteran              73287 Any Disability      \n 4 ME           Non-Veteran          42424 Vision Disability   \n 5 MI           Non-Veteran         259481 Vision Disability   \n 6 OH           Veteran              89980 Cognitive Disability\n 7 NH           Veteran                 NA Self-care Disability\n 8 AL           Veteran              31424 Self-care Disability\n 9 GU           Veteran               2102 Cognitive Disability\n10 DC           Veteran                 NA Hearing Disability  \n# … with 746 more rows\n\n\nThere are some gaps in the data now. Lets find them and remove them.\n\nvetdata2 <- drop_na(vetdata)\n\nas_factor(vetdata2$Stratification1)\n\n  [1] Hearing Disability            Mobility Disability          \n  [3] Any Disability                Vision Disability            \n  [5] Vision Disability             Cognitive Disability         \n  [7] Self-care Disability          Cognitive Disability         \n  [9] Any Disability                Self-care Disability         \n [11] Any Disability                Mobility Disability          \n [13] Vision Disability             Hearing Disability           \n [15] Hearing Disability            Any Disability               \n [17] Vision Disability             Self-care Disability         \n [19] Hearing Disability            Cognitive Disability         \n [21] Cognitive Disability          Self-care Disability         \n [23] Vision Disability             Hearing Disability           \n [25] Cognitive Disability          Hearing Disability           \n [27] Vision Disability             Hearing Disability           \n [29] Mobility Disability           Mobility Disability          \n [31] Cognitive Disability          Vision Disability            \n [33] Hearing Disability            Vision Disability            \n [35] Vision Disability             Hearing Disability           \n [37] Vision Disability             Any Disability               \n [39] Hearing Disability            Cognitive Disability         \n [41] Any Disability                Any Disability               \n [43] Vision Disability             Cognitive Disability         \n [45] Self-care Disability          Cognitive Disability         \n [47] Any Disability                Any Disability               \n [49] Any Disability                Vision Disability            \n [51] Any Disability                Any Disability               \n [53] Any Disability                Any Disability               \n [55] Vision Disability             Any Disability               \n [57] Any Disability                Any Disability               \n [59] Any Disability                Cognitive Disability         \n [61] Any Disability                Any Disability               \n [63] Any Disability                Mobility Disability          \n [65] Independent Living Disability Self-care Disability         \n [67] Mobility Disability           Any Disability               \n [69] Cognitive Disability          Independent Living Disability\n [71] Mobility Disability           Hearing Disability           \n [73] Independent Living Disability Cognitive Disability         \n [75] Independent Living Disability Self-care Disability         \n [77] Cognitive Disability          Cognitive Disability         \n [79] Cognitive Disability          Self-care Disability         \n [81] Any Disability                Mobility Disability          \n [83] Self-care Disability          Hearing Disability           \n [85] Hearing Disability            Hearing Disability           \n [87] Self-care Disability          Independent Living Disability\n [89] Hearing Disability            Independent Living Disability\n [91] Vision Disability             Mobility Disability          \n [93] Cognitive Disability          Mobility Disability          \n [95] Hearing Disability            Mobility Disability          \n [97] Mobility Disability           Independent Living Disability\n [99] Any Disability                Cognitive Disability         \n[101] Any Disability                Cognitive Disability         \n[103] Self-care Disability          Cognitive Disability         \n[105] Mobility Disability           Self-care Disability         \n[107] Independent Living Disability Independent Living Disability\n[109] Vision Disability             Mobility Disability          \n[111] Self-care Disability          Any Disability               \n[113] Vision Disability             Independent Living Disability\n[115] Any Disability                Vision Disability            \n[117] Independent Living Disability Hearing Disability           \n[119] Hearing Disability            Cognitive Disability         \n[121] Vision Disability             Mobility Disability          \n[123] Hearing Disability            Vision Disability            \n[125] Any Disability                Self-care Disability         \n[127] Vision Disability             Cognitive Disability         \n[129] Any Disability                Mobility Disability          \n[131] Independent Living Disability Self-care Disability         \n[133] Vision Disability             Independent Living Disability\n[135] Cognitive Disability          Self-care Disability         \n[137] Independent Living Disability Cognitive Disability         \n[139] Mobility Disability           Independent Living Disability\n[141] Vision Disability             Independent Living Disability\n[143] Any Disability                Mobility Disability          \n[145] Hearing Disability            Independent Living Disability\n[147] Vision Disability             Hearing Disability           \n[149] Hearing Disability            Hearing Disability           \n[151] Hearing Disability            Cognitive Disability         \n[153] Independent Living Disability Cognitive Disability         \n[155] Self-care Disability          Any Disability               \n[157] Vision Disability             Mobility Disability          \n[159] Hearing Disability            Mobility Disability          \n[161] Hearing Disability            Cognitive Disability         \n[163] Hearing Disability            Cognitive Disability         \n[165] Independent Living Disability Vision Disability            \n[167] Self-care Disability          Independent Living Disability\n[169] Cognitive Disability          Self-care Disability         \n[171] Any Disability                Vision Disability            \n[173] Mobility Disability           Hearing Disability           \n[175] Mobility Disability           Independent Living Disability\n[177] Mobility Disability           Self-care Disability         \n[179] Hearing Disability            Hearing Disability           \n[181] Independent Living Disability Independent Living Disability\n[183] Self-care Disability          Mobility Disability          \n[185] Vision Disability             Hearing Disability           \n[187] Cognitive Disability          Cognitive Disability         \n[189] Hearing Disability            Hearing Disability           \n[191] Any Disability                Hearing Disability           \n[193] Vision Disability             Mobility Disability          \n[195] Cognitive Disability          Mobility Disability          \n[197] Cognitive Disability          Self-care Disability         \n[199] Independent Living Disability Self-care Disability         \n[201] Self-care Disability          Hearing Disability           \n[203] Cognitive Disability          Any Disability               \n[205] Self-care Disability          Independent Living Disability\n[207] Independent Living Disability Self-care Disability         \n[209] Self-care Disability          Independent Living Disability\n[211] Hearing Disability            Hearing Disability           \n[213] Independent Living Disability Vision Disability            \n[215] Any Disability                Mobility Disability          \n[217] Self-care Disability          Cognitive Disability         \n[219] Vision Disability             Hearing Disability           \n[221] Any Disability                Vision Disability            \n[223] Vision Disability             Mobility Disability          \n[225] Mobility Disability           Vision Disability            \n[227] Hearing Disability            Self-care Disability         \n[229] Self-care Disability          Self-care Disability         \n[231] Independent Living Disability Cognitive Disability         \n[233] Hearing Disability            Cognitive Disability         \n[235] Vision Disability             Mobility Disability          \n[237] Independent Living Disability Independent Living Disability\n[239] Vision Disability             Mobility Disability          \n[241] Independent Living Disability Self-care Disability         \n[243] Mobility Disability           Cognitive Disability         \n[245] Hearing Disability            Cognitive Disability         \n[247] Mobility Disability           Independent Living Disability\n[249] Hearing Disability            Mobility Disability          \n[251] Independent Living Disability Mobility Disability          \n[253] Self-care Disability          Vision Disability            \n[255] Vision Disability             Independent Living Disability\n[257] Mobility Disability           Self-care Disability         \n[259] Vision Disability             Cognitive Disability         \n[261] Independent Living Disability Cognitive Disability         \n[263] Hearing Disability            Independent Living Disability\n[265] Cognitive Disability          Hearing Disability           \n[267] Vision Disability             Independent Living Disability\n[269] Cognitive Disability          Self-care Disability         \n[271] Cognitive Disability          Mobility Disability          \n[273] Independent Living Disability Mobility Disability          \n[275] Cognitive Disability          Mobility Disability          \n[277] Cognitive Disability          Mobility Disability          \n[279] Cognitive Disability          Mobility Disability          \n[281] Cognitive Disability          Mobility Disability          \n[283] Vision Disability             Mobility Disability          \n[285] Mobility Disability           Cognitive Disability         \n[287] Mobility Disability           Independent Living Disability\n[289] Cognitive Disability          Self-care Disability         \n[291] Vision Disability             Cognitive Disability         \n[293] Mobility Disability           Any Disability               \n[295] Hearing Disability            Any Disability               \n[297] Independent Living Disability Hearing Disability           \n[299] Vision Disability             Self-care Disability         \n[301] Cognitive Disability          Hearing Disability           \n[303] Independent Living Disability Cognitive Disability         \n[305] Self-care Disability          Vision Disability            \n[307] Mobility Disability           Cognitive Disability         \n[309] Independent Living Disability Self-care Disability         \n[311] Self-care Disability          Mobility Disability          \n[313] Independent Living Disability Independent Living Disability\n[315] Independent Living Disability Hearing Disability           \n[317] Mobility Disability           Vision Disability            \n[319] Cognitive Disability          Vision Disability            \n[321] Any Disability                Any Disability               \n[323] Independent Living Disability Self-care Disability         \n[325] Hearing Disability            Cognitive Disability         \n[327] Mobility Disability           Hearing Disability           \n[329] Vision Disability             Self-care Disability         \n[331] Mobility Disability           Self-care Disability         \n[333] Cognitive Disability          Independent Living Disability\n[335] Vision Disability             Mobility Disability          \n[337] Any Disability                Self-care Disability         \n[339] Hearing Disability            Self-care Disability         \n[341] Independent Living Disability Hearing Disability           \n[343] Any Disability                Any Disability               \n[345] Hearing Disability            Cognitive Disability         \n[347] Hearing Disability            Any Disability               \n[349] Mobility Disability           Any Disability               \n[351] Vision Disability             Vision Disability            \n[353] Independent Living Disability Any Disability               \n[355] Cognitive Disability          Hearing Disability           \n[357] Mobility Disability           Self-care Disability         \n[359] Cognitive Disability          Cognitive Disability         \n[361] Independent Living Disability Self-care Disability         \n[363] Independent Living Disability Vision Disability            \n[365] Mobility Disability           Mobility Disability          \n[367] Any Disability                Independent Living Disability\n[369] Vision Disability             Mobility Disability          \n[371] Hearing Disability            Hearing Disability           \n[373] Vision Disability             Hearing Disability           \n[375] Vision Disability             Cognitive Disability         \n[377] Any Disability                Hearing Disability           \n[379] Self-care Disability          Cognitive Disability         \n[381] Independent Living Disability Any Disability               \n[383] Mobility Disability           Vision Disability            \n[385] Any Disability                Mobility Disability          \n[387] Hearing Disability            Hearing Disability           \n[389] Mobility Disability           Independent Living Disability\n[391] Independent Living Disability Cognitive Disability         \n[393] Self-care Disability          Vision Disability            \n[395] Mobility Disability           Vision Disability            \n[397] Independent Living Disability Vision Disability            \n[399] Cognitive Disability          Self-care Disability         \n[401] Any Disability                Mobility Disability          \n[403] Mobility Disability           Self-care Disability         \n[405] Hearing Disability            Mobility Disability          \n[407] Any Disability                Cognitive Disability         \n[409] Mobility Disability           Cognitive Disability         \n[411] Any Disability                Hearing Disability           \n[413] Hearing Disability            Independent Living Disability\n[415] Mobility Disability           Independent Living Disability\n[417] Self-care Disability          Independent Living Disability\n[419] Mobility Disability           Any Disability               \n[421] Independent Living Disability Mobility Disability          \n[423] Cognitive Disability          Any Disability               \n[425] Vision Disability             Mobility Disability          \n[427] Mobility Disability           Hearing Disability           \n[429] Independent Living Disability Independent Living Disability\n[431] Hearing Disability            Mobility Disability          \n[433] Vision Disability             Any Disability               \n[435] Cognitive Disability          Hearing Disability           \n[437] Hearing Disability            Any Disability               \n[439] Hearing Disability            Independent Living Disability\n[441] Cognitive Disability          Hearing Disability           \n[443] Mobility Disability           Independent Living Disability\n[445] Any Disability                Mobility Disability          \n[447] Cognitive Disability          Self-care Disability         \n[449] Cognitive Disability          Mobility Disability          \n[451] Vision Disability             Any Disability               \n[453] Cognitive Disability          Independent Living Disability\n[455] Self-care Disability          Mobility Disability          \n[457] Mobility Disability           Cognitive Disability         \n[459] Independent Living Disability Vision Disability            \n[461] Hearing Disability            Mobility Disability          \n[463] Cognitive Disability          Self-care Disability         \n[465] Self-care Disability          Mobility Disability          \n[467] Cognitive Disability          Independent Living Disability\n[469] Vision Disability             Any Disability               \n[471] Vision Disability             Self-care Disability         \n[473] Cognitive Disability          Self-care Disability         \n[475] Self-care Disability          Cognitive Disability         \n[477] Cognitive Disability          Independent Living Disability\n[479] Mobility Disability           Any Disability               \n[481] Mobility Disability           Hearing Disability           \n[483] Any Disability                Independent Living Disability\n[485] Hearing Disability            Any Disability               \n[487] Independent Living Disability Vision Disability            \n[489] Any Disability                Independent Living Disability\n[491] Self-care Disability          Vision Disability            \n[493] Hearing Disability            Hearing Disability           \n[495] Any Disability                Any Disability               \n[497] Mobility Disability           Self-care Disability         \n[499] Any Disability                Vision Disability            \n[501] Vision Disability             Cognitive Disability         \n[503] Any Disability                Vision Disability            \n[505] Independent Living Disability Self-care Disability         \n[507] Vision Disability             Mobility Disability          \n[509] Cognitive Disability          Independent Living Disability\n[511] Any Disability                Self-care Disability         \n[513] Mobility Disability           Mobility Disability          \n[515] Any Disability                Mobility Disability          \n[517] Independent Living Disability Any Disability               \n[519] Self-care Disability          Any Disability               \n[521] Vision Disability             Hearing Disability           \n[523] Cognitive Disability          Mobility Disability          \n[525] Mobility Disability           Any Disability               \n[527] Cognitive Disability          Any Disability               \n[529] Independent Living Disability Independent Living Disability\n[531] Hearing Disability            Hearing Disability           \n[533] Mobility Disability           Any Disability               \n[535] Vision Disability             Cognitive Disability         \n[537] Independent Living Disability Cognitive Disability         \n[539] Any Disability                Cognitive Disability         \n[541] Mobility Disability           Mobility Disability          \n[543] Independent Living Disability Cognitive Disability         \n[545] Cognitive Disability          Self-care Disability         \n[547] Independent Living Disability Hearing Disability           \n[549] Vision Disability             Self-care Disability         \n[551] Mobility Disability           Self-care Disability         \n[553] Cognitive Disability          Independent Living Disability\n[555] Hearing Disability            Any Disability               \n[557] Independent Living Disability Hearing Disability           \n[559] Any Disability                Mobility Disability          \n[561] Vision Disability             Vision Disability            \n[563] Any Disability                Any Disability               \n[565] Any Disability                Mobility Disability          \n[567] Vision Disability             Any Disability               \n[569] Any Disability                Self-care Disability         \n[571] Self-care Disability          Any Disability               \n[573] Any Disability                Cognitive Disability         \n[575] Hearing Disability            Any Disability               \n[577] Any Disability                Vision Disability            \n[579] Hearing Disability            Hearing Disability           \n[581] Vision Disability             Cognitive Disability         \n[583] Mobility Disability           Independent Living Disability\n[585] Cognitive Disability          Self-care Disability         \n[587] Hearing Disability            Vision Disability            \n[589] Independent Living Disability Mobility Disability          \n[591] Vision Disability             Cognitive Disability         \n[593] Cognitive Disability          Any Disability               \n[595] Hearing Disability            Self-care Disability         \n[597] Hearing Disability            Any Disability               \n[599] Hearing Disability            Mobility Disability          \n[601] Self-care Disability          Hearing Disability           \n[603] Vision Disability             Vision Disability            \n[605] Hearing Disability            Any Disability               \n[607] Any Disability                Any Disability               \n[609] Self-care Disability          Vision Disability            \n[611] Independent Living Disability Any Disability               \n[613] Any Disability                Self-care Disability         \n[615] Independent Living Disability Hearing Disability           \n[617] Independent Living Disability Vision Disability            \n[619] Mobility Disability           Self-care Disability         \n[621] Cognitive Disability          Hearing Disability           \n[623] Hearing Disability            Any Disability               \n[625] Hearing Disability            Hearing Disability           \n[627] Hearing Disability            Any Disability               \n[629] Independent Living Disability Self-care Disability         \n[631] Vision Disability             Cognitive Disability         \n[633] Hearing Disability            Vision Disability            \n[635] Any Disability                Self-care Disability         \n[637] Vision Disability             Independent Living Disability\n[639] Cognitive Disability          Self-care Disability         \n[641] Mobility Disability           Self-care Disability         \n[643] Mobility Disability           Cognitive Disability         \n[645] Mobility Disability           Independent Living Disability\n[647] Any Disability                Self-care Disability         \n[649] Hearing Disability            Independent Living Disability\n[651] Independent Living Disability Vision Disability            \n[653] Vision Disability             Mobility Disability          \n[655] Self-care Disability          Vision Disability            \n[657] Independent Living Disability Mobility Disability          \n[659] Cognitive Disability          Mobility Disability          \n[661] Self-care Disability          Any Disability               \n[663] Any Disability                Any Disability               \n[665] Any Disability                Independent Living Disability\n[667] Any Disability                Any Disability               \n[669] Hearing Disability            Mobility Disability          \n[671] Vision Disability             Independent Living Disability\n[673] Cognitive Disability          Vision Disability            \n[675] Mobility Disability           Any Disability               \n[677] Any Disability                Hearing Disability           \n[679] Hearing Disability            Cognitive Disability         \n[681] Self-care Disability          Any Disability               \n[683] Cognitive Disability          Independent Living Disability\n[685] Any Disability                Independent Living Disability\n[687] Independent Living Disability Hearing Disability           \n[689] Mobility Disability           Cognitive Disability         \n[691] Hearing Disability            Self-care Disability         \n[693] Cognitive Disability          Mobility Disability          \n[695] Self-care Disability          Mobility Disability          \n[697] Cognitive Disability          Hearing Disability           \n[699] Cognitive Disability          Vision Disability            \n[701] Hearing Disability            Independent Living Disability\n7 Levels: Hearing Disability Mobility Disability ... Independent Living Disability\n\nas_factor(vetdata2$LocationAbbr)\n\n  [1] HI OH WV ME MI OH AL GU MO KS NY AR OH IA WY MS MD HI MD NE ID FL MS GA MI\n [26] AL AK ID LA NJ VT OK MT PR OK WA VT IN ID OK NE VT LA IL KY TN AL AR AK ID\n [51] AZ US CA CO AR CA AZ AR CO MO US AL AK MS MD TN KS SC CO NV KS LA MD AL UT\n [76] MT TX CT NE ME ND TX AR AZ NY WV DC GA KY IL WY NH MA FL NV SC AL CA DC NY\n[101] SD KS OK AZ GU HI NJ VA AL OR PR WI NY MN KS PA KS PA UT WV WV NE MI MS FL\n[126] NJ KS LA NC HI NY IL DC WV OR VA MO VT MA AL SC FL KY CO OK IN PA PA PR MS\n[151] AZ AR OK ID NY WY GU IL US MO MD DC IL MN TN CT WV MT CT MA TN NV VT ND ME\n[176] ID WV CO CA SC PR DE MO NY UT MT ME NH WA SC DE LA WI SD NJ NY RI ND OK LA\n[201] TX CA NC NM OR NH PR WY NE WY VT MS CO CA IA AK WV VA MT TN MN TN NC WV KY\n[226] UT NM NY VT AZ NY US DC WI GA IN IL AL WA ND LA KS TX SD OK MO WY HI PR NE\n[251] WV FL AL NM DC DC DE NH SC IA AZ AK MI KS GA CT US SC TX IN ND OK MS VT CA\n[276] MN NH MD GA SD RI IL MT MO PR MN NH NH WY NE IA KY CA RI KS CT TX NE GA SC\n[301] MD WI ND OK MD NH RI NM WY MS OH NC LA OR NE TX HI TN MI VT WA IN AZ GA NC\n[326] PR VA TN KY CA AZ WA WA MT SD WI HI MS OR FL HI RI MD OH ND PA MN ID MI MN\n[351] MO PR TN ME PR WY DE NM IA US NC SC WA CO PA CA PR MS NC TN AR NM RI FL HI\n[376] WI DE KS CT MD IN IA MT WA NJ GA VT NH AK CO ME CA TX MN KY AZ AR IL NC VA\n[401] NM CT US OR AL ID NV DE PR MT MI IN ME MA IA NM MI VT OK UT SC UT MT PA NH\n[426] MD WI NC DC IA CO CT NE RI WA TX DE CT NE US LA IN NV OH WA NM AZ US HI RI\n[451] TX VA NM VA OH TN NC SC OR KY MA MT FL UT ID GA MS TX AK OK DE IA TN WI MT\n[476] NV UT AK WA MA MI SD GA GA OH TX KY OR NH GU DE ND MO WI LA MI PA NC GU WY\n[501] IA KY OR US WI TN FL MN PA NE IL GA NJ DC UT AZ CT DC AK WI MN GU GU US DC\n[526] SD IN KS ID AR ME FL IA NJ HI UT RI OH NE DE OR VA MO NV IL KY ME AR IN MN\n[551] GU UT MS MI VA ID WA MN VT NV CO MO PR ME ND LA NJ WV SC AR NV HI MS WY RI\n[576] OH MD ME HI KY VA MA OH PA CO ME NJ MA MN UT AR SC ND MT AK PA OR TX UT ID\n[601] IN GU VA OH MO TN IL LA WA NY AK GU GA NC DE NJ CT KS AR CO WV VA US NY IL\n[626] IA SD OR NC PA AL ME NV FL MO SD WV MI AR MA ND PR ME NY WY GU NH OK OH KY\n[651] PA OR NE IN AZ TX CA AL NJ MS US PA KY FL VA US MA WY NY WA GU FL KS IN CO\n[676] NV NC MA DE FL RI OK AL UT MT SD OH WV NM OR AK MO VA MA IA SC HI CO IN ID\n[701] GA IA\n54 Levels: HI OH WV ME MI AL GU MO KS NY AR IA WY MS MD NE ID FL GA AK ... NM\n\nas_factor(vetdata2$Response)\n\n  [1] Veteran     Veteran     Veteran     Non-Veteran Non-Veteran Veteran    \n  [7] Veteran     Veteran     Veteran     Veteran     Veteran     Veteran    \n [13] Non-Veteran Non-Veteran Veteran     Veteran     Non-Veteran Veteran    \n [19] Veteran     Veteran     Non-Veteran Veteran     Veteran     Non-Veteran\n [25] Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n [31] Veteran     Veteran     Veteran     Veteran     Non-Veteran Veteran    \n [37] Non-Veteran Non-Veteran Veteran     Veteran     Veteran     Non-Veteran\n [43] Non-Veteran Veteran     Veteran     Veteran     Non-Veteran Veteran    \n [49] Veteran     Non-Veteran Non-Veteran Veteran     Veteran     Veteran    \n [55] Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran    \n [61] Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran\n [67] Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran\n [73] Non-Veteran Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n [79] Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran\n [85] Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran    \n [91] Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran\n [97] Non-Veteran Non-Veteran Veteran     Non-Veteran Veteran     Veteran    \n[103] Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran\n[109] Veteran     Veteran     Non-Veteran Veteran     Veteran     Veteran    \n[115] Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran\n[121] Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran\n[127] Veteran     Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran\n[133] Non-Veteran Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran\n[139] Veteran     Non-Veteran Non-Veteran Veteran     Veteran     Veteran    \n[145] Veteran     Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran\n[151] Veteran     Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran\n[157] Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran\n[163] Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n[169] Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran    \n[175] Veteran     Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran\n[181] Veteran     Veteran     Veteran     Veteran     Veteran     Non-Veteran\n[187] Non-Veteran Non-Veteran Non-Veteran Veteran     Veteran     Veteran    \n[193] Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran\n[199] Non-Veteran Non-Veteran Veteran     Veteran     Veteran     Veteran    \n[205] Veteran     Veteran     Non-Veteran Non-Veteran Veteran     Veteran    \n[211] Veteran     Veteran     Veteran     Non-Veteran Veteran     Veteran    \n[217] Veteran     Non-Veteran Veteran     Non-Veteran Veteran     Veteran    \n[223] Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran    \n[229] Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran    \n[235] Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran\n[241] Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran Non-Veteran\n[247] Non-Veteran Veteran     Non-Veteran Veteran     Veteran     Non-Veteran\n[253] Non-Veteran Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran\n[259] Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran     Veteran    \n[265] Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran\n[271] Non-Veteran Non-Veteran Non-Veteran Veteran     Veteran     Veteran    \n[277] Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran Veteran    \n[283] Non-Veteran Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran\n[289] Non-Veteran Non-Veteran Non-Veteran Non-Veteran Non-Veteran Veteran    \n[295] Veteran     Veteran     Veteran     Veteran     Veteran     Non-Veteran\n[301] Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran Veteran    \n[307] Veteran     Veteran     Non-Veteran Non-Veteran Veteran     Veteran    \n[313] Veteran     Veteran     Veteran     Veteran     Veteran     Non-Veteran\n[319] Non-Veteran Veteran     Veteran     Veteran     Veteran     Non-Veteran\n[325] Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran\n[331] Non-Veteran Non-Veteran Veteran     Veteran     Non-Veteran Veteran    \n[337] Veteran     Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran\n[343] Non-Veteran Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n[349] Non-Veteran Non-Veteran Non-Veteran Non-Veteran Veteran     Veteran    \n[355] Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran     Veteran    \n[361] Non-Veteran Veteran     Non-Veteran Veteran     Veteran     Veteran    \n[367] Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran Veteran    \n[373] Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran\n[379] Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran    \n[385] Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n[391] Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n[397] Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran\n[403] Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n[409] Veteran     Veteran     Veteran     Veteran     Non-Veteran Non-Veteran\n[415] Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran\n[421] Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran Veteran    \n[427] Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran Veteran    \n[433] Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran\n[439] Non-Veteran Non-Veteran Non-Veteran Non-Veteran Non-Veteran Veteran    \n[445] Non-Veteran Veteran     Non-Veteran Veteran     Veteran     Non-Veteran\n[451] Veteran     Veteran     Non-Veteran Veteran     Non-Veteran Veteran    \n[457] Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran Veteran    \n[463] Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran\n[469] Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran\n[475] Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran\n[481] Veteran     Non-Veteran Veteran     Veteran     Veteran     Veteran    \n[487] Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran Non-Veteran\n[493] Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran\n[499] Veteran     Non-Veteran Veteran     Veteran     Non-Veteran Veteran    \n[505] Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran\n[511] Non-Veteran Veteran     Veteran     Non-Veteran Veteran     Veteran    \n[517] Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran     Veteran    \n[523] Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran Non-Veteran\n[529] Veteran     Non-Veteran Veteran     Non-Veteran Non-Veteran Non-Veteran\n[535] Non-Veteran Veteran     Non-Veteran Non-Veteran Non-Veteran Veteran    \n[541] Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran Non-Veteran\n[547] Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran\n[553] Non-Veteran Veteran     Veteran     Veteran     Veteran     Veteran    \n[559] Veteran     Veteran     Non-Veteran Veteran     Veteran     Non-Veteran\n[565] Veteran     Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n[571] Non-Veteran Non-Veteran Non-Veteran Veteran     Veteran     Non-Veteran\n[577] Veteran     Veteran     Non-Veteran Veteran     Non-Veteran Veteran    \n[583] Non-Veteran Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran\n[589] Non-Veteran Veteran     Veteran     Non-Veteran Veteran     Veteran    \n[595] Veteran     Veteran     Non-Veteran Non-Veteran Veteran     Veteran    \n[601] Veteran     Non-Veteran Veteran     Veteran     Veteran     Veteran    \n[607] Veteran     Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran\n[613] Non-Veteran Veteran     Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n[619] Non-Veteran Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran\n[625] Non-Veteran Veteran     Veteran     Veteran     Veteran     Non-Veteran\n[631] Non-Veteran Veteran     Veteran     Veteran     Non-Veteran Non-Veteran\n[637] Non-Veteran Non-Veteran Veteran     Non-Veteran Veteran     Veteran    \n[643] Non-Veteran Veteran     Veteran     Non-Veteran Veteran     Veteran    \n[649] Non-Veteran Veteran     Veteran     Non-Veteran Non-Veteran Veteran    \n[655] Veteran     Non-Veteran Veteran     Veteran     Veteran     Veteran    \n[661] Non-Veteran Non-Veteran Non-Veteran Non-Veteran Non-Veteran Veteran    \n[667] Veteran     Veteran     Non-Veteran Non-Veteran Veteran     Non-Veteran\n[673] Non-Veteran Non-Veteran Non-Veteran Veteran     Non-Veteran Veteran    \n[679] Non-Veteran Veteran     Non-Veteran Veteran     Non-Veteran Veteran    \n[685] Non-Veteran Non-Veteran Non-Veteran Non-Veteran Non-Veteran Non-Veteran\n[691] Non-Veteran Non-Veteran Veteran     Non-Veteran Non-Veteran Veteran    \n[697] Non-Veteran Veteran     Veteran     Veteran     Veteran     Veteran    \nLevels: Veteran Non-Veteran\n\ntibble(vetdata2)\n\n# A tibble: 702 × 4\n   LocationAbbr Response    WeightedNumber Stratification1     \n   <chr>        <chr>                <dbl> <chr>               \n 1 HI           Veteran              20925 Hearing Disability  \n 2 OH           Veteran             158777 Mobility Disability \n 3 WV           Veteran              73287 Any Disability      \n 4 ME           Non-Veteran          42424 Vision Disability   \n 5 MI           Non-Veteran         259481 Vision Disability   \n 6 OH           Veteran              89980 Cognitive Disability\n 7 AL           Veteran              31424 Self-care Disability\n 8 GU           Veteran               2102 Cognitive Disability\n 9 MO           Veteran             223953 Any Disability      \n10 KS           Veteran              10746 Self-care Disability\n# … with 692 more rows\n\n\nNow that the data is cleaner we can make sum graphs and perform some simple statistics.\n(Possible directions of interest include “Does veteran status predispose to a certain disability”, “Are certain disabilities more common in specific states”, etc.)\nTo be continued…..\n##This section added by Vijay Panthayi (Wrangling and Exploring the Data)\nFirst, we are going to save the cleaned data into an Rds file\n\n#saving the cleaned data as an rds file\n#it appears that vetdata2 is the final, clean data \nvetdata2 %>% saveRDS(here::here(\"vetdata2.rds\"))\n\nNext, we are going to load the Rds file which previously was made of the cleaned data. Loading the data under “vetdata_clean”.\n\n#loading the vetdata2.rds file\nvetdata_clean <- readRDS(here(\"vetdata2.rds\"))\nglimpse(vetdata_clean)\n\nRows: 702\nColumns: 4\n$ LocationAbbr    <chr> \"HI\", \"OH\", \"WV\", \"ME\", \"MI\", \"OH\", \"AL\", \"GU\", \"MO\", …\n$ Response        <chr> \"Veteran\", \"Veteran\", \"Veteran\", \"Non-Veteran\", \"Non-V…\n$ WeightedNumber  <dbl> 20925, 158777, 73287, 42424, 259481, 89980, 31424, 210…\n$ Stratification1 <chr> \"Hearing Disability\", \"Mobility Disability\", \"Any Disa…\n\n\nNow that we have loaded the cleaned data, we can explore the previously mentioned interest of “Does veteran status predispose to a certain disability?”.\nTo do this, we will first grab all the data where the response is “veteran” and then create a bar graph with each stratification to visually see which disability correlates most with being a veteran according to the data.\n\n#create a subset data set of only the observations where the Response variable was \"Veteran\"\nvetdata_clean_veteran <- subset(vetdata_clean, vetdata_clean$Response == \"Veteran\")\nglimpse (vetdata_clean_veteran)\n\nRows: 325\nColumns: 4\n$ LocationAbbr    <chr> \"HI\", \"OH\", \"WV\", \"OH\", \"AL\", \"GU\", \"MO\", \"KS\", \"NY\", …\n$ Response        <chr> \"Veteran\", \"Veteran\", \"Veteran\", \"Veteran\", \"Veteran\",…\n$ WeightedNumber  <dbl> 20925, 158777, 73287, 89980, 31424, 2102, 223953, 1074…\n$ Stratification1 <chr> \"Hearing Disability\", \"Mobility Disability\", \"Any Disa…\n\n#create a bar graph of the different disabilities\ncounts <- table(vetdata_clean_veteran$Stratification1)\npar(mar = c(5,4,4,2) + 0.1)\nbarplot(counts, main = \"Disability Distribution Among Veterans\", xlab = \"Disability Type\", \n                  ylab = \"Count\", col=rainbow(20), las=2, ylim = c(0,60))\n\n\n\n#confirm the number of bars equals the number of unique entries for \"Stratification1\" variable\nunique(vetdata_clean_veteran$Stratification1)\n\n[1] \"Hearing Disability\"            \"Mobility Disability\"          \n[3] \"Any Disability\"                \"Cognitive Disability\"         \n[5] \"Self-care Disability\"          \"Vision Disability\"            \n[7] \"Independent Living Disability\"\n\n\nIt appears that Any and Mobility disabilities are about equivalent at count as the highest. Self-Care disability appears to be the lowest."
  },
  {
    "objectID": "fluanalysis/code/exploration.html",
    "href": "fluanalysis/code/exploration.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Flu Analysis: Exploration\n\nLoad the data and packages:\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(ggplot2)\n\ndata <- readRDS(here('fluanalysis/data/SypAct_clean.rds'))\ntibble(data) # to get a look at the data\n\n# A tibble: 730 × 26\n   SwollenLymph…¹ Chest…² Chill…³ Nasal…⁴ Sneeze Fatigue Subje…⁵ Heada…⁶ Weakn…⁷\n   <fct>          <fct>   <fct>   <fct>   <fct>  <fct>   <fct>   <fct>   <fct>  \n 1 Yes            No      No      No      No     Yes     Yes     Yes     Mild   \n 2 Yes            Yes     No      Yes     No     Yes     Yes     Yes     Severe \n 3 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 4 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 5 Yes            No      Yes     No      No     Yes     Yes     Yes     Modera…\n 6 No             No      Yes     No      Yes    Yes     Yes     Yes     Modera…\n 7 No             No      Yes     No      No     Yes     Yes     No      Mild   \n 8 No             Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 9 Yes            Yes     Yes     Yes     No     Yes     Yes     Yes     Modera…\n10 No             Yes     No      Yes     No     Yes     No      Yes     Modera…\n# … with 720 more rows, 17 more variables: CoughIntensity <fct>, Myalgia <fct>,\n#   RunnyNose <fct>, AbPain <fct>, ChestPain <fct>, Diarrhea <fct>,\n#   EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>, EarPn <fct>,\n#   Pharyngitis <fct>, Breathless <fct>, ToothPn <fct>, Vomit <fct>,\n#   Wheeze <fct>, BodyTemp <dbl>, and abbreviated variable names\n#   ¹​SwollenLymphNodes, ²​ChestCongestion, ³​ChillsSweats, ⁴​NasalCongestion,\n#   ⁵​SubjectiveFever, ⁶​Headache, ⁷​Weakness\n\nstr(data)\n\n'data.frame':   730 obs. of  26 variables:\n $ SwollenLymphNodes: Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"Swollen Lymph Nodes\"\n $ ChestCongestion  : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Chest Congestion\"\n $ ChillsSweats     : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 2 2 2 1 ...\n  ..- attr(*, \"label\")= chr \"Chills/Sweats\"\n $ NasalCongestion  : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Nasal Congestion\"\n $ Sneeze           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 1 2 1 2 1 1 ...\n  ..- attr(*, \"label\")= chr \"Sneeze\"\n $ Fatigue          : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Fatigue\"\n $ SubjectiveFever  : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 1 ...\n  ..- attr(*, \"label\")= chr \"Subjective Fever\"\n $ Headache         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Headache\"\n $ Weakness         : Factor w/ 4 levels \"None\",\"Mild\",..: 2 4 4 4 3 3 2 4 3 3 ...\n $ CoughIntensity   : Factor w/ 4 levels \"None\",\"Mild\",..: 4 4 2 3 1 3 4 3 3 3 ...\n  ..- attr(*, \"label\")= chr \"Cough Severity\"\n $ Myalgia          : Factor w/ 4 levels \"None\",\"Mild\",..: 2 4 4 4 2 3 2 4 3 2 ...\n $ RunnyNose        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 1 1 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Runny Nose\"\n $ AbPain           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Abdominal Pain\"\n $ ChestPain        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Chest Pain\"\n $ Diarrhea         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 2 1 1 1 1 ...\n $ EyePn            : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Eye Pain\"\n $ Insomnia         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Sleeplessness\"\n $ ItchyEye         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Itchy Eyes\"\n $ Nausea           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 1 1 2 2 ...\n $ EarPn            : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Ear Pain\"\n $ Pharyngitis      : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Sore Throat\"\n $ Breathless       : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 2 1 1 1 2 ...\n  ..- attr(*, \"label\")= chr \"Breathlessness\"\n $ ToothPn          : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"Tooth Pain\"\n $ Vomit            : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Vomiting\"\n $ Wheeze           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 2 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Wheezing\"\n $ BodyTemp         : num  98.3 100.4 100.8 98.8 100.5 ...\n\n\n\n\nMinimum requirements:\nFor each (important) variable, produce and print some numerical output (e.g. a table or some summary statistics numbers). - Myalgia - Cough Intensity - Weakness\n\nChills\nFatigue\nHeadache\nVision\n\nFor each (important) continuous variable, create a histogram or density plot. - Body Temperature\nCreate scatterplots or boxplots or similar plots for the variable you decided is your main outcome of interest and the most important (or all depending on number of variables) independent variables/predictors.\n\n\nSummary Statistics for Categorical Data\n\ntable(data$Myalgia)\n\n\n    None     Mild Moderate   Severe \n      79      213      325      113 \n\ntable(data$CoughIntensity)\n\n\n    None     Mild Moderate   Severe \n      47      154      357      172 \n\ntable(data$Weakness)\n\n\n    None     Mild Moderate   Severe \n      49      223      338      120 \n\npar(mfrow=c(1,3)) # show the following plots side by side\nbarplot(table(data$Myalgia), ylab = 'Severity of Flu Symptoms', xlab = 'Myalgia', ylim = c(0,350))\nbarplot(table(data$CoughIntensity), xlab = 'Cough Intensity', ylim = c(0,350))\nbarplot(table(data$Weakness), xlab = 'Weakness', ylim = c(0,350))\n\n\n\n\n\n\nSummary Statistics for Binary Data\n\ntable(data$ChillsSweats)\n\n\n No Yes \n130 600 \n\ntable(data$Fatigue)\n\n\n No Yes \n 64 666 \n\ntable(data$Headache)\n\n\n No Yes \n115 615 \n\ntable(data$Vision)\n\n< table of extent 0 >\n\ntable(data$Nausea)\n\n\n No Yes \n475 255 \n\npar(mfrow=c(1,5)) # show the following plots side by side\nbarplot(table(data$ChillsSweats), ylab = 'Presence of Flu Symptoms', xlab = 'Chills or Sweats', ylim = c(0,800))\nbarplot(table(data$Fatigue), xlab = 'Fatigue', ylim = c(0,800))\nbarplot(table(data$Headache), xlab = 'Headache', ylim = c(0,800))\nbarplot(table(data$Nausea), xlab = 'Nausea', ylim = c(0,800))\n\n\n\n\n\n\nSummary Statistics for Continuous Data\n\nsummary(data$BodyTemp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  97.20   98.20   98.50   98.94   99.30  103.10 \n\nhist(data$BodyTemp) #histogram\n\n\n\nd <- density(data$BodyTemp)\nplot(d, main=\"Flu Body Temperature\") #Density plot\n\n\n\n\nVisualizing Data interations\n\nggplot(data = data) +\n  geom_boxplot(aes(x= Myalgia, y = BodyTemp))\n\n\n\nggplot(data = data) +\n  geom_boxplot(aes(x= CoughIntensity, y = BodyTemp))\n\n\n\nggplot(data = data) +\n  geom_boxplot(aes(x= Weakness, y = BodyTemp))"
  },
  {
    "objectID": "fluanalysis/code/fitting.html",
    "href": "fluanalysis/code/fitting.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Flu Analysis: Fitting\n\nLoad the data and packages:\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels) #build models\n\nWarning: package 'tidymodels' was built under R version 4.2.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.3     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'infer' was built under R version 4.2.2\n\n\nWarning: package 'modeldata' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\n\nWarning: package 'rsample' was built under R version 4.2.2\n\n\nWarning: package 'tune' was built under R version 4.2.2\n\n\nWarning: package 'workflows' was built under R version 4.2.2\n\n\nWarning: package 'workflowsets' was built under R version 4.2.2\n\n\nWarning: package 'yardstick' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(here) #help read/import data\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(ggplot2) #data visualization\nlibrary(broom.mixed) # for converting bayesian models to tidy tibbles\n\nWarning: package 'broom.mixed' was built under R version 4.2.2\n\nlibrary(dotwhisker)  # for visualizing regression results\n\nWarning: package 'dotwhisker' was built under R version 4.2.2\n\nlibrary(performance) #evaluate model fit and performance\n\nWarning: package 'performance' was built under R version 4.2.2\n\n\n\nAttaching package: 'performance'\n\nThe following objects are masked from 'package:yardstick':\n\n    mae, rmse\n\ndata <- readRDS(here('fluanalysis/data/SypAct_clean.rds')) #upload cleaned data\ntibble(data) # to get a look at the data\n\n# A tibble: 730 × 26\n   SwollenLymph…¹ Chest…² Chill…³ Nasal…⁴ Sneeze Fatigue Subje…⁵ Heada…⁶ Weakn…⁷\n   <fct>          <fct>   <fct>   <fct>   <fct>  <fct>   <fct>   <fct>   <fct>  \n 1 Yes            No      No      No      No     Yes     Yes     Yes     Mild   \n 2 Yes            Yes     No      Yes     No     Yes     Yes     Yes     Severe \n 3 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 4 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 5 Yes            No      Yes     No      No     Yes     Yes     Yes     Modera…\n 6 No             No      Yes     No      Yes    Yes     Yes     Yes     Modera…\n 7 No             No      Yes     No      No     Yes     Yes     No      Mild   \n 8 No             Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 9 Yes            Yes     Yes     Yes     No     Yes     Yes     Yes     Modera…\n10 No             Yes     No      Yes     No     Yes     No      Yes     Modera…\n# … with 720 more rows, 17 more variables: CoughIntensity <fct>, Myalgia <fct>,\n#   RunnyNose <fct>, AbPain <fct>, ChestPain <fct>, Diarrhea <fct>,\n#   EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>, EarPn <fct>,\n#   Pharyngitis <fct>, Breathless <fct>, ToothPn <fct>, Vomit <fct>,\n#   Wheeze <fct>, BodyTemp <dbl>, and abbreviated variable names\n#   ¹​SwollenLymphNodes, ²​ChestCongestion, ³​ChillsSweats, ⁴​NasalCongestion,\n#   ⁵​SubjectiveFever, ⁶​Headache, ⁷​Weakness\n\nstr(data)\n\n'data.frame':   730 obs. of  26 variables:\n $ SwollenLymphNodes: Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"Swollen Lymph Nodes\"\n $ ChestCongestion  : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Chest Congestion\"\n $ ChillsSweats     : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 2 2 2 1 ...\n  ..- attr(*, \"label\")= chr \"Chills/Sweats\"\n $ NasalCongestion  : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Nasal Congestion\"\n $ Sneeze           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 1 2 1 2 1 1 ...\n  ..- attr(*, \"label\")= chr \"Sneeze\"\n $ Fatigue          : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Fatigue\"\n $ SubjectiveFever  : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 1 ...\n  ..- attr(*, \"label\")= chr \"Subjective Fever\"\n $ Headache         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Headache\"\n $ Weakness         : Factor w/ 4 levels \"None\",\"Mild\",..: 2 4 4 4 3 3 2 4 3 3 ...\n $ CoughIntensity   : Factor w/ 4 levels \"None\",\"Mild\",..: 4 4 2 3 1 3 4 3 3 3 ...\n  ..- attr(*, \"label\")= chr \"Cough Severity\"\n $ Myalgia          : Factor w/ 4 levels \"None\",\"Mild\",..: 2 4 4 4 2 3 2 4 3 2 ...\n $ RunnyNose        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 1 1 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Runny Nose\"\n $ AbPain           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Abdominal Pain\"\n $ ChestPain        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Chest Pain\"\n $ Diarrhea         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 2 1 1 1 1 ...\n $ EyePn            : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Eye Pain\"\n $ Insomnia         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Sleeplessness\"\n $ ItchyEye         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Itchy Eyes\"\n $ Nausea           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 1 1 2 2 ...\n $ EarPn            : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Ear Pain\"\n $ Pharyngitis      : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Sore Throat\"\n $ Breathless       : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 2 1 1 1 2 ...\n  ..- attr(*, \"label\")= chr \"Breathlessness\"\n $ ToothPn          : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"Tooth Pain\"\n $ Vomit            : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Vomiting\"\n $ Wheeze           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 2 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Wheezing\"\n $ BodyTemp         : num  98.3 100.4 100.8 98.8 100.5 ...\n\n\nCode will include:\n\nFitting a linear model to the continuous outcome (Body temperature) using only the main predictor of interest.\nFitting another linear model to the continuous outcome using all (important) predictors of interest.\nComparing the model results for the model with just the main predictor and all predictors.\nFitting a logistic model to the categorical outcome (Nausea) using only the main predictor of interest.\nFitting another logistic model to the categorical outcome using all (important) predictors of interest.\nCompares the model results for the categorical model with just the main predictor and all predictors.\n\n\n\nLinear Model: Body Temperature vs. Myalgia\n\n#plot suspect interaction\nggplot(data,\n       aes(x = Myalgia, y = BodyTemp)) + \n  geom_boxplot()\n\n\n\nlm_mod <- linear_reg() #note the default is lm(), thus we do not need to \"set\" the computational engine\n\nlm_fit1 <- lm_mod %>% \n  fit(BodyTemp ~ Myalgia, data = data)\n\ntidy(lm_fit1) #several significant results\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)       98.7       0.134    734.    0     \n2 MyalgiaMild        0.322     0.157      2.04  0.0413\n3 MyalgiaModerate    0.271     0.150      1.81  0.0711\n4 MyalgiaSevere      0.404     0.175      2.31  0.0214\n\ntidy(lm_fit1) %>% ##help visualize model with dot-whisker plot\n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\nLinear Model: Body Temperature vs. All Variables\n\nlm_fit_all1 <- lm_mod %>% \n  fit(BodyTemp ~ ., data = data)\n\ntidy(lm_fit_all1) #several significant results\n\n# A tibble: 32 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)          97.9        0.304   323.     0        \n 2 SwollenLymphNodesYes -0.166      0.0920   -1.81   0.0714   \n 3 ChestCongestionYes    0.103      0.0971    1.06   0.291    \n 4 ChillsSweatsYes       0.192      0.127     1.51   0.131    \n 5 NasalCongestionYes   -0.222      0.113    -1.95   0.0512   \n 6 SneezeYes            -0.373      0.0980   -3.80   0.000156 \n 7 FatigueYes            0.273      0.161     1.70   0.0901   \n 8 SubjectiveFeverYes    0.437      0.103     4.25   0.0000244\n 9 HeadacheYes           0.00498    0.125     0.0397 0.968    \n10 WeaknessMild          0.00552    0.189     0.0292 0.977    \n# … with 22 more rows\n\ntidy(lm_fit_all1) %>% ##help visualize regression with dot-whisker plot w/ 95% CI\n  dwplot(dot_args = list(size = 2, color = \"black\"), #Coefficient Estimates\n         whisker_args = list(color = \"black\"), #CI\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\nModel Output Comparison\n\n#Check the goodness of \"fit\" with these 2 lm() models\ncheck_model(lm_fit1$fit) #allows for streamlined way to look at QQ plot, normality, etc\n\n\n\ncheck_model(lm_fit_all1$fit)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n#Compare output\n#Visually\ndwplot(list(Myalgia = lm_fit1, AllVariables = lm_fit_all1)) #compare dwplots\n\n\n\nglance(lm_fit1) %>%\n  dplyr::select(adj.r.squared, AIC, BIC, p.value)\n\n# A tibble: 1 × 4\n  adj.r.squared   AIC   BIC p.value\n          <dbl> <dbl> <dbl>   <dbl>\n1       0.00387 2337. 2360.   0.121\n\nglance(lm_fit_all1) %>%\n  dplyr::select(adj.r.squared, AIC, BIC, p.value)\n\n# A tibble: 1 × 4\n  adj.r.squared   AIC   BIC      p.value\n          <dbl> <dbl> <dbl>        <dbl>\n1        0.0853 2302. 2453. 0.0000000247\n\ncompare_performance(lm_fit1,lm_fit_all1) #better way\n\n# Comparison of Model Performance Indices\n\nName        | Model |  AIC (weights) | AICc (weights) |  BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma\n----------------------------------------------------------------------------------------------------------\nlm_fit1     |   _lm | 2336.6 (<.001) | 2336.6 (<.001) | 2359.5 (>.999) | 0.008 |     0.004 | 1.191 | 1.194\nlm_fit_all1 |   _lm | 2301.6 (>.999) | 2304.8 (>.999) | 2453.1 (<.001) | 0.124 |     0.085 | 1.119 | 1.144\n\n#Via ANOVA\nanova(lm_fit1$fit, lm_fit_all1$fit)\n\nAnalysis of Variance Table\n\nModel 1: BodyTemp ~ Myalgia\nModel 2: BodyTemp ~ SwollenLymphNodes + ChestCongestion + ChillsSweats + \n    NasalCongestion + Sneeze + Fatigue + SubjectiveFever + Headache + \n    Weakness + CoughIntensity + Myalgia + RunnyNose + AbPain + \n    ChestPain + Diarrhea + EyePn + Insomnia + ItchyEye + Nausea + \n    EarPn + Pharyngitis + Breathless + ToothPn + Vomit + Wheeze\n  Res.Df     RSS Df Sum of Sq      F    Pr(>F)    \n1    726 1035.07                                  \n2    698  913.79 28    121.28 3.3086 3.294e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nLogistic Model: Nausea vs. Myalgia\n\n#plot suspect interaction\nggplot(data, aes(x = Myalgia, y = Nausea)) + \n  geom_count()\n\n\n\nglm_mod <- logistic_reg(mode = \"classification\",\n  engine = \"glm\",\n  penalty = NULL,\n  mixture = NULL) #define mode so it is a glm\n\nglm_fit1 <- glm_mod %>% \n  fit(Nausea ~ Myalgia, data = data)\n\ntidy(glm_fit1) #several significant results\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic     p.value\n  <chr>              <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)       -1.37      0.280    -4.90  0.000000980\n2 MyalgiaMild        0.291     0.321     0.905 0.366      \n3 MyalgiaModerate    0.926     0.302     3.07  0.00217    \n4 MyalgiaSevere      1.42      0.337     4.22  0.0000244  \n\ntidy(glm_fit1) %>% ##help visualize model with dot-whisker plot\n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\nLogistic Model: Nausea vs. All Variables\n\nglm_fit_all1 <- glm_mod %>% \n  fit(Nausea ~ ., data = data)\n\ntidy(glm_fit_all1) #several significant results\n\n# A tibble: 32 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)             0.207     7.81     0.0265  0.979 \n 2 SwollenLymphNodesYes   -0.247     0.196   -1.26    0.207 \n 3 ChestCongestionYes      0.265     0.210    1.26    0.207 \n 4 ChillsSweatsYes         0.291     0.287    1.01    0.311 \n 5 NasalCongestionYes      0.440     0.253    1.74    0.0822\n 6 SneezeYes               0.165     0.210    0.787   0.431 \n 7 FatigueYes              0.231     0.371    0.622   0.534 \n 8 SubjectiveFeverYes      0.255     0.223    1.14    0.253 \n 9 HeadacheYes             0.337     0.285    1.18    0.236 \n10 WeaknessMild           -0.120     0.447   -0.269   0.788 \n# … with 22 more rows\n\ntidy(glm_fit_all1) %>% ##help visualize regression with dot-whisker plot w/ 95% CI\n  dwplot(dot_args = list(size = 2, color = \"black\"), #Coefficient Estimates\n         whisker_args = list(color = \"black\"), #CI\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\nModel Output Comparison\n\n#Check the goodness of \"fit\" with these 2 lm() models\ncheck_model(glm_fit1$fit) #QQ plot seems off, residuals may be an issue\n\n\n\ncheck_model(glm_fit_all1$fit)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n#Compare output\n#Visually\ndwplot(list(Myalgia = glm_fit1, AllVariables = glm_fit_all1)) #compare dwplots\n\n\n\nglance(glm_fit1) %>%\n  dplyr::select( AIC, BIC)\n\n# A tibble: 1 × 2\n    AIC   BIC\n  <dbl> <dbl>\n1  920.  939.\n\nglance(glm_fit_all1) %>%\n  dplyr::select( AIC, BIC) #better fit\n\n# A tibble: 1 × 2\n    AIC   BIC\n  <dbl> <dbl>\n1  816.  963.\n\ncompare_performance(glm_fit1,glm_fit_all1)\n\n# Comparison of Model Performance Indices\n\nName         | Model | AIC (weights) | AICc (weights) | BIC (weights) | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n--------------------------------------------------------------------------------------------------------------------------------------------------\nglm_fit1     |  _glm | 920.3 (<.001) |  920.3 (<.001) | 938.7 (>.999) |     0.044 | 0.466 | 1.121 |    0.625 |  -110.929 |           0.006 | 0.565\nglm_fit_all1 |  _glm | 816.1 (>.999) |  819.2 (>.999) | 963.1 (<.001) |     0.246 | 0.415 | 1.038 |    0.515 |      -Inf |           0.002 | 0.657\n\n#Via ANOVA\nanova(glm_fit1$fit, glm_fit_all1$fit)\n\nAnalysis of Deviance Table\n\nModel 1: Nausea ~ Myalgia\nModel 2: Nausea ~ SwollenLymphNodes + ChestCongestion + ChillsSweats + \n    NasalCongestion + Sneeze + Fatigue + SubjectiveFever + Headache + \n    Weakness + CoughIntensity + Myalgia + RunnyNose + AbPain + \n    ChestPain + Diarrhea + EyePn + Insomnia + ItchyEye + EarPn + \n    Pharyngitis + Breathless + ToothPn + Vomit + Wheeze + BodyTemp\n  Resid. Df Resid. Dev Df Deviance\n1       726     912.28            \n2       698     752.13 28   160.15"
  },
  {
    "objectID": "fluanalysis/code/machinelearing.html",
    "href": "fluanalysis/code/machinelearing.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Fit regression models\n\n\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggplot2)\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.2.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.3     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'infer' was built under R version 4.2.2\n\n\nWarning: package 'modeldata' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\n\nWarning: package 'rsample' was built under R version 4.2.2\n\n\nWarning: package 'tune' was built under R version 4.2.2\n\n\nWarning: package 'workflows' was built under R version 4.2.2\n\n\nWarning: package 'workflowsets' was built under R version 4.2.2\n\n\nWarning: package 'yardstick' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(dplyr)\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.2.3\n\nlibrary(rpart)\n\nWarning: package 'rpart' was built under R version 4.2.3\n\n\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.2\n\n\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-7\n\nlibrary(rpart.plot)\n\nWarning: package 'rpart.plot' was built under R version 4.2.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.2.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\ndata <- readRDS(here('fluanalysis/data/SypAct_clean.rds')) #upload cleaned data\ntibble(data) #overview of data\n\n# A tibble: 730 × 26\n   SwollenLymph…¹ Chest…² Chill…³ Nasal…⁴ Sneeze Fatigue Subje…⁵ Heada…⁶ Weakn…⁷\n   <fct>          <fct>   <fct>   <fct>   <fct>  <fct>   <fct>   <fct>   <fct>  \n 1 Yes            No      No      No      No     Yes     Yes     Yes     Mild   \n 2 Yes            Yes     No      Yes     No     Yes     Yes     Yes     Severe \n 3 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 4 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 5 Yes            No      Yes     No      No     Yes     Yes     Yes     Modera…\n 6 No             No      Yes     No      Yes    Yes     Yes     Yes     Modera…\n 7 No             No      Yes     No      No     Yes     Yes     No      Mild   \n 8 No             Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 9 Yes            Yes     Yes     Yes     No     Yes     Yes     Yes     Modera…\n10 No             Yes     No      Yes     No     Yes     No      Yes     Modera…\n# … with 720 more rows, 17 more variables: CoughIntensity <fct>, Myalgia <fct>,\n#   RunnyNose <fct>, AbPain <fct>, ChestPain <fct>, Diarrhea <fct>,\n#   EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>, EarPn <fct>,\n#   Pharyngitis <fct>, Breathless <fct>, ToothPn <fct>, Vomit <fct>,\n#   Wheeze <fct>, BodyTemp <dbl>, and abbreviated variable names\n#   ¹​SwollenLymphNodes, ²​ChestCongestion, ³​ChillsSweats, ⁴​NasalCongestion,\n#   ⁵​SubjectiveFever, ⁶​Headache, ⁷​Weakness\n\n\n\n\n\n\n\nset.seed(123)\n# Fix the random numbers by setting the seed \n# This enables the analysis to be reproducible when random numbers are used \n\ndata_split <- initial_split(data, prop = 2.8/4, strata = BodyTemp) #70% training, 30% testing\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n\n#5-fold cross-validation, 5 times repeated\nfold_data <- vfold_cv(train_data, v = 5, repeats = 5, strata = BodyTemp)\n\n#Create a recipe for the data and fitting. \ndata_recipe <- recipe(BodyTemp ~ ., data = train_data) %>%\n  step_dummy(all_nominal(), -all_outcomes()) \n\n\n\n\n\nnull_recipe <- recipe(BodyTemp ~ 1, data = train_data) %>%\n  step_dummy(all_nominal(), -all_outcomes())\n\n# Logistic model recipe\nrecipe_mod <- linear_reg() %>% \n  set_engine(\"lm\") %>% \n  set_mode(\"regression\")\n\n# Model workflow to pair model and recipe \nnull_flow <- workflow() %>% \n  add_model(recipe_mod) %>% \n  add_recipe(null_recipe)\n\n#fit the null model to the folds made from the train data set.\nnull_train <- fit_resamples(null_flow, resamples = fold_data)\n\n! Fold1, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n#Compute the RMSE for both training and test data\nNull_Met <- collect_metrics(null_train)\n#RMSE = 1.22\n\n\n\n\n\n\n\n#TUNING HYPERPARAMETERS \ntune_spec <- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"regression\")\n\ntree_grid <- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid %>% \n  count(tree_depth)\n\n# A tibble: 5 × 2\n  tree_depth     n\n       <int> <int>\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5\n\n#Model tuning with a grid\ntree_wf <- workflow() %>%\n  add_model(tune_spec) %>%\n  add_recipe(data_recipe)\n\ntree_res <- #Code will take a hot minute to run\n  tree_wf %>% \n  tune_grid(\n    resamples = fold_data,\n    grid = tree_grid\n    )\n\n! Fold1, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\ntree_res %>% \n  collect_metrics()\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric .estimator     mean     n  std_err .config\n             <dbl>      <int> <chr>   <chr>         <dbl> <int>    <dbl> <chr>  \n 1    0.0000000001          1 rmse    standard     1.19      25  0.0181  Prepro…\n 2    0.0000000001          1 rsq     standard     0.0361    25  0.00422 Prepro…\n 3    0.0000000178          1 rmse    standard     1.19      25  0.0181  Prepro…\n 4    0.0000000178          1 rsq     standard     0.0361    25  0.00422 Prepro…\n 5    0.00000316            1 rmse    standard     1.19      25  0.0181  Prepro…\n 6    0.00000316            1 rsq     standard     0.0361    25  0.00422 Prepro…\n 7    0.000562              1 rmse    standard     1.19      25  0.0181  Prepro…\n 8    0.000562              1 rsq     standard     0.0361    25  0.00422 Prepro…\n 9    0.1                   1 rmse    standard     1.21      25  0.0177  Prepro…\n10    0.1                   1 rsq     standard   NaN          0 NA       Prepro…\n# … with 40 more rows\n\n#show and select best\ntree_res %>%\n  show_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \n1    0.0000000001          1 rmse    standard    1.19    25  0.0181 Preprocesso…\n2    0.0000000178          1 rmse    standard    1.19    25  0.0181 Preprocesso…\n3    0.00000316            1 rmse    standard    1.19    25  0.0181 Preprocesso…\n4    0.000562              1 rmse    standard    1.19    25  0.0181 Preprocesso…\n5    0.0000000001          4 rmse    standard    1.20    25  0.0187 Preprocesso…\n\n#rmse = 1.2\n\nbest_tree <- tree_res %>%\n  select_best(n=1)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n#Final tuned model\nfinal_wf <- \n  tree_wf %>% \n  finalize_workflow(best_tree)\n\n#The Last Fit\nfinal_fit <- \n  final_wf %>%\n  fit(train_data) \n\n#Plot\nrpart.plot(extract_fit_parsnip(final_fit)$fit)\n\nWarning: Cannot retrieve the data used to build the model (model.frame: object '..y' not found).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\n\n\n\n#BUILD THE MODEL\nlasso_mod <- \n  linear_reg(penalty = tune(), mixture = 1) %>% \n  set_engine(\"glmnet\")\n\n# Recipe and create Workflow\ndata_recipe\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         25\n\nOperations:\n\nDummy variables from all_nominal(), -all_outcomes()\n\nlasso_wf <- \n  workflow() %>% \n  add_model(lasso_mod) %>% \n  add_recipe(data_recipe)\n\n#Create grid for tuning\nlr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))\nlr_reg_grid %>% top_n(-5) # lowest penalty values\n\nSelecting by penalty\n\n\n# A tibble: 5 × 1\n   penalty\n     <dbl>\n1 0.0001  \n2 0.000127\n3 0.000161\n4 0.000204\n5 0.000259\n\nlr_reg_grid %>% top_n(5)  # highest penalty values\n\nSelecting by penalty\n\n\n# A tibble: 5 × 1\n  penalty\n    <dbl>\n1  0.0386\n2  0.0489\n3  0.0621\n4  0.0788\n5  0.1   \n\n#TRAIN AND TUNE THE MODEL\nlr_res <- \n  lasso_wf %>% \n  tune_grid(resamples = fold_data,\n            grid = lr_reg_grid,\n            control = control_grid(verbose = FALSE, save_pred = TRUE),\n            metrics = NULL)\n\nlr_res %>%\n  collect_metrics()\n\n# A tibble: 60 × 7\n    penalty .metric .estimator   mean     n std_err .config              \n      <dbl> <chr>   <chr>       <dbl> <int>   <dbl> <chr>                \n 1 0.0001   rmse    standard   1.18      25 0.0167  Preprocessor1_Model01\n 2 0.0001   rsq     standard   0.0819    25 0.00875 Preprocessor1_Model01\n 3 0.000127 rmse    standard   1.18      25 0.0167  Preprocessor1_Model02\n 4 0.000127 rsq     standard   0.0819    25 0.00875 Preprocessor1_Model02\n 5 0.000161 rmse    standard   1.18      25 0.0167  Preprocessor1_Model03\n 6 0.000161 rsq     standard   0.0819    25 0.00875 Preprocessor1_Model03\n 7 0.000204 rmse    standard   1.18      25 0.0167  Preprocessor1_Model04\n 8 0.000204 rsq     standard   0.0819    25 0.00875 Preprocessor1_Model04\n 9 0.000259 rmse    standard   1.18      25 0.0167  Preprocessor1_Model05\n10 0.000259 rsq     standard   0.0819    25 0.00875 Preprocessor1_Model05\n# … with 50 more rows\n\nlr_res %>%\n  show_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1  0.0489 rmse    standard    1.15    25  0.0170 Preprocessor1_Model27\n2  0.0621 rmse    standard    1.15    25  0.0170 Preprocessor1_Model28\n3  0.0386 rmse    standard    1.16    25  0.0170 Preprocessor1_Model26\n4  0.0304 rmse    standard    1.16    25  0.0169 Preprocessor1_Model25\n5  0.0788 rmse    standard    1.16    25  0.0172 Preprocessor1_Model29\n\n#Selects best performing model\nbest_lasso <- lr_res %>%\n  select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n#rmse = 1.18\n\n#Final Model\nlasso_final_wf <- \n  lasso_wf %>% \n  finalize_workflow(best_lasso)\n\nlasso_final_fit <- \n  lasso_final_wf %>%\n  fit(train_data) \n\n#Plot\nx <- extract_fit_engine(lasso_final_fit)\nplot(x, \"lambda\")\n\n\n\n\n\n\n\n\n#BUILD THE MODEL AND IMPROVE TRAINING TIME\ncores <- parallel::detectCores()\ncores\n\n[1] 4\n\nf_mod <- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% \n  set_engine(\"ranger\",importance = \"impurity\", num.threads = cores) %>% \n  set_mode(\"regression\")\n\nf_wf <- workflow() %>%\n  add_model(f_mod) %>%\n  add_recipe(data_recipe)\n\n#TRAIN AND TUNE THE MODEL\nf_mod\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = impurity\n  num.threads = cores\n\nComputational engine: ranger \n\nextract_parameter_set_dials(f_mod)\n\nCollection of 2 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n\nf_res <- #This code takes a long time to run!\n  f_wf %>% \n  tune_grid(fold_data,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = NULL)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#Show and select the best\n\nf_res %>%\n  show_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     5    27 rmse    standard    1.16    25  0.0168 Preprocessor1_Model18\n2     3    19 rmse    standard    1.16    25  0.0167 Preprocessor1_Model09\n3     8    24 rmse    standard    1.17    25  0.0167 Preprocessor1_Model04\n4    11    36 rmse    standard    1.17    25  0.0168 Preprocessor1_Model13\n5     6    15 rmse    standard    1.17    25  0.0167 Preprocessor1_Model22\n\n#rmse = 1.19\n\nf_best <- \n  f_res %>% \n  select_best(metric = \"rmse\")\n\nf_final_wf <- \n  f_wf %>% \n  finalize_workflow(f_best)\n\n#Final model fit\nf_final_fit <- \n  f_final_wf %>%\n  fit(train_data) \n\nf_final_fit %>% \n  extract_fit_parsnip() %>% \n  vip(num_features = 28)\n\n\n\n#Plot\nfx <- extract_fit_engine(f_final_fit)\nvip(fx)\n\n\n\n\n\n\n\n\n\n#Based on rmse the Lasso model appears to be the best\n#We will fit final lasson model on split data!\n\nlasso_final_test <- \n  lasso_final_wf %>%\n  last_fit(data_split) \n\nlasso_final_test %>%\n   collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard      1.16   Preprocessor1_Model1\n2 rsq     standard      0.0299 Preprocessor1_Model1\n\n#rmse = 1.156"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html",
    "href": "fluanalysis/code/modeleval.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Improving Models\n\nLoad packakes and data\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggplot2)\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.2.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.3     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'infer' was built under R version 4.2.2\n\n\nWarning: package 'modeldata' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\n\nWarning: package 'rsample' was built under R version 4.2.2\n\n\nWarning: package 'tune' was built under R version 4.2.2\n\n\nWarning: package 'workflows' was built under R version 4.2.2\n\n\nWarning: package 'workflowsets' was built under R version 4.2.2\n\n\nWarning: package 'yardstick' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(dplyr)\n\ndata <- readRDS(here('fluanalysis/data/SypAct_clean.rds')) #upload cleaned data\ntibble(data) #overview of data\n\n# A tibble: 730 × 26\n   SwollenLymph…¹ Chest…² Chill…³ Nasal…⁴ Sneeze Fatigue Subje…⁵ Heada…⁶ Weakn…⁷\n   <fct>          <fct>   <fct>   <fct>   <fct>  <fct>   <fct>   <fct>   <fct>  \n 1 Yes            No      No      No      No     Yes     Yes     Yes     Mild   \n 2 Yes            Yes     No      Yes     No     Yes     Yes     Yes     Severe \n 3 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 4 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 5 Yes            No      Yes     No      No     Yes     Yes     Yes     Modera…\n 6 No             No      Yes     No      Yes    Yes     Yes     Yes     Modera…\n 7 No             No      Yes     No      No     Yes     Yes     No      Mild   \n 8 No             Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 9 Yes            Yes     Yes     Yes     No     Yes     Yes     Yes     Modera…\n10 No             Yes     No      Yes     No     Yes     No      Yes     Modera…\n# … with 720 more rows, 17 more variables: CoughIntensity <fct>, Myalgia <fct>,\n#   RunnyNose <fct>, AbPain <fct>, ChestPain <fct>, Diarrhea <fct>,\n#   EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>, EarPn <fct>,\n#   Pharyngitis <fct>, Breathless <fct>, ToothPn <fct>, Vomit <fct>,\n#   Wheeze <fct>, BodyTemp <dbl>, and abbreviated variable names\n#   ¹​SwollenLymphNodes, ²​ChestCongestion, ³​ChillsSweats, ⁴​NasalCongestion,\n#   ⁵​SubjectiveFever, ⁶​Headache, ⁷​Weakness\n\n\n\n\nSplit Data\n\nset.seed(123)\n# Fix the random numbers by setting the seed \n# This enables the analysis to be reproducible when random numbers are used \n\ndata_split <- initial_split(data, prop = 3/4)\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n\n\n\nMake a recipe and fit a model\n\n# Create recipe using Nausea as categorical variable\n\ndata_recipe <- recipe(Nausea ~ ., data = train_data)\n\n# Logistic model recipe\nrecipe_mod <- logistic_reg() %>% set_engine(\"glm\")\n\n# Model workflow to pair model and recipe \nmod_flow <- workflow() %>% \n  add_model(recipe_mod) %>% \n  add_recipe(data_recipe)\n\nmod_flow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nTrain the model from the resulting predictors\n\ndata_fit <- \n  mod_flow %>% \n  fit(data = train_data)\n\ndata_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 32 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)            -2.83      9.07     -0.312  0.755 \n 2 SwollenLymphNodesYes   -0.435     0.235    -1.85   0.0649\n 3 ChestCongestionYes      0.277     0.252     1.10   0.271 \n 4 ChillsSweatsYes         0.333     0.355     0.939  0.348 \n 5 NasalCongestionYes      0.233     0.300     0.778  0.437 \n 6 SneezeYes               0.115     0.253     0.455  0.649 \n 7 FatigueYes              0.288     0.460     0.626  0.531 \n 8 SubjectiveFeverYes      0.402     0.271     1.48   0.138 \n 9 HeadacheYes             0.644     0.367     1.75   0.0794\n10 WeaknessMild           -0.274     0.574    -0.478  0.633 \n# … with 22 more rows\n\n\n\n\nUse a trained workflow to Predict\n\npredict(data_fit, test_data)\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 Yes        \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 Yes        \n# … with 173 more rows\n\ndata_aug <- \n  augment(data_fit, test_data)\n\n# The data look like: \ndata_aug %>%\n  select(Nausea, .pred_No, .pred_Yes)\n\n# A tibble: 183 × 3\n   Nausea .pred_No .pred_Yes\n   <fct>     <dbl>     <dbl>\n 1 No        0.961    0.0394\n 2 Yes       0.121    0.879 \n 3 Yes       0.769    0.231 \n 4 Yes       0.744    0.256 \n 5 Yes       0.759    0.241 \n 6 No        0.771    0.229 \n 7 No        0.544    0.456 \n 8 No        0.745    0.255 \n 9 No        0.941    0.0585\n10 Yes       0.171    0.829 \n# … with 173 more rows\n\n\n\n\nROC Curve\n\ndata_aug %>% \n  roc_curve(truth = Nausea, .pred_No) %>% \n  autoplot()\n\n\n\ndata_aug %>% \n  roc_auc(truth = Nausea, .pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.709\n\n# > 0.7; the model might be useful. \n\n\n\nAlternative Model: Main predictor to the Categorical Outcome\n\n# Create new recipe\ndata_recipe2 <- recipe(Nausea ~ Myalgia, data = train_data) #%>%\n#  step_nzv(all_predictors(), freq_cut = 995/5, unique_cut = 10) %>%\n#  step_ordinalscore(all_of(ordered_names))\n\n# Model workflow to pair model and recipe \nmod_flow2 <- workflow() %>% \n  add_model(recipe_mod) %>% \n  add_recipe(data_recipe2)\n\n#Train data\ndata_fit2 <- \n  mod_flow2 %>% \n  fit(data = train_data)\n\ndata_aug2 <- \n  augment(data_fit2, test_data)\n\ndata_aug2 %>% \n  roc_auc(truth = Nausea, .pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.633\n\n# < 0.7; the model not very useful. \n\n\n\nThe following added by SETH LATTNER\n\nFitting continuous variables\n\ndata_recipe3 <- recipe(BodyTemp ~ ., data = train_data) #%>%\n#  step_nzv(all_predictors(), freq_cut = 995/5, unique_cut = 10) %>%\n#  step_ordinalscore(all_of(ordered_names))\n\n# Logistic model recipe\nrecipe_mod3 <- linear_reg() %>% set_engine(\"lm\")\n\n# Model workflow to pair model and recipe \nmod_flow3 <- workflow() %>% \n  add_model(recipe_mod3) %>% \n  add_recipe(data_recipe3)\n\nmod_flow3\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n\nTrain the model from the resulting predictors\n\ndata_fit3 <- \n  mod_flow3 %>% \n  fit(data = train_data)\n\ndata_fit3 %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 32 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)           98.2        0.352   279.    0        \n 2 SwollenLymphNodesYes  -0.104      0.108    -0.960 0.337    \n 3 ChestCongestionYes     0.0566     0.114     0.496 0.620    \n 4 ChillsSweatsYes        0.279      0.151     1.84  0.0664   \n 5 NasalCongestionYes    -0.213      0.133    -1.60  0.110    \n 6 SneezeYes             -0.400      0.116    -3.44  0.000627 \n 7 FatigueYes             0.375      0.187     2.00  0.0461   \n 8 SubjectiveFeverYes     0.517      0.122     4.25  0.0000259\n 9 HeadacheYes           -0.0614     0.151    -0.406 0.685    \n10 WeaknessMild          -0.0473     0.226    -0.209 0.834    \n# … with 22 more rows\n\n\n\n\nUse a trained workflow to Predict\n\npredict(data_fit3, test_data)\n\n# A tibble: 183 × 1\n   .pred\n   <dbl>\n 1  99.5\n 2  98.9\n 3  99.0\n 4  98.7\n 5  98.5\n 6  99.0\n 7  99.5\n 8  99.7\n 9  98.9\n10  99.6\n# … with 173 more rows\n\ndata_aug3 <- \n  augment(data_fit3, test_data)\n\n# The data look like: \ndata_aug3 %>%\n  select(BodyTemp, .pred)\n\n# A tibble: 183 × 2\n   BodyTemp .pred\n      <dbl> <dbl>\n 1     98.3  99.5\n 2    101.   98.9\n 3     98.8  99.0\n 4     98.5  98.7\n 5     98.1  98.5\n 6     98.4  99.0\n 7     99.5  99.5\n 8     98.8  99.7\n 9    102.   98.9\n10     99.7  99.6\n# … with 173 more rows\n\n\n\n#calculate RMSE\nyardstick::rmse(data_aug3, BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.14\n\n\n\n\nAlternative Model: Main predictor to the Categorical Outcome\n\n# Create new recipe\ndata_recipe4 <- recipe(BodyTemp ~ RunnyNose, data = train_data) #%>%\n#  step_nzv(all_predictors(), freq_cut = 995/5, unique_cut = 10) %>%\n# step_ordinalscore(all_of(ordered_names))\n\n# Model workflow to pair model and recipe \nmod_flow4 <- workflow() %>% \n  add_model(recipe_mod3) %>% \n  add_recipe(data_recipe4)\n\n#Train data\ndata_fit4 <- \n  mod_flow4 %>% \n  fit(data = train_data)\n\ndata_fit4 %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.2      0.0969   1024.   0      \n2 RunnyNoseYes   -0.362    0.115      -3.16 0.00168\n\n\n\n#predict from test data\npredict(data_fit4, test_data)\n\n# A tibble: 183 × 1\n   .pred\n   <dbl>\n 1  99.2\n 2  98.9\n 3  98.9\n 4  98.9\n 5  98.9\n 6  98.9\n 7  99.2\n 8  99.2\n 9  99.2\n10  99.2\n# … with 173 more rows\n\n#augment test data\ndata_aug4 <- \n  augment(data_fit4, test_data)\n\n#the data look like:\ndata_aug4 %>%\n  select(BodyTemp, .pred)\n\n# A tibble: 183 × 2\n   BodyTemp .pred\n      <dbl> <dbl>\n 1     98.3  99.2\n 2    101.   98.9\n 3     98.8  98.9\n 4     98.5  98.9\n 5     98.1  98.9\n 6     98.4  98.9\n 7     99.5  99.2\n 8     98.8  99.2\n 9    102.   99.2\n10     99.7  99.2\n# … with 173 more rows\n\n\n\n#calculate RMSE\nyardstick::rmse(data_aug4, BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.12\n\n\nThe RMSE of the univariate model 4 (1.12) was lower than that of the global model 3 (1.15), showing that it is a better fit to the data."
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Flu Analysis: Wrangling\n\nLoad the data and packages:\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.2.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.3     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'infer' was built under R version 4.2.2\n\n\nWarning: package 'modeldata' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\n\nWarning: package 'rsample' was built under R version 4.2.2\n\n\nWarning: package 'tune' was built under R version 4.2.2\n\n\nWarning: package 'workflows' was built under R version 4.2.2\n\n\nWarning: package 'workflowsets' was built under R version 4.2.2\n\n\nWarning: package 'yardstick' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nraw_flu <- readRDS(here('fluanalysis/data/SympAct_Any_Pos.Rda'))\ntibble(raw_flu) # to get a look at the data\n\n# A tibble: 735 × 63\n   DxName1       DxName2 DxName3 DxName4 DxName5 Uniqu…¹ Activ…² Activ…³ Swoll…⁴\n   <fct>         <fct>   <fct>   <fct>   <fct>   <chr>     <int> <fct>   <fct>  \n 1 Influenza li… <NA>    <NA>    <NA>    <NA>    340_17…      10 10      Yes    \n 2 Acute tonsil… Influe… <NA>    <NA>    <NA>    340_17…       6 6       Yes    \n 3 Influenza li… Acute … <NA>    <NA>    <NA>    342_17…       2 2       Yes    \n 4 Influenza li… Unspec… <NA>    <NA>    <NA>    342_17…       2 2       Yes    \n 5 Acute pharyn… Influe… <NA>    <NA>    <NA>    342_17…       5 5       Yes    \n 6 Influenza li… <NA>    <NA>    <NA>    <NA>    343_17…       3 3       No     \n 7 Fever, unspe… Influe… <NA>    <NA>    <NA>    343_17…       4 4       No     \n 8 Acute upper … Impact… <NA>    <NA>    <NA>    344_17…       0 0       No     \n 9 Influenza li… Acute … Fever,… Other … Headac… 344_17…       0 0       Yes    \n10 Influenza li… <NA>    <NA>    <NA>    <NA>    344_17…       5 5       No     \n# … with 725 more rows, 54 more variables: ChestCongestion <fct>,\n#   ChillsSweats <fct>, NasalCongestion <fct>, CoughYN <fct>, Sneeze <fct>,\n#   Fatigue <fct>, SubjectiveFever <fct>, Headache <fct>, Weakness <fct>,\n#   WeaknessYN <fct>, CoughIntensity <fct>, CoughYN2 <fct>, Myalgia <fct>,\n#   MyalgiaYN <fct>, RunnyNose <fct>, AbPain <fct>, ChestPain <fct>,\n#   Diarrhea <fct>, EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>,\n#   EarPn <fct>, Hearing <fct>, Pharyngitis <fct>, Breathless <fct>, …\n\n\n\n\nRemove unwanted data columns\n\n+ Feature/Variable removal\nRemove all variables that have Score or Total or FluA or FluB or Dxname or Activity in their name. Also remove the variable Unique.Visit. Remove any NA observations.\nNow data set contains 32 variables coding for presence or absence of some symptom. Only one, temperature, is continuous.\n\nflu_clean <- raw_flu %>% #sort through the data and removing all variables (columns) that include the words: Score or Total or FluA or FluB or Dxname or Activity\n  select(-contains(c(\"Score\", \"Total\", \"FluA\", \"FluB\", \"Dxname\", \"Activity\"))) %>% #now will remove all columns that include Unique.Visit\n  select(-contains(c(\"Unique.Visit\"))) %>%\n  drop_na %>% #Will drop all nas now \nselect(-contains(c(\"WeaknessYN\", \"CoughYN\", \"CoughYN2\", \"MyalgiaYN\"))) ## Remove repeated variables (#Weakness, Cough and Myalgia)\n\n\n\n\nRemove binary predictors with <50 entries\n\nsummary(flu_clean)\n\n SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion Sneeze   \n No :418           No :323         No :130      No :167         No :339  \n Yes:312           Yes:407         Yes:600      Yes:563         Yes:391  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Fatigue   SubjectiveFever Headache      Weakness    CoughIntensity\n No : 64   No :230         No :115   None    : 49   None    : 47   \n Yes:666   Yes:500         Yes:615   Mild    :223   Mild    :154   \n                                     Moderate:338   Moderate:357   \n                                     Severe  :120   Severe  :172   \n                                                                   \n                                                                   \n     Myalgia    RunnyNose AbPain    ChestPain Diarrhea  EyePn     Insomnia \n None    : 79   No :211   No :639   No :497   No :631   No :617   No :315  \n Mild    :213   Yes:519   Yes: 91   Yes:233   Yes: 99   Yes:113   Yes:415  \n Moderate:325                                                              \n Severe  :113                                                              \n                                                                           \n                                                                           \n ItchyEye  Nausea    EarPn     Hearing   Pharyngitis Breathless ToothPn  \n No :551   No :475   No :568   No :700   No :119     No :436    No :565  \n Yes:179   Yes:255   Yes:162   Yes: 30   Yes:611     Yes:294    Yes:165  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Vision    Vomit     Wheeze       BodyTemp     \n No :711   No :652   No :510   Min.   : 97.20  \n Yes: 19   Yes: 78   Yes:220   1st Qu.: 98.20  \n                               Median : 98.50  \n                               Mean   : 98.94  \n                               3rd Qu.: 99.30  \n                               Max.   :103.10  \n\n#Both vision and Hearing have under 50 of either Yes/No, remove\n\nflu_clean_2 <- flu_clean %>%\nselect(-contains(c(\"Vision\", \"Hearing\")))\n\n\n\nSave file into project:\n\nsaveRDS(flu_clean_2, file= here(\"fluanalysis\", \"data\", \"SypAct_clean.rds\")) #will save as a data.frame in the RDS file"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "Welcome to my website and data analysis portfolio.\n\nUse the Menu Bar above to look around.\nPlease enjoy my attempt at:"
  },
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Upload public access data for exercise via tidytuesdayR package.\n\n#install.packages(\"tidytuesdayR\")\n#install.packages('janitor')\n\nlibrary(tidytuesdayR)\n\nWarning: package 'tidytuesdayR' was built under R version 4.2.2\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.2.2\n\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ntuesdata <- tidytuesdayR::tt_load(2023, week = 7)\n\n--- Compiling #TidyTuesday Information for 2023-02-14 ----\n--- There is 1 file available ---\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 1: `age_gaps.csv`\n\n\n--- Download complete ---\n\nage_gaps <- tuesdata$age_gaps\n\n\n\n\n\n\n\nmovie_name; character; Name of the film;\nrelease_year; integer; Release year\ndirector; character; Director of the film\nage_difference; integer; Age difference between the characters in whole years\ncouple_number; integer; An identifier for the couple in case multiple couples are listed for this film\nactor_1_name; character; The name of the older actor in this couple\nactor_2_name; character; The name of the younger actor in this couple\ncharacter_1_gender; character; The gender of the older character, as identified by the person who submitted the data for this couple\ncharacter_2_gender; character; The gender of the younger character, as identified by the person who submitted the data for this couple\nactor_1_birthdate; date; The birthdate of the older member of the couple\nactor_2_birthdate; date; The birthdate of the younger member of the couple\nactor_1_age; integer; The age of the older actor when the film was released\nactor_2_age; integer; The age of the younger actor when the film was released\n\ntibble(age_gaps)\n\n# A tibble: 1,155 × 13\n   movie_name    relea…¹ direc…² age_d…³ coupl…⁴ actor…⁵ actor…⁶ chara…⁷ chara…⁸\n   <chr>           <dbl> <chr>     <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>  \n 1 Harold and M…    1971 Hal As…      52       1 Ruth G… Bud Co… woman   man    \n 2 Venus            2006 Roger …      50       1 Peter … Jodie … man     woman  \n 3 The Quiet Am…    2002 Philli…      49       1 Michae… Do Thi… man     woman  \n 4 The Big Lebo…    1998 Joel C…      45       1 David … Tara R… man     woman  \n 5 Beginners        2010 Mike M…      43       1 Christ… Goran … man     man    \n 6 Poison Ivy       1992 Katt S…      42       1 Tom Sk… Drew B… man     woman  \n 7 Whatever Wor…    2009 Woody …      40       1 Larry … Evan R… man     woman  \n 8 Entrapment       1999 Jon Am…      39       1 Sean C… Cather… man     woman  \n 9 Husbands and…    1992 Woody …      38       1 Woody … Juliet… man     woman  \n10 Magnolia         1999 Paul T…      38       1 Jason … Julian… man     woman  \n# … with 1,145 more rows, 4 more variables: actor_1_birthdate <date>,\n#   actor_2_birthdate <date>, actor_1_age <dbl>, actor_2_age <dbl>, and\n#   abbreviated variable names ¹​release_year, ²​director, ³​age_difference,\n#   ⁴​couple_number, ⁵​actor_1_name, ⁶​actor_2_name, ⁷​character_1_gender,\n#   ⁸​character_2_gender\n\nglimpse(age_gaps)\n\nRows: 1,155\nColumns: 13\n$ movie_name         <chr> \"Harold and Maude\", \"Venus\", \"The Quiet American\", …\n$ release_year       <dbl> 1971, 2006, 2002, 1998, 2010, 1992, 2009, 1999, 199…\n$ director           <chr> \"Hal Ashby\", \"Roger Michell\", \"Phillip Noyce\", \"Joe…\n$ age_difference     <dbl> 52, 50, 49, 45, 43, 42, 40, 39, 38, 38, 36, 36, 35,…\n$ couple_number      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ actor_1_name       <chr> \"Ruth Gordon\", \"Peter O'Toole\", \"Michael Caine\", \"D…\n$ actor_2_name       <chr> \"Bud Cort\", \"Jodie Whittaker\", \"Do Thi Hai Yen\", \"T…\n$ character_1_gender <chr> \"woman\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", …\n$ character_2_gender <chr> \"man\", \"woman\", \"woman\", \"woman\", \"man\", \"woman\", \"…\n$ actor_1_birthdate  <date> 1896-10-30, 1932-08-02, 1933-03-14, 1930-09-17, 19…\n$ actor_2_birthdate  <date> 1948-03-29, 1982-06-03, 1982-10-01, 1975-11-08, 19…\n$ actor_1_age        <dbl> 75, 74, 69, 68, 81, 59, 62, 69, 57, 77, 59, 56, 65,…\n$ actor_2_age        <dbl> 23, 24, 20, 23, 38, 17, 22, 30, 19, 39, 23, 20, 30,…"
  },
  {
    "objectID": "tidytuesday_exercise.html#actor-and-release-data",
    "href": "tidytuesday_exercise.html#actor-and-release-data",
    "title": "Tidy Tuesday Exercise",
    "section": "Actor and Release Data",
    "text": "Actor and Release Data\n\n(because inquiring minds want to know…)\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.2\n\nARplot <- ggplot() +\n  geom_point(data = leadMdata, aes(x = release_year, y = lead_male_age), color = 'dodgerblue4', size=1.5, shape = 15) +\n  geom_point(data = leadFdata, aes(x = release_year, y = lead_female_age), color = 'deeppink4', size=1.5, shape = 15) +\n    geom_point(data = leadMdata, aes(x = release_year, y = supporting_actor_age), color = 'deepskyblue2', size=1.5, shape = 18) +\n  geom_point(data = leadFdata, aes(x = release_year, y = supporting_actor_age), color = 'deeppink1', size=1.5, shape = 18) +\n  ggtitle(\"Actor Age in Relation to the Movie Release Data\", subtitle = \"Evaluated by Genders\") +\nlabs(x = \"Release Year\", y = \"Actor Ages\") +\n  annotate(geom=\"text\", x=1950, y=75, label=\"Lead Male Actors\", colour=\"dodgerblue4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1950, y=80, label=\"Lead Female Actors\", colour=\"deeppink4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1950, y=65, label=\"Actors that Support Male Leads\", colour=\"deepskyblue2\", size=3, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1950, y=70, label=\"Actors that Support Female Leads\", colour=\"deeppink1\", size=3, family=\"sans\", fontface=\"bold\", angle=0)\n\nARplot\n\n\n\n\nLets look a little closer at lead actors and age gaps\n\nARAplot <- ggplot() +\n  geom_point(data = leadMdata, aes(x = release_year, y = lead_male_age, size = age_difference), fill = 'dodgerblue4', shape = 21, colour = \"black\") +\n  geom_point(data = leadFdata, aes(x = release_year, y = lead_female_age, size = age_difference), fill = 'deeppink4', shape = 21, colour = \"black\") +\n\n  ggtitle(\"Lead Actor Age in Relation to the Movie Release Data\", subtitle = \"Factoring in Age Gaps between Lead and Supporting Actors\") +\n  labs(x = \"Release Year\", y = \"Actor Ages\", color= \"Age Gap\") +\n  annotate(geom=\"text\", x=1950, y=75, label=\"Lead Male Actors\", colour=\"dodgerblue4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1950, y=80, label=\"Lead Female Actors\", colour=\"deeppink4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) \n  \n\n\nARAplot"
  },
  {
    "objectID": "tidytuesday_exercise.html#relationship-between-movie-release-data-age-difference-and-supporting-actor-age",
    "href": "tidytuesday_exercise.html#relationship-between-movie-release-data-age-difference-and-supporting-actor-age",
    "title": "Tidy Tuesday Exercise",
    "section": "Relationship between Movie release data, Age difference, and supporting Actor Age",
    "text": "Relationship between Movie release data, Age difference, and supporting Actor Age\n###Supporting actor age\n\nASAplot <- ggplot() +\n    geom_point(data = leadMdata, aes(x = release_year, y = supporting_actor_age, size = age_difference), fill = 'deepskyblue2', shape = 21, colour = \"black\") +\n  geom_point(data = leadFdata, aes(x = release_year, y = supporting_actor_age, size = age_difference), fill = 'deeppink1', shape = 21, colour = \"black\") +\n  ggtitle(\"Supporting Actor Age in Relation to the Movie Release Data\", subtitle = \"Factoring in Age Gaps between Lead and Supporting Actors\") +\nlabs(x = \"Release Year\", y = \"Actor Ages\") +\n   annotate(geom=\"text\", x=1965, y=60, label=\"Actors that Support Male Leads\", colour=\"deepskyblue2\", size=4, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1965, y=65, label=\"Actors that Support Female Leads\", colour=\"deeppink1\", size=4, family=\"sans\", fontface=\"bold\", angle=0)\n\nASAplot"
  },
  {
    "objectID": "tidytuesday_exercise.html#lead-age-vs-supporting-actor-age",
    "href": "tidytuesday_exercise.html#lead-age-vs-supporting-actor-age",
    "title": "Tidy Tuesday Exercise",
    "section": "Lead Age vs Supporting actor age",
    "text": "Lead Age vs Supporting actor age\n\nOpposite vs Same-sex\n\nlets add some trends\nMales:\n\nSSplot <- ggplot() +\n  geom_point(data = leadMdata, aes(x = age_difference, y = lead_male_age), color = 'dodgerblue4', size=2) +\n  geom_point(data = leadMdata, aes(x = age_difference, y = supporting_actor_age, color = supporting_gender), size=2 , shape = 21) +\n  ggtitle(\"Male Actor Age in Relation to the Age Gaps\", subtitle = \"Evaluated by Supporting Actor Genders\") +\n  labs(x = \"Age Difference Between Supporitng and Lead Actors\", y = \"Actor Ages\") +\n  annotate(geom=\"text\", x=7, y=80, label=\"Lead Male Actors\", colour=\"dodgerblue4\", size=4, family=\"sans\", fontface=\"bold\", angle=0)  + \n  annotate(geom=\"text\", x=7, y=75, label=\"Supporting Actors\", color=\"cyan4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) \n\n\nSSplot \n\n\n\n\nFemales:\n\nSSFplot <- ggplot() +\n  geom_point(data = leadFdata, aes(x = age_difference, y = lead_female_age), color = 'deeppink4', size=2) +\n  geom_point(data = leadFdata, aes(x = age_difference, y = supporting_actor_age, color = supporting_gender), size=2 , shape = 21) +\n  ggtitle(\"Female Actor Age in Relation to the Age Gaps\", subtitle = \"Evaluated by Supporting Actor Genders\") +\n  labs(x = \"Age Difference Between Supporitng and Lead Actors\", y = \"Actor Ages\") +\n  annotate(geom=\"text\", x=10, y=75, label=\"Lead Female Actors\", colour=\"deeppink4\", size=4, family=\"sans\", fontface=\"bold\", angle=0)  + \n  annotate(geom=\"text\", x=10, y=70, label=\"Supporting Actors\", color=\"orangered2\", size=4, family=\"sans\", fontface=\"bold\", angle=0) \n\n\nSSFplot \n\n\n\n\nWow this is pretty striking! The raw cleaned data really shows a disparity between male leads and female leads and the age gap between their supporting actors!\nWe could play with this data forever! I will stop here but if you have a recommendation please post it on my “issues” page of my github!"
  },
  {
    "objectID": "tidytuesday_exercise2.html",
    "href": "tidytuesday_exercise2.html",
    "title": "Tidy Tuesday Exercise 2",
    "section": "",
    "text": "Upload public access data for exercise via tidytuesdayR package.\n\nlibrary(tidytuesdayR)\n\nWarning: package 'tidytuesdayR' was built under R version 4.2.2\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.2.2\n\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n#tuesdata2 <- tidytuesdayR::tt_load(2023, week = 7)\n# <- tuesdata$"
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "https://fivethirtyeight.com/features/marriage-isnt-dead-yet/\nGraph I am trying to replicate:\n\n\n\nUpload raw data to R and install/load packages required to clean data.\n\n#install.packages('dslabs')\n#install.packages('tidyverse')\n#install.packages('here')\n#install.packages('rjson')\n#install.packages('plotly')\n#install.packages('ggthemes')\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.2.2\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(plotly)\n\nWarning: package 'plotly' was built under R version 4.2.2\n\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.2\n\n#import file via relative path\n#raw_bothsexes <- read_csv(here('Visualization_Exercise/raw_data/both_sexes.csv'))\nraw_divorce <- read_csv(here('Visualization_Exercise/raw_data/divorce.csv'))\n\nNew names:\nRows: 17 Columns: 21\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" dbl\n(20): ...1, year, all_3544, HS_3544, SC_3544, BAp_3544, BAo_3544, GD_35... date\n(1): date\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n\n#raw_men <- read_csv(here('Visualization_Exercise/raw_data/men.csv'))\n#raw_women <- read_csv(here('Visualization_Exercise/raw_data/women.csv'))\n\ntibble(raw_divorce)\n\n# A tibble: 17 × 21\n    ...1  year date       all_3544 HS_3544 SC_3544 BAp_3544 BAo_3544 GD_3544\n   <dbl> <dbl> <date>        <dbl>   <dbl>   <dbl>    <dbl>    <dbl>   <dbl>\n 1     1  1960 1960-01-01   0.0344  0.0349  0.0337   0.0275   0.0275 NA     \n 2     2  1970 1970-01-01   0.0493  0.0500  0.0487   0.0413   0.0413 NA     \n 3     3  1980 1980-01-01   0.106   0.104   0.113    0.0978   0.0978 NA     \n 4     4  1990 1990-01-01   0.151   0.159   0.170    0.115    0.119   0.109 \n 5     5  2000 2000-01-01   0.157   0.175   0.174    0.106    0.111   0.0959\n 6     6  2001 2001-01-01   0.157   0.174   0.178    0.107    0.112   0.0972\n 7     7  2002 2002-01-01   0.157   0.175   0.179    0.103    0.110   0.0908\n 8     8  2003 2003-01-01   0.154   0.173   0.177    0.103    0.111   0.0864\n 9     9  2004 2004-01-01   0.155   0.178   0.177    0.100    0.106   0.0891\n10    10  2005 2005-01-01   0.153   0.175   0.177    0.0995   0.107   0.0850\n11    11  2006 2006-01-01   0.162   0.189   0.184    0.104    0.111   0.0905\n12    12  2007 2007-01-01   0.160   0.187   0.185    0.104    0.112   0.0891\n13    13  2008 2008-01-01   0.161   0.188   0.189    0.102    0.111   0.0852\n14    14  2009 2009-01-01   0.160   0.187   0.190    0.102    0.112   0.0844\n15    15  2010 2010-01-01   0.164   0.190   0.197    0.103    0.112   0.0882\n16    16  2011 2011-01-01   0.166   0.192   0.200    0.108    0.117   0.0919\n17    17  2012 2012-01-01   0.165   0.190   0.203    0.107    0.115   0.0943\n# … with 12 more variables: poor_3544 <dbl>, mid_3544 <dbl>, rich_3544 <dbl>,\n#   all_4554 <dbl>, HS_4554 <dbl>, SC_4554 <dbl>, BAp_4554 <dbl>,\n#   BAo_4554 <dbl>, GD_4554 <dbl>, poor_4554 <dbl>, mid_4554 <dbl>,\n#   rich_4554 <dbl>\n\n\n\n\n\nVariables will be:\n\n\nHS | High school graduate or less (EDUCD < 65)\n\n\n\nSC | Some college (EDUCD >= 65 & <= 100)\n\n\n\nBAp | Bachelor’s degree or more (EDUCD > 100) BAo | Bachelor’s degree, no graduate degre (EDUCD > 100 & <= 113) GD | Graduate degree (EDUCD > 113)\nGoal is to have an X- Axis of “Year (Decade)” and a Y-Axis of “% of Divorce with Education” of only ages 35 to 44\n\nclean_Div <- raw_divorce %>%\n  select('year', 'HS_3544', 'SC_3544', 'BAp_3544', 'BAo_3544', 'GD_3544')\n  \nclean_Div$Graduate <- rowMeans(clean_Div[, c(3:5)], na.rm=TRUE)\n#I made the exective decision to get an average of this data because this would be what would me most reminiscent of the original graph. It looks exactly the same as there's after visualization.\n\nclean_Div <- rename(clean_Div, SomeCollege = SC_3544)\nclean_Div <- rename(clean_Div, Highschool = HS_3544)\nclean_Div <- rename(clean_Div, Year = year)\n\nDiv_3345 <- clean_Div %>%\n  select('Year','Highschool', 'SomeCollege', 'Graduate')\n\n\n\n\n\n\nmain <- ggplot(data = Div_3345) +\n  geom_line(aes(x = Year, y = Highschool), color = 'lightblue3', size=1.5) +\n  geom_line(aes(x = Year, y = Graduate), color = \"paleturquoise\", size=1.5) +\n  geom_line(aes(x = Year, y = SomeCollege), color = '#336699', size=1.5) +\n  xlab(\"\") + \n  ylab(\"\") +\n  ggtitle(\"Divorce Rates By Education\", subtitle = \"Ages 35 to 44\") +\n  scale_color_fivethirtyeight() +\n  theme_fivethirtyeight(base_size = 18, base_family = \"sans\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  annotate(geom=\"text\", x=1995, y=.2, label=\"Some College\", colour=\"#336699\",\n             size=6, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=2000, y=.15, label=\"High school or less\", colour=\"lightblue3\",\n             size=6, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=2005, y=.12, label=\"College graduates\", colour=\"paleturquoise\",\n             size=6, family=\"sans\", fontface=\"bold\", angle=0)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n#My biggest issue with this graph is I cannot figure out how they added the labels for each education level with black with lines pointing to each trendline. Is it possible that they did this in lightroom after? To compensate, I made the labels \"float\" near the lines and made their color match.\n\nmain\n\n\n\n##ggthemes had a theme called 'fivethirtyeight' that was very close to what is seen in the original plot. It was found here: https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/theme_fivethirtyeight/\n\n\n\n\n\nggplotly(maintooltip = c(\"text\"))\n\nWarning: plotly.js does not (yet) support horizontal legend items \nYou can track progress here: \nhttps://github.com/plotly/plotly.js/issues/53 \n\n\n\n\n\ntwo <- plotly_build(main)\n\nWarning: plotly.js does not (yet) support horizontal legend items \nYou can track progress here: \nhttps://github.com/plotly/plotly.js/issues/53 \n\nnames(two$x$data[[1]])\n\n [1] \"x\"          \"y\"          \"text\"       \"type\"       \"mode\"      \n [6] \"line\"       \"hoveron\"    \"showlegend\" \"xaxis\"      \"yaxis\"     \n[11] \"hoverinfo\"  \"frame\"     \n\nnames(two$x$layout)\n\n [1] \"margin\"        \"plot_bgcolor\"  \"paper_bgcolor\" \"font\"         \n [5] \"title\"         \"xaxis\"         \"yaxis\"         \"shapes\"       \n [9] \"showlegend\"    \"legend\"        \"hovermode\"     \"barmode\"      \n\n#I am having trouble editing the layout of plotly. The github and help pages have not been very helpful."
  },
  {
    "objectID": "tidytuesday_exercise2.html#us-egg-production",
    "href": "tidytuesday_exercise2.html#us-egg-production",
    "title": "Tidy Tuesday Exercise 2",
    "section": "US Egg Production",
    "text": "US Egg Production\nThe data this week comes from The Humane League’s US Egg Production dataset by Samara Mendez. Dataset and code is available for this project on OSF at US Egg Production Data Set.\nThis dataset tracks the supply of cage-free eggs in the United States from December 2007 to February 2021. For TidyTuesday we’ve used data through February 2021, but the full dataset, with data through the present, is available in the OSF project.\n\nIn this project, they synthesize an analysis-ready data set that tracks cage-free hens and the supply of cage-free eggs relative to the overall numbers of hens and table eggs in the United States. The data set is based on reports produced by the United States Department of Agriculture (USDA), which are published weekly or monthly. They supplement these data with definitions and a taxonomy of egg products drawn from USDA and industry publications. The data include flock size (both absolute and relative) and egg production of cage-free hens as well as all table-egg-laying hens in the US, collected to understand the impact of the industry’s cage-free transition on hens. Data coverage ranges from December 2007 to February 2021.\n\n\nEgg Production\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nobserved_month\ndouble\nMonth in which report observations are collected,Dates are recorded in ISO 8601 format YYYY-MM-DD\n\n\nprod_type\ncharacter\ntype of egg product: hatching, table eggs\n\n\nprod_process\ncharacter\ntype of production process and housing: cage-free (organic), cage-free (non-organic), all. The value ‘all’ includes cage-free and conventional housing.\n\n\nn_hens\ndouble\nnumber of hens produced by hens for a given month-type-process combo\n\n\nn_eggs\ndouble\nnumber of eggs producing eggs for a given month-type-process combo\n\n\nsource\ncharacter\nOriginal USDA report from which data are sourced. Values correspond to titles of PDF reports. Date of report is included in title.\n\n\n\n\n\nCage Free Percentages\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nobserved_month\ndouble\nMonth in which report observations are collected,Dates are recorded in ISO 8601 format YYYY-MM-DD\n\n\npercent_hens\ndouble\nobserved or computed percentage of cage-free hens relative to all table-egg-laying hens\n\n\npercent_eggs\ndouble\ncomputed percentage of cage-free eggs relative to all table eggs,This variable is not available for data sourced from the Egg Markets Overview report\n\n\nsource\ncharacter\nOriginal USDA report from which data are sourced. Values correspond to titles of PDF reports. Date of report is included in title.\n\n\n\n#Exploring Egg Production\n\ntibble(eggproduction)\n\n# A tibble: 220 × 6\n   observed_month prod_type     prod_process   n_hens     n_eggs source         \n   <date>         <chr>         <chr>           <dbl>      <dbl> <chr>          \n 1 2016-07-31     hatching eggs all          57975000 1147000000 ChicEggs-09-23…\n 2 2016-08-31     hatching eggs all          57595000 1142700000 ChicEggs-10-21…\n 3 2016-09-30     hatching eggs all          57161000 1093300000 ChicEggs-11-22…\n 4 2016-10-31     hatching eggs all          56857000 1126700000 ChicEggs-12-23…\n 5 2016-11-30     hatching eggs all          57116000 1096600000 ChicEggs-01-24…\n 6 2016-12-31     hatching eggs all          57750000 1132900000 ChicEggs-02-28…\n 7 2017-01-31     hatching eggs all          57991000 1123400000 ChicEggs-03-21…\n 8 2017-02-28     hatching eggs all          58286000 1014500000 ChicEggs-04-21…\n 9 2017-03-31     hatching eggs all          58735000 1128500000 ChicEggs-05-22…\n10 2017-04-30     hatching eggs all          59072000 1097200000 ChicEggs-06-23…\n# ℹ 210 more rows\n\nggplot() +\n    geom_point(data = eggproduction, aes(x = n_hens, y = n_eggs, color = prod_process), shape = 19) +\n    ggtitle(\"Laying Efficency\", subtitle = \"Number of hens vs number of eggs laid\") +\n    labs(x = \"Hens\", y = \"Eggs\")\n\n\n\nggplot() +\n    geom_point(data = eggproduction, aes(x = n_hens, y = n_eggs, color = prod_process), shape = 19) +\n    ggtitle(\"Laying Efficency\", subtitle = \"Number of hens vs number of eggs laid\") +\n    labs(x = \"Hens\", y = \"Eggs\") +\n    xlim(0, 70000000) +\n    ylim(0, 1700000000)\n\nWarning: Removed 55 rows containing missing values (`geom_point()`).\n\n\n\n\nggplot() +\n    geom_line(data = eggproduction, aes(x = observed_month, y = n_eggs, color = prod_process)) +\n    ggtitle(\"Eggs Production over time\", subtitle = \"\") +\n    labs(x = \"Time\", y = \"Eggs\")\n\n\n\n\n#Exploring Cage Free %\n\ntibble(cagefreepercentages)\n\n# A tibble: 96 × 4\n   observed_month percent_hens percent_eggs source                             \n   <date>                <dbl>        <dbl> <chr>                              \n 1 2007-12-31              3.2           NA Egg-Markets-Overview-2019-10-19.pdf\n 2 2008-12-31              3.5           NA Egg-Markets-Overview-2019-10-19.pdf\n 3 2009-12-31              3.6           NA Egg-Markets-Overview-2019-10-19.pdf\n 4 2010-12-31              4.4           NA Egg-Markets-Overview-2019-10-19.pdf\n 5 2011-12-31              5.4           NA Egg-Markets-Overview-2019-10-19.pdf\n 6 2012-12-31              6             NA Egg-Markets-Overview-2019-10-19.pdf\n 7 2013-12-31              5.9           NA Egg-Markets-Overview-2019-10-19.pdf\n 8 2014-12-31              5.7           NA Egg-Markets-Overview-2019-10-19.pdf\n 9 2015-12-31              8.6           NA Egg-Markets-Overview-2019-10-19.pdf\n10 2016-04-30              9.9           NA Egg-Markets-Overview-2016-12-02.pdf\n# ℹ 86 more rows\n\nggplot() +\n    geom_line(data = cagefreepercentages, aes(x = observed_month, y = percent_eggs), color =  'darkgreen') +\n    geom_line(data = cagefreepercentages, aes(x = observed_month, y = percent_hens), color =  'brown') +\n    ggtitle(\"% Hens and Eggs relative to all Tables\", subtitle = \"\") +\n    labs(x = \"Year\", y = \"Hens & Eggs (%)\")\n\nWarning: Removed 11 rows containing missing values (`geom_line()`).\n\n\n\n\n\nWill merge data via date\n\nALLdata <- inner_join(cagefreepercentages, eggproduction, by=\"observed_month\")\n\nWarning in inner_join(cagefreepercentages, eggproduction, by = \"observed_month\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 11 of `x` matches multiple rows in `y`.\nℹ Row 2 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntibble(ALLdata)\n\n# A tibble: 238 × 9\n   observed_month percent_hens percent_eggs source.x      prod_type prod_process\n   <date>                <dbl>        <dbl> <chr>         <chr>     <chr>       \n 1 2016-08-31             10.1         9.63 computed      hatching… all         \n 2 2016-08-31             10.1         9.63 computed      table eg… all         \n 3 2016-08-31             10.1         9.63 computed      table eg… cage-free (…\n 4 2016-08-31             10.1         9.63 computed      table eg… cage-free (…\n 5 2016-08-31             12          NA    Egg-Markets-… hatching… all         \n 6 2016-08-31             12          NA    Egg-Markets-… table eg… all         \n 7 2016-08-31             12          NA    Egg-Markets-… table eg… cage-free (…\n 8 2016-08-31             12          NA    Egg-Markets-… table eg… cage-free (…\n 9 2016-09-30             10.1         9.56 computed      hatching… all         \n10 2016-09-30             10.1         9.56 computed      table eg… all         \n# ℹ 228 more rows\n# ℹ 3 more variables: n_hens <dbl>, n_eggs <dbl>, source.y <chr>\n\n#Now to avoid confusion remove sources and prod_process \"all\"\n\nallclean <- ALLdata %>%\n  select(observed_month  | percent_hens | n_hens | percent_eggs |  n_eggs | prod_process) %>%\n  filter(!prod_process == 'all')\n\ntibble(allclean)\n\n# A tibble: 120 × 6\n   observed_month percent_hens   n_hens percent_eggs     n_eggs prod_process    \n   <date>                <dbl>    <dbl>        <dbl>      <dbl> <chr>           \n 1 2016-08-31             10.1 17000000         9.63 397884291. cage-free (non-…\n 2 2016-08-31             10.1 13500000         9.63 315968297. cage-free (orga…\n 3 2016-08-31             12   17000000        NA    397884291. cage-free (non-…\n 4 2016-08-31             12   13500000        NA    315968297. cage-free (orga…\n 5 2016-09-30             10.1 17000000         9.56 383774914. cage-free (non-…\n 6 2016-09-30             10.1 13500000         9.56 304762114. cage-free (orga…\n 7 2016-10-31             12.3 23500000        11.6  546374469. cage-free (non-…\n 8 2016-10-31             12.3 14100000        11.6  327825000  cage-free (orga…\n 9 2016-11-30             12.1 23500000        11.4  530864743. cage-free (non-…\n10 2016-11-30             12.1 14100000        11.4  318519771. cage-free (orga…\n# ℹ 110 more rows\n\n\nMore data visualization\n\nggplot() +\n  geom_point(data = allclean, aes(x = observed_month, y = percent_hens, size = n_hens), fill = 'brown', shape = 21, colour = \"black\") +\n  geom_point(data = allclean, aes(x = observed_month, y = percent_eggs, size = n_eggs), fill = 'gold', shape = 21, colour = \"black\")  +\n  ggtitle(\"Cage free eggs vs Years\", subtitle = \"\") +\nlabs(x = \"Year\", y = \"% Eggs and Hens\")\n\nWarning: Removed 12 rows containing missing values (`geom_point()`).\n\n\n\n\nggplot() +\n  geom_line(data = allclean, aes(x = observed_month, y = n_hens, colour = prod_process)) +\n  ggtitle(\"Cage free hens\", subtitle = \"Organic vs non-Organic\") +\nlabs(x = \"Year\", y = \"Hens\")\n\n\n\nggplot() +\n  geom_line(data = allclean, aes(x = observed_month, y = n_eggs, colour = prod_process)) +\n  ggtitle(\"Cage free egg production\", subtitle = \"Organic vs non-Organic\") +\nlabs(x = \"Year\", y = \"Eggs\")\n\n\n\n\nAs the demand for cage free eggs increases so do the number of hens producing them.However, it seems like egg production may be less efficient in organic hens. We are going to explore!\n#Fitting a model ##Hypothesis: Non-organic egg production is more efficient (more eggs produced per hen), then organic egg production in cage-free facilities.\n###Data Setup\n\n#prepare data for machine learning\n\nset.seed(123)\n# Fix the random numbers by setting the seed \n\ncdata_split <- initial_split(allclean, prop = 2.8/4, strata = prod_process) #70% training, 30% testing\n\n# Create data frames for the two sets:\ntrain_cdata <- training(cdata_split)\ntest_cdata  <- testing(cdata_split)\n\n#5-fold cross-validation, 5 times repeated\nfold_cdata <- vfold_cv(train_cdata, v = 5, repeats = 5, strata = prod_process)\n\n#Create a recipe for the data and fitting. \ndata_recipe <- recipe(prod_process ~ ., data = train_cdata) %>%\n  step_dummy(all_nominal(), -all_outcomes())"
  }
]