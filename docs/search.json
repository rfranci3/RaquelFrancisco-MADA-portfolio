[
  {
    "objectID": "tidytuesday_exercise2.html#us-egg-production",
    "href": "tidytuesday_exercise2.html#us-egg-production",
    "title": "Tidy Tuesday Exercise 2",
    "section": "US Egg Production",
    "text": "US Egg Production\nThe data this week comes from The Humane League’s US Egg Production dataset by Samara Mendez. Dataset and code is available for this project on OSF at US Egg Production Data Set.\nThis dataset tracks the supply of cage-free eggs in the United States from December 2007 to February 2021. For TidyTuesday we’ve used data through February 2021, but the full dataset, with data through the present, is available in the OSF project.\n\nIn this project, they synthesize an analysis-ready data set that tracks cage-free hens and the supply of cage-free eggs relative to the overall numbers of hens and table eggs in the United States. The data set is based on reports produced by the United States Department of Agriculture (USDA), which are published weekly or monthly. They supplement these data with definitions and a taxonomy of egg products drawn from USDA and industry publications. The data include flock size (both absolute and relative) and egg production of cage-free hens as well as all table-egg-laying hens in the US, collected to understand the impact of the industry’s cage-free transition on hens. Data coverage ranges from December 2007 to February 2021.\n\n\nEgg Production\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nobserved_month\ndouble\nMonth in which report observations are collected,Dates are recorded in ISO 8601 format YYYY-MM-DD\n\n\nprod_type\ncharacter\ntype of egg product: hatching, table eggs\n\n\nprod_process\ncharacter\ntype of production process and housing: cage-free (organic), cage-free (non-organic), all. The value ‘all’ includes cage-free and conventional housing.\n\n\nn_hens\ndouble\nnumber of hens produced by hens for a given month-type-process combo\n\n\nn_eggs\ndouble\nnumber of eggs producing eggs for a given month-type-process combo\n\n\nsource\ncharacter\nOriginal USDA report from which data are sourced. Values correspond to titles of PDF reports. Date of report is included in title.\n\n\n\n\n\nCage Free Percentages\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\nobserved_month\ndouble\nMonth in which report observations are collected,Dates are recorded in ISO 8601 format YYYY-MM-DD\n\n\npercent_hens\ndouble\nobserved or computed percentage of cage-free hens relative to all table-egg-laying hens\n\n\npercent_eggs\ndouble\ncomputed percentage of cage-free eggs relative to all table eggs,This variable is not available for data sourced from the Egg Markets Overview report\n\n\nsource\ncharacter\nOriginal USDA report from which data are sourced. Values correspond to titles of PDF reports. Date of report is included in title.\n\n\n\n#Exploring Egg Production\n\ntibble(eggproduction)\n\n# A tibble: 220 × 6\n   observed_month prod_type     prod_process   n_hens     n_eggs source         \n   <date>         <chr>         <chr>           <dbl>      <dbl> <chr>          \n 1 2016-07-31     hatching eggs all          57975000 1147000000 ChicEggs-09-23…\n 2 2016-08-31     hatching eggs all          57595000 1142700000 ChicEggs-10-21…\n 3 2016-09-30     hatching eggs all          57161000 1093300000 ChicEggs-11-22…\n 4 2016-10-31     hatching eggs all          56857000 1126700000 ChicEggs-12-23…\n 5 2016-11-30     hatching eggs all          57116000 1096600000 ChicEggs-01-24…\n 6 2016-12-31     hatching eggs all          57750000 1132900000 ChicEggs-02-28…\n 7 2017-01-31     hatching eggs all          57991000 1123400000 ChicEggs-03-21…\n 8 2017-02-28     hatching eggs all          58286000 1014500000 ChicEggs-04-21…\n 9 2017-03-31     hatching eggs all          58735000 1128500000 ChicEggs-05-22…\n10 2017-04-30     hatching eggs all          59072000 1097200000 ChicEggs-06-23…\n# ℹ 210 more rows\n\nggplot() +\n    geom_point(data = eggproduction, aes(x = n_hens, y = n_eggs, color = prod_process), shape = 19) +\n    ggtitle(\"Laying Efficency\", subtitle = \"Number of hens vs number of eggs laid\") +\n    labs(x = \"Hens\", y = \"Eggs\")\n\n\n\nggplot() +\n    geom_point(data = eggproduction, aes(x = n_hens, y = n_eggs, color = prod_process), shape = 19) +\n    ggtitle(\"Laying Efficency\", subtitle = \"Number of hens vs number of eggs laid\") +\n    labs(x = \"Hens\", y = \"Eggs\") +\n    xlim(0, 70000000) +\n    ylim(0, 1700000000)\n\nWarning: Removed 55 rows containing missing values (`geom_point()`).\n\n\n\n\nggplot() +\n    geom_line(data = eggproduction, aes(x = observed_month, y = n_eggs, color = prod_process)) +\n    ggtitle(\"Eggs Production over time\", subtitle = \"\") +\n    labs(x = \"Time\", y = \"Eggs\")\n\n\n\n\n#Exploring Cage Free %\n\ntibble(cagefreepercentages)\n\n# A tibble: 96 × 4\n   observed_month percent_hens percent_eggs source                             \n   <date>                <dbl>        <dbl> <chr>                              \n 1 2007-12-31              3.2           NA Egg-Markets-Overview-2019-10-19.pdf\n 2 2008-12-31              3.5           NA Egg-Markets-Overview-2019-10-19.pdf\n 3 2009-12-31              3.6           NA Egg-Markets-Overview-2019-10-19.pdf\n 4 2010-12-31              4.4           NA Egg-Markets-Overview-2019-10-19.pdf\n 5 2011-12-31              5.4           NA Egg-Markets-Overview-2019-10-19.pdf\n 6 2012-12-31              6             NA Egg-Markets-Overview-2019-10-19.pdf\n 7 2013-12-31              5.9           NA Egg-Markets-Overview-2019-10-19.pdf\n 8 2014-12-31              5.7           NA Egg-Markets-Overview-2019-10-19.pdf\n 9 2015-12-31              8.6           NA Egg-Markets-Overview-2019-10-19.pdf\n10 2016-04-30              9.9           NA Egg-Markets-Overview-2016-12-02.pdf\n# ℹ 86 more rows\n\nggplot() +\n    geom_line(data = cagefreepercentages, aes(x = observed_month, y = percent_eggs), color =  'darkgreen') +\n    geom_line(data = cagefreepercentages, aes(x = observed_month, y = percent_hens), color =  'brown') +\n    ggtitle(\"% Hens and Eggs relative to all Tables\", subtitle = \"\") +\n    labs(x = \"Year\", y = \"Hens & Eggs (%)\")\n\nWarning: Removed 11 rows containing missing values (`geom_line()`).\n\n\n\n\n\nWill merge data via date\n\nALLdata <- inner_join(cagefreepercentages, eggproduction, by=\"observed_month\")\n\nWarning in inner_join(cagefreepercentages, eggproduction, by = \"observed_month\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 11 of `x` matches multiple rows in `y`.\nℹ Row 2 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\ntibble(ALLdata)\n\n# A tibble: 238 × 9\n   observed_month percent_hens percent_eggs source.x      prod_type prod_process\n   <date>                <dbl>        <dbl> <chr>         <chr>     <chr>       \n 1 2016-08-31             10.1         9.63 computed      hatching… all         \n 2 2016-08-31             10.1         9.63 computed      table eg… all         \n 3 2016-08-31             10.1         9.63 computed      table eg… cage-free (…\n 4 2016-08-31             10.1         9.63 computed      table eg… cage-free (…\n 5 2016-08-31             12          NA    Egg-Markets-… hatching… all         \n 6 2016-08-31             12          NA    Egg-Markets-… table eg… all         \n 7 2016-08-31             12          NA    Egg-Markets-… table eg… cage-free (…\n 8 2016-08-31             12          NA    Egg-Markets-… table eg… cage-free (…\n 9 2016-09-30             10.1         9.56 computed      hatching… all         \n10 2016-09-30             10.1         9.56 computed      table eg… all         \n# ℹ 228 more rows\n# ℹ 3 more variables: n_hens <dbl>, n_eggs <dbl>, source.y <chr>\n\n#Now to avoid confusion remove sources and prod_process \"all\"\n\nallclean <- ALLdata %>%\n  select(observed_month  | percent_hens | n_hens | percent_eggs |  n_eggs | prod_process) %>%\n  filter(!prod_process == 'all')\n\ntibble(allclean)\n\n# A tibble: 120 × 6\n   observed_month percent_hens   n_hens percent_eggs     n_eggs prod_process    \n   <date>                <dbl>    <dbl>        <dbl>      <dbl> <chr>           \n 1 2016-08-31             10.1 17000000         9.63 397884291. cage-free (non-…\n 2 2016-08-31             10.1 13500000         9.63 315968297. cage-free (orga…\n 3 2016-08-31             12   17000000        NA    397884291. cage-free (non-…\n 4 2016-08-31             12   13500000        NA    315968297. cage-free (orga…\n 5 2016-09-30             10.1 17000000         9.56 383774914. cage-free (non-…\n 6 2016-09-30             10.1 13500000         9.56 304762114. cage-free (orga…\n 7 2016-10-31             12.3 23500000        11.6  546374469. cage-free (non-…\n 8 2016-10-31             12.3 14100000        11.6  327825000  cage-free (orga…\n 9 2016-11-30             12.1 23500000        11.4  530864743. cage-free (non-…\n10 2016-11-30             12.1 14100000        11.4  318519771. cage-free (orga…\n# ℹ 110 more rows\n\n\nMore data visualization\n\nggplot() +\n  geom_point(data = allclean, aes(x = observed_month, y = percent_hens, size = n_hens), fill = 'brown', shape = 21, colour = \"black\") +\n  geom_point(data = allclean, aes(x = observed_month, y = percent_eggs, size = n_eggs), fill = 'gold', shape = 21, colour = \"black\")  +\n  ggtitle(\"Cage free eggs vs Years\", subtitle = \"\") +\nlabs(x = \"Year\", y = \"% Eggs and Hens\")\n\nWarning: Removed 12 rows containing missing values (`geom_point()`).\n\n\n\n\nggplot() +\n  geom_line(data = allclean, aes(x = observed_month, y = n_hens, colour = prod_process)) +\n  ggtitle(\"Cage free hens\", subtitle = \"Organic vs non-Organic\") +\nlabs(x = \"Year\", y = \"Hens\")\n\n\n\nggplot() +\n  geom_line(data = allclean, aes(x = observed_month, y = n_eggs, colour = prod_process)) +\n  ggtitle(\"Cage free egg production\", subtitle = \"Organic vs non-Organic\") +\nlabs(x = \"Year\", y = \"Eggs\")\n\n\n\n\nAs the demand for cage free eggs increases so do the number of hens producing them.However, it seems like egg production may be less efficient in organic hens. We are going to explore!\n#Fitting a model ##Hypothesis: Non-organic egg production is more efficient (more eggs produced per hen), then organic egg production in cage-free facilities.\n###Data Setup\n\n#prepare data for machine learning\n\nset.seed(123)\n# Fix the random numbers by setting the seed \n\ncdata_split <- initial_split(allclean, prop = 2.8/4, strata = n_eggs) #70% training, 30% testing\n\n# Create data frames for the two sets:\ntrain_cdata <- training(cdata_split)\ntest_cdata  <- testing(cdata_split)\n\n#5-fold cross-validation, 5 times repeated\nfold_cdata <- vfold_cv(train_cdata, v = 5, repeats = 5, strata = prod_process)\n\n#Create a recipe for the data and fitting. \ndata_recipe <- recipe(n_eggs ~ prod_process, data = train_cdata) %>%\n  step_dummy(all_nominal(), -all_outcomes())"
  },
  {
    "objectID": "tidytuesday_exercise2.html#null-model-performance",
    "href": "tidytuesday_exercise2.html#null-model-performance",
    "title": "Tidy Tuesday Exercise 2",
    "section": "Null model performance",
    "text": "Null model performance\n\nnull_recipe <- recipe(n_eggs ~ 1, data = train_cdata) %>%\n  step_dummy(all_nominal(), -all_outcomes())\n\n# Logistic model recipe\nrecipe_mod <- linear_reg() %>% \n  set_engine(\"lm\") %>% \n  set_mode(\"regression\")\n\n# Model workflow to pair model and recipe \nnull_flow <- workflow() %>% \n  add_model(recipe_mod) %>% \n  add_recipe(null_recipe)\n\n#fit the null model to the folds made from the train data set.\nnull_train <- fit_resamples(null_flow, resamples = fold_cdata)\n\n→ A | warning: There was 1 warning in `dplyr::summarise()`.\n               ℹ In argument: `.estimate = metric_fn(truth = n_eggs, estimate = .pred, na_rm =\n                 na_rm)`.\n               Caused by warning:\n               ! A correlation computation is required, but `estimate` is constant and has 0 standard deviation, resulting in a divide by 0 error. `NA` will be returned.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x7\n\n\nThere were issues with some computations   A: x13\n\n\nThere were issues with some computations   A: x21\n\n\nThere were issues with some computations   A: x25\n\n\n\n\n#Compute the RMSE for both training and test data\nNull_Met <- collect_metrics(null_train)\nNull_Met\n\n# A tibble: 2 × 6\n  .metric .estimator       mean     n   std_err .config             \n  <chr>   <chr>           <dbl> <int>     <dbl> <chr>               \n1 rmse    standard   391114191.    25 10381628. Preprocessor1_Model1\n2 rsq     standard         NaN      0       NA  Preprocessor1_Model1\n\n#RMSE = 391114191\n\n###Test Data with a linear model\n\nlm_flow <- workflow() %>% \n  add_model(recipe_mod) %>% \n  add_recipe(data_recipe)\n\nfit<- lm_flow %>%\n  fit(data = train_cdata)\n\nfit %>%\n  extract_fit_parsnip() %>%\n  tidy()\n\n# A tibble: 2 × 5\n  term                                estimate std.error statistic  p.value\n  <chr>                                  <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)                       990483520. 35900514.      27.6 2.94e-43\n2 prod_process_cage.free..organic. -637575077. 50770994.     -12.6 8.55e-21\n\n\n###Performance metrics\n\naug_test <- augment(fit, train_cdata)\nrmse <- aug_test %>% rmse(truth = n_eggs, .pred)\nrsq <- aug_test %>% rsq(truth = n_eggs, .pred)\nmetrics<- full_join(rmse, rsq)\n\nJoining with `by = join_by(.metric, .estimator, .estimate)`\n\nmetrics\n\n# A tibble: 2 × 3\n  .metric .estimator     .estimate\n  <chr>   <chr>              <dbl>\n1 rmse    standard   229875450.   \n2 rsq     standard           0.658\n\n#RMSE = 2.298755e+08\n#Something is going wrong here\n\n#Residuals?\negg_mod<- lm(n_eggs ~ prod_process, data = train_cdata)\nres<- resid(egg_mod)\nplot(fitted(egg_mod), res)\n\n\n\n\n#Tree model\n\n#Tune\ntune_spec_dtree <- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()) %>%\n  set_engine(\"rpart\") %>% \n  set_mode(\"regression\")\ntune_spec_dtree\n\nDecision Tree Model Specification (regression)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\ndtree_wf <- workflow() %>%\n  add_model(tune_spec_dtree) %>%\n  add_recipe(data_recipe)\n\n#create a regular grid of values to try using some convenience functions \n\ntree_grid_dtree <-\n  grid_regular(\n    cost_complexity(), \n    tree_depth(), \n    levels = 5)\n\ntree_grid_dtree\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             <dbl>      <int>\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n#### Tuning using Cross-validation\n\ndtree_resample <- \n  dtree_wf %>% \n  tune_grid(\n    resamples = fold_cdata,\n    grid = tree_grid_dtree)\n\ndtree_resample %>%\n  collect_metrics()\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric .estimator      mean     n std_err .config\n             <dbl>      <int> <chr>   <chr>          <dbl> <int>   <dbl> <chr>  \n 1    0.0000000001          1 rmse    standard     2.35e+8    25 6.29e+6 Prepro…\n 2    0.0000000001          1 rsq     standard     6.78e-1    25 1.72e-2 Prepro…\n 3    0.0000000178          1 rmse    standard     2.35e+8    25 6.29e+6 Prepro…\n 4    0.0000000178          1 rsq     standard     6.78e-1    25 1.72e-2 Prepro…\n 5    0.00000316            1 rmse    standard     2.35e+8    25 6.29e+6 Prepro…\n 6    0.00000316            1 rsq     standard     6.78e-1    25 1.72e-2 Prepro…\n 7    0.000562              1 rmse    standard     2.35e+8    25 6.29e+6 Prepro…\n 8    0.000562              1 rsq     standard     6.78e-1    25 1.72e-2 Prepro…\n 9    0.1                   1 rmse    standard     2.35e+8    25 6.29e+6 Prepro…\n10    0.1                   1 rsq     standard     6.78e-1    25 1.72e-2 Prepro…\n# ℹ 40 more rows"
  },
  {
    "objectID": "tidytuesday_exercise2.html#plot",
    "href": "tidytuesday_exercise2.html#plot",
    "title": "Tidy Tuesday Exercise 2",
    "section": "Plot",
    "text": "Plot\n\ndtree_resample %>%\n  collect_metrics() %>%\n  mutate(tree_depth = factor(tree_depth)) %>%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(linewidth = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\ndtree_resample %>%\n  show_best(n=1)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 1 × 8\n  cost_complexity tree_depth .metric .estimator       mean     n std_err .config\n            <dbl>      <int> <chr>   <chr>           <dbl> <int>   <dbl> <chr>  \n1    0.0000000001          1 rmse    standard   234787516.    25  6.29e6 Prepro…\n\n#these numbers are strange...\n\nbest_tree <- dtree_resample %>%\n  select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\nbest_tree\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            <dbl>      <int> <chr>                \n1    0.0000000001          1 Preprocessor1_Model01\n\n\n#Make workflow\n\ndtree_final_wf <- \n  dtree_wf %>% \n  finalize_workflow(best_tree)\n\ndtree_final_fit <- \n  dtree_final_wf %>%\n  fit(train_cdata) \n\ndtree_residuals <- dtree_final_fit %>%\n  augment(train_cdata) %>%\n  select(c(.pred, n_eggs)) %>%\n  mutate(.resid = n_eggs - .pred) \n  \n#calculate residuals and make new row.\ndtree_residuals\n\n# A tibble: 84 × 3\n        .pred     n_eggs     .resid\n        <dbl>      <dbl>      <dbl>\n 1 352908443. 304762114. -48146329.\n 2 352908443. 327825000  -25083443.\n 3 352908443. 318519771. -34388672.\n 4 352908443. 325639234. -27269209.\n 5 352908443. 330010766. -22897678.\n 6 352908443. 298074240  -54834203.\n 7 352908443. 333754149. -19154295.\n 8 352908443. 333754149. -19154295.\n 9 352908443. 330689829. -22218615.\n10 352908443. 341712823. -11195620.\n# ℹ 74 more rows\n\n\n##Plot Pred vs Actual & Residuals\n\n#Actual\ndtree_pred_plot <- ggplot(dtree_residuals, \n                          aes(x = n_eggs, \n                              y = .pred)) + \n  geom_point() + \n  labs(title = \"Predictions vs Actual: Decision Tree\", \n       x = \"Egg Outcome\", \n       y = \"Egg Prediction\")\n\ndtree_pred_plot\n\n\n\n#Residuals\n\ndtree_residual_plot <- ggplot(dtree_residuals, \n                              aes(y = .resid, \n                                  x = .pred)) + \n  geom_point() + \n  labs(title = \"Predictions vs Residuals: Decision Tree\", \n       x = \"Egg Prediction\", \n       y = \"Residuals\")\n\nplot(dtree_residual_plot)\n\n\n\n\n\nRegression Tree\n\ntree <- rpart(n_eggs ~ prod_process, data = train_cdata)\n\nrpart.plot(tree)\n\n\n\np <- predict(tree, train_cdata)\n\nrmse<- sqrt(mean(train_cdata$n_eggs - p))\n\nr2<- (cor(train_cdata$n_eggs,p))\n\nr2\n\n[1] 0.8111138\n\nrmse\n\n[1] 0.0004083695\n\n\n###Random Forest Model\n\n#detect cores for RFM computation\ncores <- parallel::detectCores()\ncores\n\n[1] 4\n\n#Specify Model\nrf_mod <- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% \n  set_engine(\"ranger\", num.threads = cores) %>% \n  set_mode(\"regression\")\n\n#Crea Wortekflow\nrf_wf <- workflow() %>%\n  add_model(rf_mod) %>%\n  add_recipe(data_recipe)\n\n#Create Tuning Grid\nrf_grid  <- expand.grid(mtry = c(3, 4, 5, 6),\n                        min_n = c(40,50,60), \n                        trees = c(500,1000)  )\n\n#Cross-validation\nrf_resample <- \n  rf_wf %>% \n  tune_grid(fold_cdata,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(yardstick::rmse))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\nrf_resample %>%\n  collect_metrics()\n\n# A tibble: 23 × 8\n    mtry min_n .metric .estimator       mean     n  std_err .config             \n   <int> <int> <chr>   <chr>           <dbl> <int>    <dbl> <chr>               \n 1     1    34 rmse    standard   234869869.    25 6236595. Preprocessor1_Model…\n 2     1     8 rmse    standard   234791478.    25 6314424. Preprocessor1_Model…\n 3     1    30 rmse    standard   234709445.    25 6291365. Preprocessor1_Model…\n 4     1    36 rmse    standard   234677565.    25 6304081. Preprocessor1_Model…\n 5     1    27 rmse    standard   234944370.    25 6302353. Preprocessor1_Model…\n 6     1    11 rmse    standard   234869238.    25 6302126. Preprocessor1_Model…\n 7     1     6 rmse    standard   234888556.    25 6333906. Preprocessor1_Model…\n 8     1    23 rmse    standard   234716166.    25 6280759. Preprocessor1_Model…\n 9     1    19 rmse    standard   234744630.    25 6313443. Preprocessor1_Model…\n10     1    15 rmse    standard   234777118.    25 6259570. Preprocessor1_Model…\n# ℹ 13 more rows\n\n#select best models\nrf_resample %>%\n  show_best(n=1)\n\n# A tibble: 1 × 8\n   mtry min_n .metric .estimator       mean     n  std_err .config              \n  <int> <int> <chr>   <chr>           <dbl> <int>    <dbl> <chr>                \n1     1    36 rmse    standard   234677565.    25 6304081. Preprocessor1_Model04\n\n#Selects best performing model\nbest_rf <- rf_resample %>%\n  select_best(method = \"rmse\")\n\n#RMSE = 234720024 STD_ERR = 6282911"
  },
  {
    "objectID": "fluanalysis/code/fitting.html",
    "href": "fluanalysis/code/fitting.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Flu Analysis: Fitting\n\nLoad the data and packages:\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels) #build models\n\nWarning: package 'tidymodels' was built under R version 4.2.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.3     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'infer' was built under R version 4.2.2\n\n\nWarning: package 'modeldata' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\n\nWarning: package 'rsample' was built under R version 4.2.2\n\n\nWarning: package 'tune' was built under R version 4.2.2\n\n\nWarning: package 'workflows' was built under R version 4.2.2\n\n\nWarning: package 'workflowsets' was built under R version 4.2.2\n\n\nWarning: package 'yardstick' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(here) #help read/import data\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(ggplot2) #data visualization\nlibrary(broom.mixed) # for converting bayesian models to tidy tibbles\n\nWarning: package 'broom.mixed' was built under R version 4.2.2\n\nlibrary(dotwhisker)  # for visualizing regression results\n\nWarning: package 'dotwhisker' was built under R version 4.2.2\n\nlibrary(performance) #evaluate model fit and performance\n\nWarning: package 'performance' was built under R version 4.2.2\n\n\n\nAttaching package: 'performance'\n\nThe following objects are masked from 'package:yardstick':\n\n    mae, rmse\n\ndata <- readRDS(here('fluanalysis/data/SypAct_clean.rds')) #upload cleaned data\ntibble(data) # to get a look at the data\n\n# A tibble: 730 × 26\n   SwollenLymph…¹ Chest…² Chill…³ Nasal…⁴ Sneeze Fatigue Subje…⁵ Heada…⁶ Weakn…⁷\n   <fct>          <fct>   <fct>   <fct>   <fct>  <fct>   <fct>   <fct>   <fct>  \n 1 Yes            No      No      No      No     Yes     Yes     Yes     Mild   \n 2 Yes            Yes     No      Yes     No     Yes     Yes     Yes     Severe \n 3 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 4 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 5 Yes            No      Yes     No      No     Yes     Yes     Yes     Modera…\n 6 No             No      Yes     No      Yes    Yes     Yes     Yes     Modera…\n 7 No             No      Yes     No      No     Yes     Yes     No      Mild   \n 8 No             Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 9 Yes            Yes     Yes     Yes     No     Yes     Yes     Yes     Modera…\n10 No             Yes     No      Yes     No     Yes     No      Yes     Modera…\n# … with 720 more rows, 17 more variables: CoughIntensity <fct>, Myalgia <fct>,\n#   RunnyNose <fct>, AbPain <fct>, ChestPain <fct>, Diarrhea <fct>,\n#   EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>, EarPn <fct>,\n#   Pharyngitis <fct>, Breathless <fct>, ToothPn <fct>, Vomit <fct>,\n#   Wheeze <fct>, BodyTemp <dbl>, and abbreviated variable names\n#   ¹​SwollenLymphNodes, ²​ChestCongestion, ³​ChillsSweats, ⁴​NasalCongestion,\n#   ⁵​SubjectiveFever, ⁶​Headache, ⁷​Weakness\n\nstr(data)\n\n'data.frame':   730 obs. of  26 variables:\n $ SwollenLymphNodes: Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 1 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"Swollen Lymph Nodes\"\n $ ChestCongestion  : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Chest Congestion\"\n $ ChillsSweats     : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 2 2 2 1 ...\n  ..- attr(*, \"label\")= chr \"Chills/Sweats\"\n $ NasalCongestion  : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 2 1 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Nasal Congestion\"\n $ Sneeze           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 1 2 1 2 1 1 ...\n  ..- attr(*, \"label\")= chr \"Sneeze\"\n $ Fatigue          : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Fatigue\"\n $ SubjectiveFever  : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 1 ...\n  ..- attr(*, \"label\")= chr \"Subjective Fever\"\n $ Headache         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Headache\"\n $ Weakness         : Factor w/ 4 levels \"None\",\"Mild\",..: 2 4 4 4 3 3 2 4 3 3 ...\n $ CoughIntensity   : Factor w/ 4 levels \"None\",\"Mild\",..: 4 4 2 3 1 3 4 3 3 3 ...\n  ..- attr(*, \"label\")= chr \"Cough Severity\"\n $ Myalgia          : Factor w/ 4 levels \"None\",\"Mild\",..: 2 4 4 4 2 3 2 4 3 2 ...\n $ RunnyNose        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 1 1 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Runny Nose\"\n $ AbPain           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Abdominal Pain\"\n $ ChestPain        : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Chest Pain\"\n $ Diarrhea         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 2 1 1 1 1 ...\n $ EyePn            : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Eye Pain\"\n $ Insomnia         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 1 1 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"Sleeplessness\"\n $ ItchyEye         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Itchy Eyes\"\n $ Nausea           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 2 2 2 1 1 2 2 ...\n $ EarPn            : Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Ear Pain\"\n $ Pharyngitis      : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Sore Throat\"\n $ Breathless       : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 2 1 1 1 2 ...\n  ..- attr(*, \"label\")= chr \"Breathlessness\"\n $ ToothPn          : Factor w/ 2 levels \"No\",\"Yes\": 1 1 2 1 1 1 1 1 2 1 ...\n  ..- attr(*, \"label\")= chr \"Tooth Pain\"\n $ Vomit            : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 2 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Vomiting\"\n $ Wheeze           : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 2 1 2 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Wheezing\"\n $ BodyTemp         : num  98.3 100.4 100.8 98.8 100.5 ...\n\n\nCode will include:\n\nFitting a linear model to the continuous outcome (Body temperature) using only the main predictor of interest.\nFitting another linear model to the continuous outcome using all (important) predictors of interest.\nComparing the model results for the model with just the main predictor and all predictors.\nFitting a logistic model to the categorical outcome (Nausea) using only the main predictor of interest.\nFitting another logistic model to the categorical outcome using all (important) predictors of interest.\nCompares the model results for the categorical model with just the main predictor and all predictors.\n\n\n\nLinear Model: Body Temperature vs. Myalgia\n\n#plot suspect interaction\nggplot(data,\n       aes(x = Myalgia, y = BodyTemp)) + \n  geom_boxplot()\n\n\n\nlm_mod <- linear_reg() #note the default is lm(), thus we do not need to \"set\" the computational engine\n\nlm_fit1 <- lm_mod %>% \n  fit(BodyTemp ~ Myalgia, data = data)\n\ntidy(lm_fit1) #several significant results\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic p.value\n  <chr>              <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)       98.7       0.134    734.    0     \n2 MyalgiaMild        0.322     0.157      2.04  0.0413\n3 MyalgiaModerate    0.271     0.150      1.81  0.0711\n4 MyalgiaSevere      0.404     0.175      2.31  0.0214\n\ntidy(lm_fit1) %>% ##help visualize model with dot-whisker plot\n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\nLinear Model: Body Temperature vs. All Variables\n\nlm_fit_all1 <- lm_mod %>% \n  fit(BodyTemp ~ ., data = data)\n\ntidy(lm_fit_all1) #several significant results\n\n# A tibble: 32 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)          97.9        0.304   323.     0        \n 2 SwollenLymphNodesYes -0.166      0.0920   -1.81   0.0714   \n 3 ChestCongestionYes    0.103      0.0971    1.06   0.291    \n 4 ChillsSweatsYes       0.192      0.127     1.51   0.131    \n 5 NasalCongestionYes   -0.222      0.113    -1.95   0.0512   \n 6 SneezeYes            -0.373      0.0980   -3.80   0.000156 \n 7 FatigueYes            0.273      0.161     1.70   0.0901   \n 8 SubjectiveFeverYes    0.437      0.103     4.25   0.0000244\n 9 HeadacheYes           0.00498    0.125     0.0397 0.968    \n10 WeaknessMild          0.00552    0.189     0.0292 0.977    \n# … with 22 more rows\n\ntidy(lm_fit_all1) %>% ##help visualize regression with dot-whisker plot w/ 95% CI\n  dwplot(dot_args = list(size = 2, color = \"black\"), #Coefficient Estimates\n         whisker_args = list(color = \"black\"), #CI\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\nModel Output Comparison\n\n#Check the goodness of \"fit\" with these 2 lm() models\ncheck_model(lm_fit1$fit) #allows for streamlined way to look at QQ plot, normality, etc\n\n\n\ncheck_model(lm_fit_all1$fit)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n#Compare output\n#Visually\ndwplot(list(Myalgia = lm_fit1, AllVariables = lm_fit_all1)) #compare dwplots\n\n\n\nglance(lm_fit1) %>%\n  dplyr::select(adj.r.squared, AIC, BIC, p.value)\n\n# A tibble: 1 × 4\n  adj.r.squared   AIC   BIC p.value\n          <dbl> <dbl> <dbl>   <dbl>\n1       0.00387 2337. 2360.   0.121\n\nglance(lm_fit_all1) %>%\n  dplyr::select(adj.r.squared, AIC, BIC, p.value)\n\n# A tibble: 1 × 4\n  adj.r.squared   AIC   BIC      p.value\n          <dbl> <dbl> <dbl>        <dbl>\n1        0.0853 2302. 2453. 0.0000000247\n\ncompare_performance(lm_fit1,lm_fit_all1) #better way\n\n# Comparison of Model Performance Indices\n\nName        | Model |  AIC (weights) | AICc (weights) |  BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma\n----------------------------------------------------------------------------------------------------------\nlm_fit1     |   _lm | 2336.6 (<.001) | 2336.6 (<.001) | 2359.5 (>.999) | 0.008 |     0.004 | 1.191 | 1.194\nlm_fit_all1 |   _lm | 2301.6 (>.999) | 2304.8 (>.999) | 2453.1 (<.001) | 0.124 |     0.085 | 1.119 | 1.144\n\n#Via ANOVA\nanova(lm_fit1$fit, lm_fit_all1$fit)\n\nAnalysis of Variance Table\n\nModel 1: BodyTemp ~ Myalgia\nModel 2: BodyTemp ~ SwollenLymphNodes + ChestCongestion + ChillsSweats + \n    NasalCongestion + Sneeze + Fatigue + SubjectiveFever + Headache + \n    Weakness + CoughIntensity + Myalgia + RunnyNose + AbPain + \n    ChestPain + Diarrhea + EyePn + Insomnia + ItchyEye + Nausea + \n    EarPn + Pharyngitis + Breathless + ToothPn + Vomit + Wheeze\n  Res.Df     RSS Df Sum of Sq      F    Pr(>F)    \n1    726 1035.07                                  \n2    698  913.79 28    121.28 3.3086 3.294e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nLogistic Model: Nausea vs. Myalgia\n\n#plot suspect interaction\nggplot(data, aes(x = Myalgia, y = Nausea)) + \n  geom_count()\n\n\n\nglm_mod <- logistic_reg(mode = \"classification\",\n  engine = \"glm\",\n  penalty = NULL,\n  mixture = NULL) #define mode so it is a glm\n\nglm_fit1 <- glm_mod %>% \n  fit(Nausea ~ Myalgia, data = data)\n\ntidy(glm_fit1) #several significant results\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic     p.value\n  <chr>              <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)       -1.37      0.280    -4.90  0.000000980\n2 MyalgiaMild        0.291     0.321     0.905 0.366      \n3 MyalgiaModerate    0.926     0.302     3.07  0.00217    \n4 MyalgiaSevere      1.42      0.337     4.22  0.0000244  \n\ntidy(glm_fit1) %>% ##help visualize model with dot-whisker plot\n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\nLogistic Model: Nausea vs. All Variables\n\nglm_fit_all1 <- glm_mod %>% \n  fit(Nausea ~ ., data = data)\n\ntidy(glm_fit_all1) #several significant results\n\n# A tibble: 32 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)             0.207     7.81     0.0265  0.979 \n 2 SwollenLymphNodesYes   -0.247     0.196   -1.26    0.207 \n 3 ChestCongestionYes      0.265     0.210    1.26    0.207 \n 4 ChillsSweatsYes         0.291     0.287    1.01    0.311 \n 5 NasalCongestionYes      0.440     0.253    1.74    0.0822\n 6 SneezeYes               0.165     0.210    0.787   0.431 \n 7 FatigueYes              0.231     0.371    0.622   0.534 \n 8 SubjectiveFeverYes      0.255     0.223    1.14    0.253 \n 9 HeadacheYes             0.337     0.285    1.18    0.236 \n10 WeaknessMild           -0.120     0.447   -0.269   0.788 \n# … with 22 more rows\n\ntidy(glm_fit_all1) %>% ##help visualize regression with dot-whisker plot w/ 95% CI\n  dwplot(dot_args = list(size = 2, color = \"black\"), #Coefficient Estimates\n         whisker_args = list(color = \"black\"), #CI\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n\n\n\n\n\n\nModel Output Comparison\n\n#Check the goodness of \"fit\" with these 2 lm() models\ncheck_model(glm_fit1$fit) #QQ plot seems off, residuals may be an issue\n\n\n\ncheck_model(glm_fit_all1$fit)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n#Compare output\n#Visually\ndwplot(list(Myalgia = glm_fit1, AllVariables = glm_fit_all1)) #compare dwplots\n\n\n\nglance(glm_fit1) %>%\n  dplyr::select( AIC, BIC)\n\n# A tibble: 1 × 2\n    AIC   BIC\n  <dbl> <dbl>\n1  920.  939.\n\nglance(glm_fit_all1) %>%\n  dplyr::select( AIC, BIC) #better fit\n\n# A tibble: 1 × 2\n    AIC   BIC\n  <dbl> <dbl>\n1  816.  963.\n\ncompare_performance(glm_fit1,glm_fit_all1)\n\n# Comparison of Model Performance Indices\n\nName         | Model | AIC (weights) | AICc (weights) | BIC (weights) | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n--------------------------------------------------------------------------------------------------------------------------------------------------\nglm_fit1     |  _glm | 920.3 (<.001) |  920.3 (<.001) | 938.7 (>.999) |     0.044 | 0.466 | 1.121 |    0.625 |  -110.929 |           0.006 | 0.565\nglm_fit_all1 |  _glm | 816.1 (>.999) |  819.2 (>.999) | 963.1 (<.001) |     0.246 | 0.415 | 1.038 |    0.515 |      -Inf |           0.002 | 0.657\n\n#Via ANOVA\nanova(glm_fit1$fit, glm_fit_all1$fit)\n\nAnalysis of Deviance Table\n\nModel 1: Nausea ~ Myalgia\nModel 2: Nausea ~ SwollenLymphNodes + ChestCongestion + ChillsSweats + \n    NasalCongestion + Sneeze + Fatigue + SubjectiveFever + Headache + \n    Weakness + CoughIntensity + Myalgia + RunnyNose + AbPain + \n    ChestPain + Diarrhea + EyePn + Insomnia + ItchyEye + EarPn + \n    Pharyngitis + Breathless + ToothPn + Vomit + Wheeze + BodyTemp\n  Resid. Df Resid. Dev Df Deviance\n1       726     912.28            \n2       698     752.13 28   160.15"
  },
  {
    "objectID": "fluanalysis/code/machinelearing.html",
    "href": "fluanalysis/code/machinelearing.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Fit regression models\n\n\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.3\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\nWarning: package 'readr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\nWarning: package 'forcats' was built under R version 4.2.3\n\n\nWarning: package 'lubridate' was built under R version 4.2.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.2.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.4     ✔ rsample      1.1.1\n✔ dials        1.2.0     ✔ tune         1.1.1\n✔ infer        1.0.4     ✔ workflows    1.1.3\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.0     ✔ yardstick    1.1.0\n✔ recipes      1.0.5     \n\n\nWarning: package 'broom' was built under R version 4.2.3\n\n\nWarning: package 'dials' was built under R version 4.2.3\n\n\nWarning: package 'infer' was built under R version 4.2.2\n\n\nWarning: package 'modeldata' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.3\n\n\nWarning: package 'recipes' was built under R version 4.2.3\n\n\nWarning: package 'rsample' was built under R version 4.2.2\n\n\nWarning: package 'tune' was built under R version 4.2.3\n\n\nWarning: package 'workflows' was built under R version 4.2.3\n\n\nWarning: package 'workflowsets' was built under R version 4.2.3\n\n\nWarning: package 'yardstick' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(dplyr)\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.2.3\n\nlibrary(rpart)\n\nWarning: package 'rpart' was built under R version 4.2.3\n\n\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-7\n\nlibrary(rpart.plot)\n\nWarning: package 'rpart.plot' was built under R version 4.2.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.2.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(finetune)\n\nWarning: package 'finetune' was built under R version 4.2.3\n\nlibrary(kernlab)\n\nWarning: package 'kernlab' was built under R version 4.2.2\n\n\n\nAttaching package: 'kernlab'\n\nThe following object is masked from 'package:scales':\n\n    alpha\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    alpha\n\nlibrary(doParallel)\n\nWarning: package 'doParallel' was built under R version 4.2.3\n\n\nLoading required package: foreach\n\nAttaching package: 'foreach'\n\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n\nLoading required package: iterators\nLoading required package: parallel\n\ndata <- readRDS(here('fluanalysis/data/SypAct_clean.rds')) #upload cleaned data\ntibble(data) #overview of data\n\n# A tibble: 730 × 26\n   SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion Sneeze Fatigue\n   <fct>             <fct>           <fct>        <fct>           <fct>  <fct>  \n 1 Yes               No              No           No              No     Yes    \n 2 Yes               Yes             No           Yes             No     Yes    \n 3 Yes               Yes             Yes          Yes             Yes    Yes    \n 4 Yes               Yes             Yes          Yes             Yes    Yes    \n 5 Yes               No              Yes          No              No     Yes    \n 6 No                No              Yes          No              Yes    Yes    \n 7 No                No              Yes          No              No     Yes    \n 8 No                Yes             Yes          Yes             Yes    Yes    \n 9 Yes               Yes             Yes          Yes             No     Yes    \n10 No                Yes             No           Yes             No     Yes    \n# ℹ 720 more rows\n# ℹ 20 more variables: SubjectiveFever <fct>, Headache <fct>, Weakness <fct>,\n#   CoughIntensity <fct>, Myalgia <fct>, RunnyNose <fct>, AbPain <fct>,\n#   ChestPain <fct>, Diarrhea <fct>, EyePn <fct>, Insomnia <fct>,\n#   ItchyEye <fct>, Nausea <fct>, EarPn <fct>, Pharyngitis <fct>,\n#   Breathless <fct>, ToothPn <fct>, Vomit <fct>, Wheeze <fct>, BodyTemp <dbl>\n\n\n\n\n\n\n\nset.seed(123)\n# Fix the random numbers by setting the seed \n# This enables the analysis to be reproducible when random numbers are used \n\ndata_split <- initial_split(data, prop = 2.8/4, strata = BodyTemp) #70% training, 30% testing\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n\n#5-fold cross-validation, 5 times repeated\nfold_data <- vfold_cv(train_data, v = 5, repeats = 5, strata = BodyTemp)\n\n#Create a recipe for the data and fitting. \ndata_recipe <- recipe(BodyTemp ~ ., data = train_data) %>%\n  step_dummy(all_nominal(), -all_outcomes()) \n\n\n\n\n\nnull_recipe <- recipe(BodyTemp ~ 1, data = train_data) %>%\n  step_dummy(all_nominal(), -all_outcomes())\n\n# Logistic model recipe\nrecipe_mod <- linear_reg() %>% \n  set_engine(\"lm\") %>% \n  set_mode(\"regression\")\n\n# Model workflow to pair model and recipe \nnull_flow <- workflow() %>% \n  add_model(recipe_mod) %>% \n  add_recipe(null_recipe)\n\n#fit the null model to the folds made from the train data set.\nnull_train <- fit_resamples(null_flow, resamples = fold_data)\n\n→ A | warning: There was 1 warning in `dplyr::summarise()`.\n               ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pred, na_rm\n                 = na_rm)`.\n               Caused by warning:\n               ! A correlation computation is required, but `estimate` is constant and has 0 standard deviation, resulting in a divide by 0 error. `NA` will be returned.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x2\n\n\nThere were issues with some computations   A: x13\n\n\nThere were issues with some computations   A: x25\nThere were issues with some computations   A: x25\n\n\n\n\n#Compute the RMSE for both training and test data\nNull_Met <- collect_metrics(null_train)\n#RMSE = 1.22\n\n\n\n\n\n\n\n#TUNING HYPERPARAMETERS \ntune_spec <- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"regression\")\n\ntree_grid <- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid %>% \n  count(tree_depth)\n\n# A tibble: 5 × 2\n  tree_depth     n\n       <int> <int>\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5\n\n#Model tuning with a grid\ntree_wf <- workflow() %>%\n  add_model(tune_spec) %>%\n  add_recipe(data_recipe)\n\ntree_res <- #Code will take a hot minute to run\n  tree_wf %>% \n  tune_grid(\n    resamples = fold_data,\n    grid = tree_grid\n    )\n\n→ A | warning: There was 1 warning in `dplyr::summarise()`.\n               ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pred, na_rm\n                 = na_rm)`.\n               ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n               Caused by warning:\n               ! A correlation computation is required, but `estimate` is constant and has 0 standard deviation, resulting in a divide by 0 error. `NA` will be returned., There was 1 warning in `dplyr::summarise()`.\n               ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pred, na_rm\n                 = na_rm)`.\n               ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n               Caused by warning:\n               ! A correlation computation is required, but `estimate` is constant and has 0 standard deviation, resulting in a divide by 0 error. `NA` will be returned., There was 1 warning in `dplyr::summarise()`.\n               ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pred, na_rm\n                 = na_rm)`.\n               ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n               Caused by warning:\n               ! A correlation computation is required, but `estimate` is constant and has 0 standard deviation, resulting in a divide by 0 error. `NA` will be returned., There was 1 warning in `dplyr::summarise()`.\n               ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pred, na_rm\n                 = na_rm)`.\n               ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n               Caused by warning:\n               ! A correlation computation is required, but `estimate` is constant and has 0 standard deviation, resulting in a divide by 0 error. `NA` will be returned., There was 1 warning in `dplyr::summarise()`.\n               ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pred, na_rm\n                 = na_rm)`.\n               ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n               Caused by warning:\n               ! A correlation computation is required, but `estimate` is constant and has 0 standard deviation, resulting in a divide by 0 error. `NA` will be returned.\n\n\nThere were issues with some computations   A: x1\n\n\nThere were issues with some computations   A: x2\n\n\nThere were issues with some computations   A: x3\n\n\nThere were issues with some computations   A: x4\n\n\nThere were issues with some computations   A: x5\n\n\nThere were issues with some computations   A: x6\n\n\nThere were issues with some computations   A: x7\n\n\nThere were issues with some computations   A: x8\n\n\nThere were issues with some computations   A: x9\n\n\nThere were issues with some computations   A: x10\n\n\nThere were issues with some computations   A: x11\n\n\nThere were issues with some computations   A: x12\n\n\nThere were issues with some computations   A: x13\n\n\nThere were issues with some computations   A: x14\n\n\nThere were issues with some computations   A: x15\n\n\nThere were issues with some computations   A: x16\n\n\nThere were issues with some computations   A: x17\n\n\nThere were issues with some computations   A: x18\n\n\nThere were issues with some computations   A: x19\n\n\nThere were issues with some computations   A: x20\n\n\nThere were issues with some computations   A: x21\n\n\nThere were issues with some computations   A: x22\n\n\nThere were issues with some computations   A: x23\n\n\nThere were issues with some computations   A: x24\n\n\nThere were issues with some computations   A: x25\nThere were issues with some computations   A: x25\n\n\n\n\ntree_res %>% \n  collect_metrics()\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric .estimator     mean     n  std_err .config\n             <dbl>      <int> <chr>   <chr>         <dbl> <int>    <dbl> <chr>  \n 1    0.0000000001          1 rmse    standard     1.19      25  0.0181  Prepro…\n 2    0.0000000001          1 rsq     standard     0.0361    25  0.00422 Prepro…\n 3    0.0000000178          1 rmse    standard     1.19      25  0.0181  Prepro…\n 4    0.0000000178          1 rsq     standard     0.0361    25  0.00422 Prepro…\n 5    0.00000316            1 rmse    standard     1.19      25  0.0181  Prepro…\n 6    0.00000316            1 rsq     standard     0.0361    25  0.00422 Prepro…\n 7    0.000562              1 rmse    standard     1.19      25  0.0181  Prepro…\n 8    0.000562              1 rsq     standard     0.0361    25  0.00422 Prepro…\n 9    0.1                   1 rmse    standard     1.21      25  0.0177  Prepro…\n10    0.1                   1 rsq     standard   NaN          0 NA       Prepro…\n# ℹ 40 more rows\n\n#show and select best\ntree_res %>%\n  show_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \n1    0.0000000001          1 rmse    standard    1.19    25  0.0181 Preprocesso…\n2    0.0000000178          1 rmse    standard    1.19    25  0.0181 Preprocesso…\n3    0.00000316            1 rmse    standard    1.19    25  0.0181 Preprocesso…\n4    0.000562              1 rmse    standard    1.19    25  0.0181 Preprocesso…\n5    0.0000000001          4 rmse    standard    1.20    25  0.0187 Preprocesso…\n\n#rmse = 1.2\n\nbest_tree <- tree_res %>%\n  select_best(n=1)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n#Final tuned model\nfinal_wf <- \n  tree_wf %>% \n  finalize_workflow(best_tree)\n\n#The Last Fit\nfinal_fit <- \n  final_wf %>%\n  fit(train_data) \n\n#Plot\nrpart.plot(extract_fit_parsnip(final_fit)$fit)\n\nWarning: Cannot retrieve the data used to build the model (model.frame: object '..y' not found).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n\n\n\n\n\n\n\n\n\n#BUILD THE MODEL\nlasso_mod <- \n  linear_reg(penalty = tune(), mixture = 1) %>% \n  set_engine(\"glmnet\")\n\n# Recipe and create Workflow\ndata_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 25\n\n\n\n\n\n── Operations \n\n\n• Dummy variables from: all_nominal(), -all_outcomes()\n\nlasso_wf <- \n  workflow() %>% \n  add_model(lasso_mod) %>% \n  add_recipe(data_recipe)\n\n#Create grid for tuning\nlr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))\nlr_reg_grid %>% top_n(-5) # lowest penalty values\n\nSelecting by penalty\n\n\n# A tibble: 5 × 1\n   penalty\n     <dbl>\n1 0.0001  \n2 0.000127\n3 0.000161\n4 0.000204\n5 0.000259\n\nlr_reg_grid %>% top_n(5)  # highest penalty values\n\nSelecting by penalty\n\n\n# A tibble: 5 × 1\n  penalty\n    <dbl>\n1  0.0386\n2  0.0489\n3  0.0621\n4  0.0788\n5  0.1   \n\n#TRAIN AND TUNE THE MODEL\nlr_res <- \n  lasso_wf %>% \n  tune_grid(resamples = fold_data,\n            grid = lr_reg_grid,\n            control = control_grid(verbose = FALSE, save_pred = TRUE),\n            metrics = NULL)\n\nlr_res %>%\n  collect_metrics()\n\n# A tibble: 60 × 7\n    penalty .metric .estimator   mean     n std_err .config              \n      <dbl> <chr>   <chr>       <dbl> <int>   <dbl> <chr>                \n 1 0.0001   rmse    standard   1.18      25 0.0167  Preprocessor1_Model01\n 2 0.0001   rsq     standard   0.0819    25 0.00875 Preprocessor1_Model01\n 3 0.000127 rmse    standard   1.18      25 0.0167  Preprocessor1_Model02\n 4 0.000127 rsq     standard   0.0819    25 0.00875 Preprocessor1_Model02\n 5 0.000161 rmse    standard   1.18      25 0.0167  Preprocessor1_Model03\n 6 0.000161 rsq     standard   0.0819    25 0.00875 Preprocessor1_Model03\n 7 0.000204 rmse    standard   1.18      25 0.0167  Preprocessor1_Model04\n 8 0.000204 rsq     standard   0.0819    25 0.00875 Preprocessor1_Model04\n 9 0.000259 rmse    standard   1.18      25 0.0167  Preprocessor1_Model05\n10 0.000259 rsq     standard   0.0819    25 0.00875 Preprocessor1_Model05\n# ℹ 50 more rows\n\nlr_res %>%\n  show_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1  0.0489 rmse    standard    1.15    25  0.0170 Preprocessor1_Model27\n2  0.0621 rmse    standard    1.15    25  0.0170 Preprocessor1_Model28\n3  0.0386 rmse    standard    1.16    25  0.0170 Preprocessor1_Model26\n4  0.0304 rmse    standard    1.16    25  0.0169 Preprocessor1_Model25\n5  0.0788 rmse    standard    1.16    25  0.0172 Preprocessor1_Model29\n\n#Selects best performing model\nbest_lasso <- lr_res %>%\n  select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n#rmse = 1.18\n\n#Final Model\nlasso_final_wf <- \n  lasso_wf %>% \n  finalize_workflow(best_lasso)\n\nlasso_final_fit <- \n  lasso_final_wf %>%\n  fit(train_data) \n\n#Plot\nx <- extract_fit_engine(lasso_final_fit)\nplot(x, \"lambda\")\n\n\n\n\n\n\n\n\n#BUILD THE MODEL AND IMPROVE TRAINING TIME\ncores <- parallel::detectCores()\ncores\n\n[1] 4\n\nf_mod <- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% \n  set_engine(\"ranger\",importance = \"impurity\", num.threads = cores) %>% \n  set_mode(\"regression\")\n\nf_wf <- workflow() %>%\n  add_model(f_mod) %>%\n  add_recipe(data_recipe)\n\n#TRAIN AND TUNE THE MODEL\nf_mod\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = 1000\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = impurity\n  num.threads = cores\n\nComputational engine: ranger \n\nextract_parameter_set_dials(f_mod)\n\nCollection of 2 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n\nf_res <- #This code takes a long time to run!\n  f_wf %>% \n  tune_grid(fold_data,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = NULL)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#Show and select the best\n\nf_res %>%\n  show_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     5    27 rmse    standard    1.16    25  0.0168 Preprocessor1_Model18\n2     3    19 rmse    standard    1.16    25  0.0167 Preprocessor1_Model09\n3     8    24 rmse    standard    1.17    25  0.0167 Preprocessor1_Model04\n4    11    36 rmse    standard    1.17    25  0.0168 Preprocessor1_Model13\n5     6    15 rmse    standard    1.17    25  0.0167 Preprocessor1_Model22\n\n#rmse = 1.19\n\nf_best <- \n  f_res %>% \n  select_best(metric = \"rmse\")\n\nf_final_wf <- \n  f_wf %>% \n  finalize_workflow(f_best)\n\n#Final model fit\nf_final_fit <- \n  f_final_wf %>%\n  fit(train_data) \n\nf_final_fit %>% \n  extract_fit_parsnip() %>% \n  vip(num_features = 28)\n\n\n\n#Plot\nfx <- extract_fit_engine(f_final_fit)\nvip(fx)\n\n\n\n\n\n\n\n\n\n#Based on rmse the Lasso model appears to be the best\n#We will fit final lasson model on split data!\n\nlasso_final_test <- \n  lasso_final_wf %>%\n  last_fit(data_split) \n\nlasso_final_test %>%\n   collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard      1.16   Preprocessor1_Model1\n2 rsq     standard      0.0299 Preprocessor1_Model1\n\n#rmse = 1.156"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html",
    "href": "fluanalysis/code/modeleval.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Improving Models\n\nLoad packakes and data\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggplot2)\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.2.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.3     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'infer' was built under R version 4.2.2\n\n\nWarning: package 'modeldata' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\n\nWarning: package 'rsample' was built under R version 4.2.2\n\n\nWarning: package 'tune' was built under R version 4.2.2\n\n\nWarning: package 'workflows' was built under R version 4.2.2\n\n\nWarning: package 'workflowsets' was built under R version 4.2.2\n\n\nWarning: package 'yardstick' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(dplyr)\n\ndata <- readRDS(here('fluanalysis/data/SypAct_clean.rds')) #upload cleaned data\ntibble(data) #overview of data\n\n# A tibble: 730 × 26\n   SwollenLymph…¹ Chest…² Chill…³ Nasal…⁴ Sneeze Fatigue Subje…⁵ Heada…⁶ Weakn…⁷\n   <fct>          <fct>   <fct>   <fct>   <fct>  <fct>   <fct>   <fct>   <fct>  \n 1 Yes            No      No      No      No     Yes     Yes     Yes     Mild   \n 2 Yes            Yes     No      Yes     No     Yes     Yes     Yes     Severe \n 3 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 4 Yes            Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 5 Yes            No      Yes     No      No     Yes     Yes     Yes     Modera…\n 6 No             No      Yes     No      Yes    Yes     Yes     Yes     Modera…\n 7 No             No      Yes     No      No     Yes     Yes     No      Mild   \n 8 No             Yes     Yes     Yes     Yes    Yes     Yes     Yes     Severe \n 9 Yes            Yes     Yes     Yes     No     Yes     Yes     Yes     Modera…\n10 No             Yes     No      Yes     No     Yes     No      Yes     Modera…\n# … with 720 more rows, 17 more variables: CoughIntensity <fct>, Myalgia <fct>,\n#   RunnyNose <fct>, AbPain <fct>, ChestPain <fct>, Diarrhea <fct>,\n#   EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>, EarPn <fct>,\n#   Pharyngitis <fct>, Breathless <fct>, ToothPn <fct>, Vomit <fct>,\n#   Wheeze <fct>, BodyTemp <dbl>, and abbreviated variable names\n#   ¹​SwollenLymphNodes, ²​ChestCongestion, ³​ChillsSweats, ⁴​NasalCongestion,\n#   ⁵​SubjectiveFever, ⁶​Headache, ⁷​Weakness\n\n\n\n\nSplit Data\n\nset.seed(123)\n# Fix the random numbers by setting the seed \n# This enables the analysis to be reproducible when random numbers are used \n\ndata_split <- initial_split(data, prop = 3/4)\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n\n\n\nMake a recipe and fit a model\n\n# Create recipe using Nausea as categorical variable\n\ndata_recipe <- recipe(Nausea ~ ., data = train_data)\n\n# Logistic model recipe\nrecipe_mod <- logistic_reg() %>% set_engine(\"glm\")\n\n# Model workflow to pair model and recipe \nmod_flow <- workflow() %>% \n  add_model(recipe_mod) %>% \n  add_recipe(data_recipe)\n\nmod_flow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nTrain the model from the resulting predictors\n\ndata_fit <- \n  mod_flow %>% \n  fit(data = train_data)\n\ndata_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 32 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)            -2.83      9.07     -0.312  0.755 \n 2 SwollenLymphNodesYes   -0.435     0.235    -1.85   0.0649\n 3 ChestCongestionYes      0.277     0.252     1.10   0.271 \n 4 ChillsSweatsYes         0.333     0.355     0.939  0.348 \n 5 NasalCongestionYes      0.233     0.300     0.778  0.437 \n 6 SneezeYes               0.115     0.253     0.455  0.649 \n 7 FatigueYes              0.288     0.460     0.626  0.531 \n 8 SubjectiveFeverYes      0.402     0.271     1.48   0.138 \n 9 HeadacheYes             0.644     0.367     1.75   0.0794\n10 WeaknessMild           -0.274     0.574    -0.478  0.633 \n# … with 22 more rows\n\n\n\n\nUse a trained workflow to Predict\n\npredict(data_fit, test_data)\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 Yes        \n 3 No         \n 4 No         \n 5 No         \n 6 No         \n 7 No         \n 8 No         \n 9 No         \n10 Yes        \n# … with 173 more rows\n\ndata_aug <- \n  augment(data_fit, test_data)\n\n# The data look like: \ndata_aug %>%\n  select(Nausea, .pred_No, .pred_Yes)\n\n# A tibble: 183 × 3\n   Nausea .pred_No .pred_Yes\n   <fct>     <dbl>     <dbl>\n 1 No        0.961    0.0394\n 2 Yes       0.121    0.879 \n 3 Yes       0.769    0.231 \n 4 Yes       0.744    0.256 \n 5 Yes       0.759    0.241 \n 6 No        0.771    0.229 \n 7 No        0.544    0.456 \n 8 No        0.745    0.255 \n 9 No        0.941    0.0585\n10 Yes       0.171    0.829 \n# … with 173 more rows\n\n\n\n\nROC Curve\n\ndata_aug %>% \n  roc_curve(truth = Nausea, .pred_No) %>% \n  autoplot()\n\n\n\ndata_aug %>% \n  roc_auc(truth = Nausea, .pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.709\n\n# > 0.7; the model might be useful. \n\n\n\nAlternative Model: Main predictor to the Categorical Outcome\n\n# Create new recipe\ndata_recipe2 <- recipe(Nausea ~ Myalgia, data = train_data) #%>%\n#  step_nzv(all_predictors(), freq_cut = 995/5, unique_cut = 10) %>%\n#  step_ordinalscore(all_of(ordered_names))\n\n# Model workflow to pair model and recipe \nmod_flow2 <- workflow() %>% \n  add_model(recipe_mod) %>% \n  add_recipe(data_recipe2)\n\n#Train data\ndata_fit2 <- \n  mod_flow2 %>% \n  fit(data = train_data)\n\ndata_aug2 <- \n  augment(data_fit2, test_data)\n\ndata_aug2 %>% \n  roc_auc(truth = Nausea, .pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.633\n\n# < 0.7; the model not very useful. \n\n\n\nThe following added by SETH LATTNER\n\nFitting continuous variables\n\ndata_recipe3 <- recipe(BodyTemp ~ ., data = train_data) #%>%\n#  step_nzv(all_predictors(), freq_cut = 995/5, unique_cut = 10) %>%\n#  step_ordinalscore(all_of(ordered_names))\n\n# Logistic model recipe\nrecipe_mod3 <- linear_reg() %>% set_engine(\"lm\")\n\n# Model workflow to pair model and recipe \nmod_flow3 <- workflow() %>% \n  add_model(recipe_mod3) %>% \n  add_recipe(data_recipe3)\n\nmod_flow3\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n\nTrain the model from the resulting predictors\n\ndata_fit3 <- \n  mod_flow3 %>% \n  fit(data = train_data)\n\ndata_fit3 %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 32 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)           98.2        0.352   279.    0        \n 2 SwollenLymphNodesYes  -0.104      0.108    -0.960 0.337    \n 3 ChestCongestionYes     0.0566     0.114     0.496 0.620    \n 4 ChillsSweatsYes        0.279      0.151     1.84  0.0664   \n 5 NasalCongestionYes    -0.213      0.133    -1.60  0.110    \n 6 SneezeYes             -0.400      0.116    -3.44  0.000627 \n 7 FatigueYes             0.375      0.187     2.00  0.0461   \n 8 SubjectiveFeverYes     0.517      0.122     4.25  0.0000259\n 9 HeadacheYes           -0.0614     0.151    -0.406 0.685    \n10 WeaknessMild          -0.0473     0.226    -0.209 0.834    \n# … with 22 more rows\n\n\n\n\nUse a trained workflow to Predict\n\npredict(data_fit3, test_data)\n\n# A tibble: 183 × 1\n   .pred\n   <dbl>\n 1  99.5\n 2  98.9\n 3  99.0\n 4  98.7\n 5  98.5\n 6  99.0\n 7  99.5\n 8  99.7\n 9  98.9\n10  99.6\n# … with 173 more rows\n\ndata_aug3 <- \n  augment(data_fit3, test_data)\n\n# The data look like: \ndata_aug3 %>%\n  select(BodyTemp, .pred)\n\n# A tibble: 183 × 2\n   BodyTemp .pred\n      <dbl> <dbl>\n 1     98.3  99.5\n 2    101.   98.9\n 3     98.8  99.0\n 4     98.5  98.7\n 5     98.1  98.5\n 6     98.4  99.0\n 7     99.5  99.5\n 8     98.8  99.7\n 9    102.   98.9\n10     99.7  99.6\n# … with 173 more rows\n\n\n\n#calculate RMSE\nyardstick::rmse(data_aug3, BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.14\n\n\n\n\nAlternative Model: Main predictor to the Categorical Outcome\n\n# Create new recipe\ndata_recipe4 <- recipe(BodyTemp ~ RunnyNose, data = train_data) #%>%\n#  step_nzv(all_predictors(), freq_cut = 995/5, unique_cut = 10) %>%\n# step_ordinalscore(all_of(ordered_names))\n\n# Model workflow to pair model and recipe \nmod_flow4 <- workflow() %>% \n  add_model(recipe_mod3) %>% \n  add_recipe(data_recipe4)\n\n#Train data\ndata_fit4 <- \n  mod_flow4 %>% \n  fit(data = train_data)\n\ndata_fit4 %>% \n  extract_fit_parsnip() %>% \n  tidy()\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.2      0.0969   1024.   0      \n2 RunnyNoseYes   -0.362    0.115      -3.16 0.00168\n\n\n\n#predict from test data\npredict(data_fit4, test_data)\n\n# A tibble: 183 × 1\n   .pred\n   <dbl>\n 1  99.2\n 2  98.9\n 3  98.9\n 4  98.9\n 5  98.9\n 6  98.9\n 7  99.2\n 8  99.2\n 9  99.2\n10  99.2\n# … with 173 more rows\n\n#augment test data\ndata_aug4 <- \n  augment(data_fit4, test_data)\n\n#the data look like:\ndata_aug4 %>%\n  select(BodyTemp, .pred)\n\n# A tibble: 183 × 2\n   BodyTemp .pred\n      <dbl> <dbl>\n 1     98.3  99.2\n 2    101.   98.9\n 3     98.8  98.9\n 4     98.5  98.9\n 5     98.1  98.9\n 6     98.4  98.9\n 7     99.5  99.2\n 8     98.8  99.2\n 9    102.   99.2\n10     99.7  99.2\n# … with 173 more rows\n\n\n\n#calculate RMSE\nyardstick::rmse(data_aug4, BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.12\n\n\nThe RMSE of the univariate model 4 (1.12) was lower than that of the global model 3 (1.15), showing that it is a better fit to the data."
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "My Data Analysis Portfolio",
    "section": "",
    "text": "Flu Analysis: Wrangling\n\nLoad the data and packages:\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.2.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.3     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n\n\nWarning: package 'broom' was built under R version 4.2.2\n\n\nWarning: package 'dials' was built under R version 4.2.2\n\n\nWarning: package 'infer' was built under R version 4.2.2\n\n\nWarning: package 'modeldata' was built under R version 4.2.2\n\n\nWarning: package 'parsnip' was built under R version 4.2.2\n\n\nWarning: package 'recipes' was built under R version 4.2.2\n\n\nWarning: package 'rsample' was built under R version 4.2.2\n\n\nWarning: package 'tune' was built under R version 4.2.2\n\n\nWarning: package 'workflows' was built under R version 4.2.2\n\n\nWarning: package 'workflowsets' was built under R version 4.2.2\n\n\nWarning: package 'yardstick' was built under R version 4.2.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nraw_flu <- readRDS(here('fluanalysis/data/SympAct_Any_Pos.Rda'))\ntibble(raw_flu) # to get a look at the data\n\n# A tibble: 735 × 63\n   DxName1       DxName2 DxName3 DxName4 DxName5 Uniqu…¹ Activ…² Activ…³ Swoll…⁴\n   <fct>         <fct>   <fct>   <fct>   <fct>   <chr>     <int> <fct>   <fct>  \n 1 Influenza li… <NA>    <NA>    <NA>    <NA>    340_17…      10 10      Yes    \n 2 Acute tonsil… Influe… <NA>    <NA>    <NA>    340_17…       6 6       Yes    \n 3 Influenza li… Acute … <NA>    <NA>    <NA>    342_17…       2 2       Yes    \n 4 Influenza li… Unspec… <NA>    <NA>    <NA>    342_17…       2 2       Yes    \n 5 Acute pharyn… Influe… <NA>    <NA>    <NA>    342_17…       5 5       Yes    \n 6 Influenza li… <NA>    <NA>    <NA>    <NA>    343_17…       3 3       No     \n 7 Fever, unspe… Influe… <NA>    <NA>    <NA>    343_17…       4 4       No     \n 8 Acute upper … Impact… <NA>    <NA>    <NA>    344_17…       0 0       No     \n 9 Influenza li… Acute … Fever,… Other … Headac… 344_17…       0 0       Yes    \n10 Influenza li… <NA>    <NA>    <NA>    <NA>    344_17…       5 5       No     \n# … with 725 more rows, 54 more variables: ChestCongestion <fct>,\n#   ChillsSweats <fct>, NasalCongestion <fct>, CoughYN <fct>, Sneeze <fct>,\n#   Fatigue <fct>, SubjectiveFever <fct>, Headache <fct>, Weakness <fct>,\n#   WeaknessYN <fct>, CoughIntensity <fct>, CoughYN2 <fct>, Myalgia <fct>,\n#   MyalgiaYN <fct>, RunnyNose <fct>, AbPain <fct>, ChestPain <fct>,\n#   Diarrhea <fct>, EyePn <fct>, Insomnia <fct>, ItchyEye <fct>, Nausea <fct>,\n#   EarPn <fct>, Hearing <fct>, Pharyngitis <fct>, Breathless <fct>, …\n\n\n\n\nRemove unwanted data columns\n\n+ Feature/Variable removal\nRemove all variables that have Score or Total or FluA or FluB or Dxname or Activity in their name. Also remove the variable Unique.Visit. Remove any NA observations.\nNow data set contains 32 variables coding for presence or absence of some symptom. Only one, temperature, is continuous.\n\nflu_clean <- raw_flu %>% #sort through the data and removing all variables (columns) that include the words: Score or Total or FluA or FluB or Dxname or Activity\n  select(-contains(c(\"Score\", \"Total\", \"FluA\", \"FluB\", \"Dxname\", \"Activity\"))) %>% #now will remove all columns that include Unique.Visit\n  select(-contains(c(\"Unique.Visit\"))) %>%\n  drop_na %>% #Will drop all nas now \nselect(-contains(c(\"WeaknessYN\", \"CoughYN\", \"CoughYN2\", \"MyalgiaYN\"))) ## Remove repeated variables (#Weakness, Cough and Myalgia)\n\n\n\n\nRemove binary predictors with <50 entries\n\nsummary(flu_clean)\n\n SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion Sneeze   \n No :418           No :323         No :130      No :167         No :339  \n Yes:312           Yes:407         Yes:600      Yes:563         Yes:391  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Fatigue   SubjectiveFever Headache      Weakness    CoughIntensity\n No : 64   No :230         No :115   None    : 49   None    : 47   \n Yes:666   Yes:500         Yes:615   Mild    :223   Mild    :154   \n                                     Moderate:338   Moderate:357   \n                                     Severe  :120   Severe  :172   \n                                                                   \n                                                                   \n     Myalgia    RunnyNose AbPain    ChestPain Diarrhea  EyePn     Insomnia \n None    : 79   No :211   No :639   No :497   No :631   No :617   No :315  \n Mild    :213   Yes:519   Yes: 91   Yes:233   Yes: 99   Yes:113   Yes:415  \n Moderate:325                                                              \n Severe  :113                                                              \n                                                                           \n                                                                           \n ItchyEye  Nausea    EarPn     Hearing   Pharyngitis Breathless ToothPn  \n No :551   No :475   No :568   No :700   No :119     No :436    No :565  \n Yes:179   Yes:255   Yes:162   Yes: 30   Yes:611     Yes:294    Yes:165  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Vision    Vomit     Wheeze       BodyTemp     \n No :711   No :652   No :510   Min.   : 97.20  \n Yes: 19   Yes: 78   Yes:220   1st Qu.: 98.20  \n                               Median : 98.50  \n                               Mean   : 98.94  \n                               3rd Qu.: 99.30  \n                               Max.   :103.10  \n\n#Both vision and Hearing have under 50 of either Yes/No, remove\n\nflu_clean_2 <- flu_clean %>%\nselect(-contains(c(\"Vision\", \"Hearing\")))\n\n\n\nSave file into project:\n\nsaveRDS(flu_clean_2, file= here(\"fluanalysis\", \"data\", \"SypAct_clean.rds\")) #will save as a data.frame in the RDS file"
  },
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Upload public access data for exercise via tidytuesdayR package.\n\n#install.packages(\"tidytuesdayR\")\n#install.packages('janitor')\n\nlibrary(tidytuesdayR)\n\nWarning: package 'tidytuesdayR' was built under R version 4.2.2\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.2.2\n\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ntuesdata <- tidytuesdayR::tt_load(2023, week = 7)\n\n--- Compiling #TidyTuesday Information for 2023-02-14 ----\n--- There is 1 file available ---\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 1: `age_gaps.csv`\n\n\n--- Download complete ---\n\nage_gaps <- tuesdata$age_gaps\n\n\n\n\n\n\n\nmovie_name; character; Name of the film;\nrelease_year; integer; Release year\ndirector; character; Director of the film\nage_difference; integer; Age difference between the characters in whole years\ncouple_number; integer; An identifier for the couple in case multiple couples are listed for this film\nactor_1_name; character; The name of the older actor in this couple\nactor_2_name; character; The name of the younger actor in this couple\ncharacter_1_gender; character; The gender of the older character, as identified by the person who submitted the data for this couple\ncharacter_2_gender; character; The gender of the younger character, as identified by the person who submitted the data for this couple\nactor_1_birthdate; date; The birthdate of the older member of the couple\nactor_2_birthdate; date; The birthdate of the younger member of the couple\nactor_1_age; integer; The age of the older actor when the film was released\nactor_2_age; integer; The age of the younger actor when the film was released\n\ntibble(age_gaps)\n\n# A tibble: 1,155 × 13\n   movie_name    relea…¹ direc…² age_d…³ coupl…⁴ actor…⁵ actor…⁶ chara…⁷ chara…⁸\n   <chr>           <dbl> <chr>     <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>  \n 1 Harold and M…    1971 Hal As…      52       1 Ruth G… Bud Co… woman   man    \n 2 Venus            2006 Roger …      50       1 Peter … Jodie … man     woman  \n 3 The Quiet Am…    2002 Philli…      49       1 Michae… Do Thi… man     woman  \n 4 The Big Lebo…    1998 Joel C…      45       1 David … Tara R… man     woman  \n 5 Beginners        2010 Mike M…      43       1 Christ… Goran … man     man    \n 6 Poison Ivy       1992 Katt S…      42       1 Tom Sk… Drew B… man     woman  \n 7 Whatever Wor…    2009 Woody …      40       1 Larry … Evan R… man     woman  \n 8 Entrapment       1999 Jon Am…      39       1 Sean C… Cather… man     woman  \n 9 Husbands and…    1992 Woody …      38       1 Woody … Juliet… man     woman  \n10 Magnolia         1999 Paul T…      38       1 Jason … Julian… man     woman  \n# … with 1,145 more rows, 4 more variables: actor_1_birthdate <date>,\n#   actor_2_birthdate <date>, actor_1_age <dbl>, actor_2_age <dbl>, and\n#   abbreviated variable names ¹​release_year, ²​director, ³​age_difference,\n#   ⁴​couple_number, ⁵​actor_1_name, ⁶​actor_2_name, ⁷​character_1_gender,\n#   ⁸​character_2_gender\n\nglimpse(age_gaps)\n\nRows: 1,155\nColumns: 13\n$ movie_name         <chr> \"Harold and Maude\", \"Venus\", \"The Quiet American\", …\n$ release_year       <dbl> 1971, 2006, 2002, 1998, 2010, 1992, 2009, 1999, 199…\n$ director           <chr> \"Hal Ashby\", \"Roger Michell\", \"Phillip Noyce\", \"Joe…\n$ age_difference     <dbl> 52, 50, 49, 45, 43, 42, 40, 39, 38, 38, 36, 36, 35,…\n$ couple_number      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ actor_1_name       <chr> \"Ruth Gordon\", \"Peter O'Toole\", \"Michael Caine\", \"D…\n$ actor_2_name       <chr> \"Bud Cort\", \"Jodie Whittaker\", \"Do Thi Hai Yen\", \"T…\n$ character_1_gender <chr> \"woman\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", …\n$ character_2_gender <chr> \"man\", \"woman\", \"woman\", \"woman\", \"man\", \"woman\", \"…\n$ actor_1_birthdate  <date> 1896-10-30, 1932-08-02, 1933-03-14, 1930-09-17, 19…\n$ actor_2_birthdate  <date> 1948-03-29, 1982-06-03, 1982-10-01, 1975-11-08, 19…\n$ actor_1_age        <dbl> 75, 74, 69, 68, 81, 59, 62, 69, 57, 77, 59, 56, 65,…\n$ actor_2_age        <dbl> 23, 24, 20, 23, 38, 17, 22, 30, 19, 39, 23, 20, 30,…"
  },
  {
    "objectID": "tidytuesday_exercise.html#actor-and-release-data",
    "href": "tidytuesday_exercise.html#actor-and-release-data",
    "title": "Tidy Tuesday Exercise",
    "section": "Actor and Release Data",
    "text": "Actor and Release Data\n\n(because inquiring minds want to know…)\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.2\n\nARplot <- ggplot() +\n  geom_point(data = leadMdata, aes(x = release_year, y = lead_male_age), color = 'dodgerblue4', size=1.5, shape = 15) +\n  geom_point(data = leadFdata, aes(x = release_year, y = lead_female_age), color = 'deeppink4', size=1.5, shape = 15) +\n    geom_point(data = leadMdata, aes(x = release_year, y = supporting_actor_age), color = 'deepskyblue2', size=1.5, shape = 18) +\n  geom_point(data = leadFdata, aes(x = release_year, y = supporting_actor_age), color = 'deeppink1', size=1.5, shape = 18) +\n  ggtitle(\"Actor Age in Relation to the Movie Release Data\", subtitle = \"Evaluated by Genders\") +\nlabs(x = \"Release Year\", y = \"Actor Ages\") +\n  annotate(geom=\"text\", x=1950, y=75, label=\"Lead Male Actors\", colour=\"dodgerblue4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1950, y=80, label=\"Lead Female Actors\", colour=\"deeppink4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1950, y=65, label=\"Actors that Support Male Leads\", colour=\"deepskyblue2\", size=3, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1950, y=70, label=\"Actors that Support Female Leads\", colour=\"deeppink1\", size=3, family=\"sans\", fontface=\"bold\", angle=0)\n\nARplot\n\n\n\n\nLets look a little closer at lead actors and age gaps\n\nARAplot <- ggplot() +\n  geom_point(data = leadMdata, aes(x = release_year, y = lead_male_age, size = age_difference), fill = 'dodgerblue4', shape = 21, colour = \"black\") +\n  geom_point(data = leadFdata, aes(x = release_year, y = lead_female_age, size = age_difference), fill = 'deeppink4', shape = 21, colour = \"black\") +\n\n  ggtitle(\"Lead Actor Age in Relation to the Movie Release Data\", subtitle = \"Factoring in Age Gaps between Lead and Supporting Actors\") +\n  labs(x = \"Release Year\", y = \"Actor Ages\", color= \"Age Gap\") +\n  annotate(geom=\"text\", x=1950, y=75, label=\"Lead Male Actors\", colour=\"dodgerblue4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1950, y=80, label=\"Lead Female Actors\", colour=\"deeppink4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) \n  \n\n\nARAplot"
  },
  {
    "objectID": "tidytuesday_exercise.html#relationship-between-movie-release-data-age-difference-and-supporting-actor-age",
    "href": "tidytuesday_exercise.html#relationship-between-movie-release-data-age-difference-and-supporting-actor-age",
    "title": "Tidy Tuesday Exercise",
    "section": "Relationship between Movie release data, Age difference, and supporting Actor Age",
    "text": "Relationship between Movie release data, Age difference, and supporting Actor Age\n###Supporting actor age\n\nASAplot <- ggplot() +\n    geom_point(data = leadMdata, aes(x = release_year, y = supporting_actor_age, size = age_difference), fill = 'deepskyblue2', shape = 21, colour = \"black\") +\n  geom_point(data = leadFdata, aes(x = release_year, y = supporting_actor_age, size = age_difference), fill = 'deeppink1', shape = 21, colour = \"black\") +\n  ggtitle(\"Supporting Actor Age in Relation to the Movie Release Data\", subtitle = \"Factoring in Age Gaps between Lead and Supporting Actors\") +\nlabs(x = \"Release Year\", y = \"Actor Ages\") +\n   annotate(geom=\"text\", x=1965, y=60, label=\"Actors that Support Male Leads\", colour=\"deepskyblue2\", size=4, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=1965, y=65, label=\"Actors that Support Female Leads\", colour=\"deeppink1\", size=4, family=\"sans\", fontface=\"bold\", angle=0)\n\nASAplot"
  },
  {
    "objectID": "tidytuesday_exercise.html#lead-age-vs-supporting-actor-age",
    "href": "tidytuesday_exercise.html#lead-age-vs-supporting-actor-age",
    "title": "Tidy Tuesday Exercise",
    "section": "Lead Age vs Supporting actor age",
    "text": "Lead Age vs Supporting actor age\n\nOpposite vs Same-sex\n\nlets add some trends\nMales:\n\nSSplot <- ggplot() +\n  geom_point(data = leadMdata, aes(x = age_difference, y = lead_male_age), color = 'dodgerblue4', size=2) +\n  geom_point(data = leadMdata, aes(x = age_difference, y = supporting_actor_age, color = supporting_gender), size=2 , shape = 21) +\n  ggtitle(\"Male Actor Age in Relation to the Age Gaps\", subtitle = \"Evaluated by Supporting Actor Genders\") +\n  labs(x = \"Age Difference Between Supporitng and Lead Actors\", y = \"Actor Ages\") +\n  annotate(geom=\"text\", x=7, y=80, label=\"Lead Male Actors\", colour=\"dodgerblue4\", size=4, family=\"sans\", fontface=\"bold\", angle=0)  + \n  annotate(geom=\"text\", x=7, y=75, label=\"Supporting Actors\", color=\"cyan4\", size=4, family=\"sans\", fontface=\"bold\", angle=0) \n\n\nSSplot \n\n\n\n\nFemales:\n\nSSFplot <- ggplot() +\n  geom_point(data = leadFdata, aes(x = age_difference, y = lead_female_age), color = 'deeppink4', size=2) +\n  geom_point(data = leadFdata, aes(x = age_difference, y = supporting_actor_age, color = supporting_gender), size=2 , shape = 21) +\n  ggtitle(\"Female Actor Age in Relation to the Age Gaps\", subtitle = \"Evaluated by Supporting Actor Genders\") +\n  labs(x = \"Age Difference Between Supporitng and Lead Actors\", y = \"Actor Ages\") +\n  annotate(geom=\"text\", x=10, y=75, label=\"Lead Female Actors\", colour=\"deeppink4\", size=4, family=\"sans\", fontface=\"bold\", angle=0)  + \n  annotate(geom=\"text\", x=10, y=70, label=\"Supporting Actors\", color=\"orangered2\", size=4, family=\"sans\", fontface=\"bold\", angle=0) \n\n\nSSFplot \n\n\n\n\nWow this is pretty striking! The raw cleaned data really shows a disparity between male leads and female leads and the age gap between their supporting actors!\nWe could play with this data forever! I will stop here but if you have a recommendation please post it on my “issues” page of my github!"
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "https://fivethirtyeight.com/features/marriage-isnt-dead-yet/\nGraph I am trying to replicate:\n\n\n\nUpload raw data to R and install/load packages required to clean data.\n\n#install.packages('dslabs')\n#install.packages('tidyverse')\n#install.packages('here')\n#install.packages('rjson')\n#install.packages('plotly')\n#install.packages('ggthemes')\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'stringr' was built under R version 4.2.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(dslabs)\n\nWarning: package 'dslabs' was built under R version 4.2.2\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at C:/Users/Raquel/GitHub/MADA/RaquelFrancisco-MADA-portfolio\n\nlibrary(plotly)\n\nWarning: package 'plotly' was built under R version 4.2.2\n\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.2\n\n#import file via relative path\n#raw_bothsexes <- read_csv(here('Visualization_Exercise/raw_data/both_sexes.csv'))\nraw_divorce <- read_csv(here('Visualization_Exercise/raw_data/divorce.csv'))\n\nNew names:\nRows: 17 Columns: 21\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" dbl\n(20): ...1, year, all_3544, HS_3544, SC_3544, BAp_3544, BAo_3544, GD_35... date\n(1): date\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n\n#raw_men <- read_csv(here('Visualization_Exercise/raw_data/men.csv'))\n#raw_women <- read_csv(here('Visualization_Exercise/raw_data/women.csv'))\n\ntibble(raw_divorce)\n\n# A tibble: 17 × 21\n    ...1  year date       all_3544 HS_3544 SC_3544 BAp_3544 BAo_3544 GD_3544\n   <dbl> <dbl> <date>        <dbl>   <dbl>   <dbl>    <dbl>    <dbl>   <dbl>\n 1     1  1960 1960-01-01   0.0344  0.0349  0.0337   0.0275   0.0275 NA     \n 2     2  1970 1970-01-01   0.0493  0.0500  0.0487   0.0413   0.0413 NA     \n 3     3  1980 1980-01-01   0.106   0.104   0.113    0.0978   0.0978 NA     \n 4     4  1990 1990-01-01   0.151   0.159   0.170    0.115    0.119   0.109 \n 5     5  2000 2000-01-01   0.157   0.175   0.174    0.106    0.111   0.0959\n 6     6  2001 2001-01-01   0.157   0.174   0.178    0.107    0.112   0.0972\n 7     7  2002 2002-01-01   0.157   0.175   0.179    0.103    0.110   0.0908\n 8     8  2003 2003-01-01   0.154   0.173   0.177    0.103    0.111   0.0864\n 9     9  2004 2004-01-01   0.155   0.178   0.177    0.100    0.106   0.0891\n10    10  2005 2005-01-01   0.153   0.175   0.177    0.0995   0.107   0.0850\n11    11  2006 2006-01-01   0.162   0.189   0.184    0.104    0.111   0.0905\n12    12  2007 2007-01-01   0.160   0.187   0.185    0.104    0.112   0.0891\n13    13  2008 2008-01-01   0.161   0.188   0.189    0.102    0.111   0.0852\n14    14  2009 2009-01-01   0.160   0.187   0.190    0.102    0.112   0.0844\n15    15  2010 2010-01-01   0.164   0.190   0.197    0.103    0.112   0.0882\n16    16  2011 2011-01-01   0.166   0.192   0.200    0.108    0.117   0.0919\n17    17  2012 2012-01-01   0.165   0.190   0.203    0.107    0.115   0.0943\n# … with 12 more variables: poor_3544 <dbl>, mid_3544 <dbl>, rich_3544 <dbl>,\n#   all_4554 <dbl>, HS_4554 <dbl>, SC_4554 <dbl>, BAp_4554 <dbl>,\n#   BAo_4554 <dbl>, GD_4554 <dbl>, poor_4554 <dbl>, mid_4554 <dbl>,\n#   rich_4554 <dbl>\n\n\n\n\n\nVariables will be:\n\n\nHS | High school graduate or less (EDUCD < 65)\n\n\n\nSC | Some college (EDUCD >= 65 & <= 100)\n\n\n\nBAp | Bachelor’s degree or more (EDUCD > 100) BAo | Bachelor’s degree, no graduate degre (EDUCD > 100 & <= 113) GD | Graduate degree (EDUCD > 113)\nGoal is to have an X- Axis of “Year (Decade)” and a Y-Axis of “% of Divorce with Education” of only ages 35 to 44\n\nclean_Div <- raw_divorce %>%\n  select('year', 'HS_3544', 'SC_3544', 'BAp_3544', 'BAo_3544', 'GD_3544')\n  \nclean_Div$Graduate <- rowMeans(clean_Div[, c(3:5)], na.rm=TRUE)\n#I made the exective decision to get an average of this data because this would be what would me most reminiscent of the original graph. It looks exactly the same as there's after visualization.\n\nclean_Div <- rename(clean_Div, SomeCollege = SC_3544)\nclean_Div <- rename(clean_Div, Highschool = HS_3544)\nclean_Div <- rename(clean_Div, Year = year)\n\nDiv_3345 <- clean_Div %>%\n  select('Year','Highschool', 'SomeCollege', 'Graduate')\n\n\n\n\n\n\nmain <- ggplot(data = Div_3345) +\n  geom_line(aes(x = Year, y = Highschool), color = 'lightblue3', size=1.5) +\n  geom_line(aes(x = Year, y = Graduate), color = \"paleturquoise\", size=1.5) +\n  geom_line(aes(x = Year, y = SomeCollege), color = '#336699', size=1.5) +\n  xlab(\"\") + \n  ylab(\"\") +\n  ggtitle(\"Divorce Rates By Education\", subtitle = \"Ages 35 to 44\") +\n  scale_color_fivethirtyeight() +\n  theme_fivethirtyeight(base_size = 18, base_family = \"sans\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  annotate(geom=\"text\", x=1995, y=.2, label=\"Some College\", colour=\"#336699\",\n             size=6, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=2000, y=.15, label=\"High school or less\", colour=\"lightblue3\",\n             size=6, family=\"sans\", fontface=\"bold\", angle=0) +\n  annotate(geom=\"text\", x=2005, y=.12, label=\"College graduates\", colour=\"paleturquoise\",\n             size=6, family=\"sans\", fontface=\"bold\", angle=0)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n#My biggest issue with this graph is I cannot figure out how they added the labels for each education level with black with lines pointing to each trendline. Is it possible that they did this in lightroom after? To compensate, I made the labels \"float\" near the lines and made their color match.\n\nmain\n\n\n\n##ggthemes had a theme called 'fivethirtyeight' that was very close to what is seen in the original plot. It was found here: https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/theme_fivethirtyeight/\n\n\n\n\n\nggplotly(maintooltip = c(\"text\"))\n\nWarning: plotly.js does not (yet) support horizontal legend items \nYou can track progress here: \nhttps://github.com/plotly/plotly.js/issues/53 \n\n\n\n\n\ntwo <- plotly_build(main)\n\nWarning: plotly.js does not (yet) support horizontal legend items \nYou can track progress here: \nhttps://github.com/plotly/plotly.js/issues/53 \n\nnames(two$x$data[[1]])\n\n [1] \"x\"          \"y\"          \"text\"       \"type\"       \"mode\"      \n [6] \"line\"       \"hoveron\"    \"showlegend\" \"xaxis\"      \"yaxis\"     \n[11] \"hoverinfo\"  \"frame\"     \n\nnames(two$x$layout)\n\n [1] \"margin\"        \"plot_bgcolor\"  \"paper_bgcolor\" \"font\"         \n [5] \"title\"         \"xaxis\"         \"yaxis\"         \"shapes\"       \n [9] \"showlegend\"    \"legend\"        \"hovermode\"     \"barmode\"      \n\n#I am having trouble editing the layout of plotly. The github and help pages have not been very helpful."
  }
]